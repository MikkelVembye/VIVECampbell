[{"path":"https://mikkelvembye.github.io/VIVECampbell/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2023 VIVECampbell authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://mikkelvembye.github.io/VIVECampbell/articles/Entering-data.html","id":"introduktion","dir":"Articles","previous_headings":"","what":"Introduktion","title":"Indtastning af data, effektstørrelsesudregning og cluster bias justering, når der kun er clustering i en gruppe","text":"Vigtig note Hvis du endnu ikke har arbejdet med R, så har Jens og jeg skrevet den lille blog “Kom godt gang med metaanalyse R”, som jeg vil anbefale gennemse sammen med denne blog. Alternativ kan de også være en god ide læse det første kapitel R4DS. Nedenfor loader jeg en række af de pakker som vi ofteste benytter forbindelse med dataindtastning og effektstørrelsesudregning. Dog vil jeg fremhæve, den langt vigtigste af disse pakker er dplyr. Det kan være en ret stor fordel blive god til grundfunktionerne denne pakke, dvs. filter(), mutate(), group_by(), summarise(), arrange() og select().   Denne vignette/blog er tiltænkt skulle være en basic introduktion til en række vigtige emner, som er relevante, når man skal indtaste komplex resultatdata og beregne effektstørrelser fra studier, som skal med vores systematiske reviews. En vigtig del af vignetten handler om vise, hvordan man benytter funktionerne vgt_smd_1armcluster(), df_h_1armcluster(), eta_1armcluster() og gamma_1armcluster() fra VIVECampbell R pakken. Vignetten er opbygget som følger: første del gennemgår jeg, hvordan kompleks data indtastes, og jeg taler kort om, hvilket fejl man typisk laver, når man indtaster data. Derefter viser jeg tre af de mest normale/typiske effektstørrelser, som man støder på socialvidenskaben. Herefter viser jeg, hvordan disse kan beregnes. Jeg viser blandt andet, hvordan man ofte kan beregne pre-posttest korrelationer mellem outcomes, når vise datastrukturer afrapporteres primær forskningen. den sidste del, viser jeg, hvordan vi kan kluster bias korrigere vores effekter, når der kun er klustering en gruppe samt hvordan man kan estimere varians-covarians matricer studier med flere treatment (og/eller kontrol) grupper. viser jeg hvordan man kan benytte vcalc() funktionen fra metafor-pakken. Afsluttende viser jeg, hvordan man kan visualisere den konstruerede effektstørrelsesdata.","code":""},{"path":"https://mikkelvembye.github.io/VIVECampbell/articles/Entering-data.html","id":"nødvendige-pakker-og-hjælpsomme-options","dir":"Articles","previous_headings":"Introduktion","what":"Nødvendige pakker og hjælpsomme options","title":"Indtastning af data, effektstørrelsesudregning og cluster bias justering, når der kun er clustering i en gruppe","text":"Når du er klar til gå ombord denne blog, kan du nedenfor se, de pakker som bloggen trækker på. Ud fra hver pakke har jeg beskrevet, hvad pakkens eller optionens primære rolle er. hente VIVECampbell skal fjerne # foran hhv. install.packages(\"devtools\") og devtools::install_github(\"MikkelVembye/VIVECampbell\") og så køre disse koder. Dette skal kun gøre første gang man kører koderne. Dog ikke nødvendigt gøre, hvis man allerede har hentet VIVECampbell-pakken.","code":"#install.packages(\"devtools\") #devtools::install_github(\"MikkelVembye/VIVECampbell\")  library(VIVECampbell) # Indholder funktioner til at udføre cluster bias justeringer library(purrr) # Indeholde vigtige loop (map) funktioner, der gør det let at gentage mange ens udregninger og dataændringer library(dplyr) # Nøglepakke til at manipulere data library(tidyr) # Indeholder vigtige pivot_ funktioner, som hjælper med at ændre dataset fra wide til long format vice versa library(gt)    # Tabelkonstruktionens svar på ggplot2 library(ggplot2) # Til at visualisere plot library(tibble) # En type af data.frames som er mere effektive. I vil se, at jeg altid arbejder med tibbler og ikke rå data.frames library(metafor) # benytte vi til at beregne variance-covariance matrix  # Options som jeg for det mest benytter options(pillar.sigfig = 4) # Resultater printes med 4 decimaler options(tibble.width = Inf) # Sikre at alle variabler printes options(dplyr.print_min = 310) # Antal rækker som printes fra et datasæt options(scipen = 10) # Indikerer hvormange decimaler der skal være før R printer videnskabelige numre options(dplyr.summarise.inform = FALSE) # Undgår info fra summarize() fra dplyr"},{"path":"https://mikkelvembye.github.io/VIVECampbell/articles/Entering-data.html","id":"kompleks-resultdata-og-hvordan-den-kan-indtastes-long-format","dir":"Articles","previous_headings":"","what":"Kompleks resultdata og hvordan den kan indtastes (long-format)","title":"Indtastning af data, effektstørrelsesudregning og cluster bias justering, når der kun er clustering i en gruppe","text":"Når vi laver systematiske reviews, støder vi meget tit på studier, som afrapporterer rigtig mange resultater, som er relevante vores review. Et typisk eksempel kan se ud som Tabel 1 nedenfor fra Fisher & Bentley (1996).1 Som det kan ses , er den resultatsdata som skal udtrækkes relativ kompleks med pretest, posttest og difference mål nested inden treatment grupper (dvs. Disease--recovery, Coginitive behavioral og TAU grupperne), som er nestet inden kontekster/settings (dvs. Inpatient og Outpatient settings), som igen er nestet inden outcomes (dvs. Alcohol use, Drug use, Social family relations samt Psychological functioning). Jeg vil senere vise, hvordan man kan arbejde med effektstørrelsesdata, hvor man har mere end en treatment- eller kontrolgruppe. Men først lidt introduktion til en vigtig basic funktion. Når man vil konstruere et datasæt R er en vigtig base::-funktion kende til den som hedder rep(). Den tillader replikere de samme værdier på forskellig vis inden en given variabel. Nedenfor vise en række eksempler på, hvordan denne kan bruges. Nedenfor viser jeg, hvordan man kunne indtaste data fra Tabel 1 vha. tibble() samt rep(). Måden, hvorpå jeg indtaster data kaldes af nogen long format data, hvor hver treatment gruppernes (dvs. Disease--recovery, Coginitive behavioral og TAU) resultater repræsenteret hver deres række. Jeg vil senere bloggen tale og vise forskellen på long og wide-format data (hvor hver effektstørrelse har en række), og hvordan man benytter pivot_longer() og pivot_wider() fra tidyr-pakken til skifte mellem disse formater.  Når man indtaster data, kan det være en klar fordel konstruere treatment/group variabel sådan treatment gruppen/grupperne kommer indtastet før kontrol gruppen. Hvis dette gøres er det hvert fald lettere genbruge mine koder fra tidligere projekter, da det altid er måden jeg gør det på. Derudover benytter jeg aldrig store start bogstaver, når jeg laver variabelnavne. Det er kun værdierne inden en variabel, jeg kan finde på give store bogstaver.","code":"# Her replikeres den samme værdirækkefølge x (dvs. i dette tilfæde 4) gange rep(LETTERS[1:3], 4) #>  [1] \"A\" \"B\" \"C\" \"A\" \"B\" \"C\" \"A\" \"B\" \"C\" \"A\" \"B\" \"C\"  # Her replikeres hver værdi x (dvs. i dette tilfæde 3) gange rep(LETTERS[1:3], each = 3) #> [1] \"A\" \"A\" \"A\" \"B\" \"B\" \"B\" \"C\" \"C\" \"C\"  # Ovenstående operationer kan også kombineres rep(LETTERS[1:3], each = 2, 2) #>  [1] \"A\" \"A\" \"B\" \"B\" \"C\" \"C\" \"A\" \"A\" \"B\" \"B\" \"C\" \"C\"  # Man kan også skabe en variable med en fast antal gentagelser således rep(LETTERS[1:3], length.out = 11) #>  [1] \"A\" \"B\" \"C\" \"A\" \"B\" \"C\" \"A\" \"B\" \"C\" \"A\" \"B\"  # Igen alle disse operationer kan kombineres i samme funktion rep(LETTERS[1:3], each = 2, 2, length.out = 11) #>  [1] \"A\" \"A\" \"B\" \"B\" \"C\" \"C\" \"A\" \"A\" \"B\" \"B\" \"C\" Fisher1996 <- tibble::tibble(      outcome = rep(c(\"Alcohol use\", \"Drug use\", \"Social\", \"Psych func\"), each = 6),       setting = rep(c(\"Inpatient\", \"Outpatient\"), each = 3, 4),      treatment = rep(c(\"Disease\", \"Cognitive\", \"TAU\"), 8),      N = rep(c(6,6,7), 8),       m_pre = c(          # Alle værider som er indtaster i de andre variable har samme rækkefølge som denne variabel     # Det er altid en god ide at skrive en vha. # som viser hvilket outcome der indtastes          .469, .441, .349, # Alcohol use - inpatient     .725, .598, .682, # Alcohol use - outpatient          .107, .116, .117, # Drug use - inpatient      .219, .200, .322, # Drug use - outpatient          .342, .419, .450, # Social and family relations - inpatient     .683, .584, .571, # Social and family relations - outpatient          .393, .498, .605, # Psychological functioning - inpatient       .464, .476, .487  # Psychological functioning - outpatient             ),      sd_pre = c(     .12, .13, .22,     .11, .16, .17,          .09, .10, .12,     .11, .12, .05,          .21, .12, .24,     .04, .05, .09,          .17, .13, .15,     .14, .12, .16        ),      m_post = c(     .070, .018, .141,     .521, .152, .492,          .001, .008, .087,     .167, .044, .216,          .083, .103, .489,     .641, .233, .514,          .319, .442, .601,     .432, .232, .472        ),      sd_post = c(     .11, .05, .21,     .11, .15, .27,          .01, .02, .12,     .10, .05, .15,          .10, .10, .18,     .06, .16, .12,          .14, .16, .18,      .18, .07, .18             ),      m_diff = c(     .399, .423, .208,     .204, .446, .190,          .106, .108, .030,     .052, .196, .106,          .259, .316, -.039,     .042, .351, .057,          .074, .056, .004,      .032, .244, .015        ),      sd_diff = c(     .02, .09, .04,     .01, .02, .11,          .09, .09, .02,      .02, .08, .11,          .13, .03, .07,     .03, .12, .04,          .04, .04, .04,     .05, .06, .03        ),      # Here we test if the mean differences reported in the study are in line   # with the differences between the reported pre and post means. It seems to   # be the case that they make a reporting error for the cognitive outpatient    # group mean difference on drug use. Write about the error can be on many levels   mean_diff_test = m_pre - m_post,    ); Fisher1996 #> # A tibble: 24 × 11 #>    outcome     setting    treatment     N m_pre sd_pre m_post sd_post m_diff #>    <chr>       <chr>      <chr>     <dbl> <dbl>  <dbl>  <dbl>   <dbl>  <dbl> #>  1 Alcohol use Inpatient  Disease       6 0.469   0.12  0.07     0.11  0.399 #>  2 Alcohol use Inpatient  Cognitive     6 0.441   0.13  0.018    0.05  0.423 #>  3 Alcohol use Inpatient  TAU           7 0.349   0.22  0.141    0.21  0.208 #>  4 Alcohol use Outpatient Disease       6 0.725   0.11  0.521    0.11  0.204 #>  5 Alcohol use Outpatient Cognitive     6 0.598   0.16  0.152    0.15  0.446 #>  6 Alcohol use Outpatient TAU           7 0.682   0.17  0.492    0.27  0.19  #>  7 Drug use    Inpatient  Disease       6 0.107   0.09  0.001    0.01  0.106 #>  8 Drug use    Inpatient  Cognitive     6 0.116   0.1   0.008    0.02  0.108 #>  9 Drug use    Inpatient  TAU           7 0.117   0.12  0.087    0.12  0.03  #> 10 Drug use    Outpatient Disease       6 0.219   0.11  0.167    0.1   0.052 #> 11 Drug use    Outpatient Cognitive     6 0.2     0.12  0.044    0.05  0.196 #> 12 Drug use    Outpatient TAU           7 0.322   0.05  0.216    0.15  0.106 #> 13 Social      Inpatient  Disease       6 0.342   0.21  0.083    0.1   0.259 #> 14 Social      Inpatient  Cognitive     6 0.419   0.12  0.103    0.1   0.316 #> 15 Social      Inpatient  TAU           7 0.45    0.24  0.489    0.18 -0.039 #> 16 Social      Outpatient Disease       6 0.683   0.04  0.641    0.06  0.042 #> 17 Social      Outpatient Cognitive     6 0.584   0.05  0.233    0.16  0.351 #> 18 Social      Outpatient TAU           7 0.571   0.09  0.514    0.12  0.057 #> 19 Psych func  Inpatient  Disease       6 0.393   0.17  0.319    0.14  0.074 #> 20 Psych func  Inpatient  Cognitive     6 0.498   0.13  0.442    0.16  0.056 #> 21 Psych func  Inpatient  TAU           7 0.605   0.15  0.601    0.18  0.004 #> 22 Psych func  Outpatient Disease       6 0.464   0.14  0.432    0.18  0.032 #> 23 Psych func  Outpatient Cognitive     6 0.476   0.12  0.232    0.07  0.244 #> 24 Psych func  Outpatient TAU           7 0.487   0.16  0.472    0.18  0.015 #>    sd_diff mean_diff_test #>      <dbl>          <dbl> #>  1    0.02       0.399    #>  2    0.09       0.423    #>  3    0.04       0.208    #>  4    0.01       0.204    #>  5    0.02       0.446    #>  6    0.11       0.19     #>  7    0.09       0.106    #>  8    0.09       0.108    #>  9    0.02       0.03     #> 10    0.02       0.052    #> 11    0.08       0.156    #> 12    0.11       0.106    #> 13    0.13       0.259    #> 14    0.03       0.316    #> 15    0.07      -0.0390   #> 16    0.03       0.04200  #> 17    0.12       0.351    #> 18    0.04       0.05700  #> 19    0.04       0.074    #> 20    0.04       0.056    #> 21    0.04       0.004000 #> 22    0.05       0.03200  #> 23    0.06       0.244    #> 24    0.03       0.01500"},{"path":"https://mikkelvembye.github.io/VIVECampbell/articles/Entering-data.html","id":"typiske-fejl-når-man-indtaster-data","dir":"Articles","previous_headings":"Kompleks resultdata og hvordan den kan indtastes (long-format)","what":"Typiske fejl, når man indtaster data","title":"Indtastning af data, effektstørrelsesudregning og cluster bias justering, når der kun er clustering i en gruppe","text":"Når man benytter rep() til skabe en variabel et datasæt, er en af de mest typiske fejl man laver, man genererer variabler, som ikke har lige mange værdier. Hvis dette er tilfældet, får man en fejlmelding la den nedenfor.","code":"tibble(   var1 = rep(1:2, 2),   var2 = rep(c(\"A\", \"B\"), 3) )  #Error in `tibble()`: #! Tibble columns must have compatible sizes. #• Size 4: Existing data. #• Size 6: Column at position 2. #ℹ Only values of size one are recycled. #Run `rlang::last_trace()` to see where the error occurred."},{"path":"https://mikkelvembye.github.io/VIVECampbell/articles/Entering-data.html","id":"effektstørrelsesudregning-med-kompleks-data","dir":"Articles","previous_headings":"","what":"Effektstørrelsesudregning med kompleks data","title":"Indtastning af data, effektstørrelsesudregning og cluster bias justering, når der kun er clustering i en gruppe","text":"Når man får fingrene så komplekst afrapporteret data som den fra Tabel 1, opstår der en række spørgsmål ift. hvilken typer af effektstørrelser, som vil være de bedste beregne, idet man kan vælge en række forskellige effektstørrelsesindekser dette tilfælde. Jeg vil gennemgå de tre mest kendte typer af effektstørrelser som man vil kunne beregne ud fra denne data, og vise, hvordan man kan beregne pre-posttest korrelationer ρprepost\\rho_{prepost}, når data er afrapporteret som Tabel 1.","code":""},{"path":"https://mikkelvembye.github.io/VIVECampbell/articles/Entering-data.html","id":"cohens-d","dir":"Articles","previous_headings":"Effektstørrelsesudregning med kompleks data","what":"Cohens’ dd","title":"Indtastning af data, effektstørrelsesudregning og cluster bias justering, når der kun er clustering i en gruppe","text":"Den vel nok mest kendte effektstørrelse, som man vil møde litteraturen er den som kaldes Cohens’ dd. Denne effektstørrelse beregnes således d=(MpostT−MpostCSDpool)\\begin{equation}   \\tag{1}    d = \\left(\\frac{M^T_{post} - M^C_{post}}{SD_{pool}}\\right) \\end{equation} hvor MpostTM^T_{post} og MpostCM^C_{post} er posttestmål hhv. treatment og kontrolgruppen, mes SDpoolSD_{pool} beregnes via SDpool=(npostT−1)×(SDpostT)2+(npostC−1)×(SDpostC)2nT+nC−2\\begin{equation}   \\tag{2}    SD_{pool}  = \\sqrt{\\frac{(n^T_{post} -1)\\times(SD^T_{post})^2 + (n^C_{post} -1)\\times(SD^C_{post})^2}{n^T + n^C - 2}} \\end{equation} nTn^T og nCn^C samt SDpostTSD^T_{post} og SDpostCSD^C_{post} er samplestørrelsen og standardafvigelsen på posttest niveau hhv. treatment og kontrolgruppen. Sampling variansen Cohens’ dd er givet ved Vard=(1nT+1nC)+d22df\\begin{equation}   \\tag{3}    Var_d = \\left(\\frac{1}{n^T} + \\frac{1}{n^C}\\right) + \\frac{d^2}{2df} \\end{equation} hvor df=nT+nCdf = n^T + n^C når der ikke er clusteringproblemer. En meget vigtig viden, som forhåbentlig kan gøre det lettere forstå, hvorfor vi senere laver cluster-justeringer og hvordan vi gennemfører publikationsbiastests, er, forstå, det første led formel (2), dvs. (1nT+1nC)\\left(\\frac{1}{n^T} + \\frac{1}{n^C}\\right), indfanger sampling variationen tælleren formel (1), dvs. MpostT−MpostCM^T_{post} - M^C_{post}, mens andet led formel (2), dvs. d22df\\frac{d^2}{2df} indfanger sampling variansen nævner formel (1), dvs. SDpoolSD_{pool}. Det er første led, som skaber det store bias, hvis et studie ikke har håndtere klustering korrekt. Så når vi senere kluster bias korrigerer effekterne fra dette studie, vil se, led et få gange en kluster faktor på sig, som ofte vil gøre dette led substantielt større. En anden vigtig del ift. formel (3) er forstå, andet leddet formel (3) (dvs. leddet til højre ++-tegnet), og senere formel (8), skaber en falsk korrelation mellem dd og VardVar_d (se Pustejovsky & Rodgers, (2019), fordi dd benyttes til beregne dette led. Når vi estimerer publikationsbias test fjerner vi derfor dette led, så kan vi ikke risikerer fejlagtigt konkludere små studier oftere afrapporterer større effekter, som blot skyldes et beregningsartifakt. Variansleddet vi benytter publikationsbiastest ser derfor således ud; Wd=(1nT+1nC)\\begin{equation}   \\tag{4}    W_d = \\left(\\frac{1}{n^T} + \\frac{1}{n^C}\\right) \\end{equation}","code":""},{"path":"https://mikkelvembye.github.io/VIVECampbell/articles/Entering-data.html","id":"beregning-af-standardafvigelse-baseret-på-alle-grupper-i-fleregruppe-studier","dir":"Articles","previous_headings":"Effektstørrelsesudregning med kompleks data > Cohens’ dd","what":"Beregning af standardafvigelse baseret på alle grupper i fleregruppe studier","title":"Indtastning af data, effektstørrelsesudregning og cluster bias justering, når der kun er clustering i en gruppe","text":"Når man har med fleregruppe studier (dvs. multi-arm trials), som Fisher studiet , kan man argumentere , en bedre beregning af den poolede standardafvigelse (SD) ville bero på en SD, som er baseret på alle målte SDs på tværs af alle grupperne forsøget. Dermed vil den poolede SD holdes konstant på af de forskellige effekter. Det er normalt ikke noget vi benytter vores reviews, men jeg viser formlen og koderne til beregne denne, hvis man skulle få brug den. Hvis man vil bruge denne tilgang, så beregnes den samlede SDpool,allSD_{pool, } således SDpool,=1N−T−1∑t=0T(nt−1)(SDpostt)2\\begin{equation}   \\tag{5}    SD_{pool, } = \\sqrt{\\frac{1}{N-T-1}\\sum^{T}_{t=0}(n^t-1)(SD^t_{post})^2} \\end{equation} hvor N=∑t=0TntN = \\sum^{T}_{t=0}n^t treatmentgrupperne t=0,...,Tt=0,...,T med t=0t=0 svarende til kontrolgruppen (CC). Det objekt kan senere bindes sammen med vores effektstørrelsesdata.","code":"SD_all_arms <-    Fisher1996 |>    dplyr::summarise(     # Her beregner jeg formel (5)     SD_all_arm = sqrt( (1/(sum(N)-3-1)) * sum((N-1)*sd_post^2) ),     .by = c(outcome, setting)   ) |>    slice(rep(1:8, 2)) |>    arrange(outcome, setting) |>    mutate(     treatment = rep(c(\"Disease\", \"Cognitive\"), 8)   ) |>    relocate(treatment, .after = setting)"},{"path":"https://mikkelvembye.github.io/VIVECampbell/articles/Entering-data.html","id":"hedges-g","dir":"Articles","previous_headings":"Effektstørrelsesudregning med kompleks data","what":"Hedges’ gg","title":"Indtastning af data, effektstørrelsesudregning og cluster bias justering, når der kun er clustering i en gruppe","text":"En anden meget kendte effektstørrelser er den såkaldte Hedges’ gg. Forskellen med Cohens’ dd og Hedges’ gg er, Hedges gg korrigerer en overestimeringfejl Cohens’ dd. Det vil konkret sige Cohens’ dd bliver stor ift. den sande bagvedliggende effekt som forsøges estimeres, når sample størrelsen er lille, dvs. når nt<20n^t<20. Derfor ganges en korrektion faktor J=1−3(4−df−1)J = 1 - \\frac{3}{(4-df-1)} på formlel (1). Det ser ud således g=J(MpostT−MpostCSDpool)\\begin{equation}   \\tag{6}    g = J\\left(\\frac{M^T_{post} - M^C_{post}}{SD_{pool}}\\right) \\end{equation} Larry Hedges, som har udviklet denne effektstørrelse, har senere fundet, det ikke er nødvendigt korrigere variansen denne effektstørrelse. Det vil sige, vi kan beregne sampling variansen med formel (2). vil kunne støde på nogle referencer, som ganger J2J^2 på formel (2), men dette ser som sagt ikke længere ud til være nødvendigt.","code":""},{"path":"https://mikkelvembye.github.io/VIVECampbell/articles/Entering-data.html","id":"glass-delta","dir":"Articles","previous_headings":"Effektstørrelsesudregning med kompleks data","what":"Glass’ Δ\\Delta","title":"Indtastning af data, effektstørrelsesudregning og cluster bias justering, når der kun er clustering i en gruppe","text":"Den sidste også relativt kendte effektstørrelse er Glass’ Δ\\Delta. Denne effektstørrelse adskiller sig ved, man kun benytter post-test standardafvigelsen fra kontrolgruppen, SDpostCSD^C_{post}, til standardisere/skalere effektforskellen formel (1). Det bygger på antagelsen om, kontrolgruppen ligner den fulde population mest, da disse ikke har været udsat en intervention. Den ser således ud Δ=(MpostT−MpostCSDpostC)\\begin{equation}   \\tag{7}    \\Delta = \\left(\\frac{M^T_{post} - M^C_{post}}{SD^C_{post}}\\right) \\end{equation} Formel (2) kan også benyttes til beregne sampling Δ\\Delta","code":""},{"path":"https://mikkelvembye.github.io/VIVECampbell/articles/Entering-data.html","id":"pretestbaseline-adjustede-effektstørrelser","dir":"Articles","previous_headings":"Effektstørrelsesudregning med kompleks data","what":"Pretest/baseline adjustede effektstørrelser","title":"Indtastning af data, effektstørrelsesudregning og cluster bias justering, når der kun er clustering i en gruppe","text":"Ovenfor har jeg vist en række af de mest kendte og simple effektstørrelsesformler. Fælles disse er, de alle sammen ‘kun’ benytter posttest-effekter til beregne gennemsnitforskellen mellem treatment og kontrolgruppen, som beror på den antagelse de raw means er unbiased. Det kan dog være en hård antagelse mange tilfælde, når vi tillader ikke-randomiserede studier vores reviews, da means ofte vil være en biased forskellig grad grundet brug af samples som ikke er trukket via randomisering. Dog kan antagelsen også være hård means, der kommer fra RCTs, især små RCTer, da samplingfejl selvfølgelig også kan forekomme den type af studier. En løsning til formildne dette intern validitetsprogram, er beregne, de såkaldte difference--differences () effektstørrelser (og kaldte pretest-adjusted effect sizes), hvor man kontrollerer baseline forskellene på outcme variablen ud mellem treatment og kontrolgruppen. Vi vil ofte beregne både Hedges’ gg og effektstørrelser, men jeg er ret stor fan af den sidste og vil altid lægge mest vægt på fotolkningen af disse, dels fordi denne effektsttørreslser kan reducere bias og dels fordi den kan estimateres mere præcist (se Hedges et al. 2023). Formlen effektstørrelsen er givet ved gDID=J([MpostT−MpreT]−[MpostC−MpreC]SDpool)\\begin{equation}   \\tag{8}    g_{} = J \\left(\\frac{[M^T_{post} - M^T_{pre}] - [M^C_{post} - M^C_{pre}]}{SD_{pool}}\\right) \\end{equation} hvor MpostTM^T_{post} og MpostCM^C_{post} samt MpreTM^T_{pre} og MpreCM^C_{pre} er post- og baselinemål hhv. treatment- og kontrolgruppen, og SDpool=(npostT−1)×(SDpostT)2+(npostC−1)×(SDpostC)2nT+nC−2SD_{pool}  = \\sqrt{\\frac{(n^T_{post} -1)\\times(SD^T_{post})^2 + (n^C_{post} -1)\\times(SD^C_{post})^2}{n^T + n^C - 2}}, mens nTn^T og nCn^C samt SDpostTSD^T_{post} og SDpostCSD^C_{post} er samplestørrelsen og standardafvigelsen hhv. treatment og kontrolgruppen. JJ formel (1) er Hedges’ sample sample korrektor lige med 1−34df−11 - \\frac{3}{4df-1} (nogen trækker 9 fra dfdf stedet 1, men det har ingen substantiel betydning).  Hvis vi antager, der ikke er klusterproblmer, så er df=nT+nCdf = n^T + n^C. Når der er klusteringproblemer kan dfdf beregnes via Equation E.21 (WWC, 2023, s. 171) eller hvis der kun er klustering en gruppe Equation 7 Hedges og Citkowicz (2015). Sampling variansen gDIDg_{} er givet ved VargDID=(1nT+1nC)2(1−ρprepost)+gDID22df\\begin{equation}   \\tag{9}    Var_{g_{}} = \\left(\\frac{1}{n^T} + \\frac{1}{n^C}\\right) 2(1-\\rho_{prepost})  + \\frac{g_{}^2}{2df} \\end{equation} Problemet er dog, man skal kende pre-posttest korrelationen, ρprepost\\rho_{prepost}, kunne beregne variansen korrekt. mange tilfælde vil vi være stand til kunne beregne denne (se eksempel nedenfor). Se eksemplvis formlerne fra Cochranes handbook eller formel 31 Wilson (2016). Se også denne blog på VIVECampbell siden. Alternativt kan VargDIDVar_{g_{}} beregnes korrekt, hvis forfatterne har afrapporteret tt- eller FF-værdier fra repeated ANOVA, ANCOVA eller en regressions model, som har inkluderet pretest-outcome som kontrol variabel. Hvis dette er tilfældet, så VargDID=gDID2t2+gDID22df\\begin{equation}   \\tag{10}    Var_{g_{}} = \\frac{g_{}^2}{t^2} + \\frac{g_{}^2}{2df} \\end{equation} Bemærk F=t2F = t^2. Se James Pustejovskys blog en yderligere uddybning. Det er igen vigtigt notere, når vi benytter disse typer af effektstørrelser publikationsbiastests, fjernes igen andet leddet (dvs. leddet på højre side af ++-tegnet) formlerne (8) og (9).","code":""},{"path":"https://mikkelvembye.github.io/VIVECampbell/articles/Entering-data.html","id":"beregning-af-pre-posttest-korrelation-rho_prepost","dir":"Articles","previous_headings":"Effektstørrelsesudregning med kompleks data > Pretest/baseline adjustede effektstørrelser","what":"Beregning af pre-posttest korrelation ρprepost\\rho_{prepost}","title":"Indtastning af data, effektstørrelsesudregning og cluster bias justering, når der kun er clustering i en gruppe","text":"kunne beregne sampling variansen gDIDg_{} skal vi kende, estimere eller imputere en værdi korrelationen mellem pretest og postscorene, ρprepost\\rho_{prepost}. jeg vil på et senere tidspunkt skrive en blog, hvor jeg vil vise eksempler på alle de måder jeg kender til, hvorpå man kan bakke ud ρprepost\\rho_{prepost}. Når resultaterne er afrapportet som Tabel 1, kan vi faktisk udregne den ρprepost\\rho_{prepost} hhv. treatment- og kontrolgruppen. kan vi benytte formler fra Cochranes handbook, som treatmentet gruppen kan beregnes vha ρprepostT=(SDpreT)2+(SDpostT)2−(SDdiffT)22×SDpreT×SDpostT\\begin{equation}   \\tag{11}    \\rho^T_{prepost} = \\frac{(SD^T_{pre})^2 + (SD^T_{post})^2 - (SD^T_{diff})^2}{2 \\times SD^T_{pre} \\times SD^T_{post}} \\end{equation} og kontrolgruppen ρprepostC=(SDpreC)2+(SDpostC)2−(SDdiffC)22×SDpreC×SDpostC\\begin{equation}   \\tag{12}    \\rho^C_{prepost} = \\frac{(SD^C_{pre})^2 + (SD^C_{post})^2 - (SD^C_{diff})^2}{2 \\times SD^C_{pre} \\times SD^C_{post}} \\end{equation} Disse beregninger kan vi faktisk lave/tilføje direkte vores datasæt indtastet ovenfor Nu kender vi pre-posttest korrelationen hhv. treatment- og kontrolgrupperne, men kunne beregne ρprepost\\rho_{prepost} skal vi beregne den gennemsnitlige korrelation baseret på korrelationen fra den treatment- og kontrolgruppe, som benyttes til udregne den givne effektstørrelse. præcist kunne beregne denne omregner man korrelationer til Fishers’ z-scores via zi=0.5×ln(1+ρpreposti1−ρpreposti)z_i = 0.5 \\times ln\\left(\\frac{1+\\rho^i_{prepost}}{1-\\rho^i_{prepost}}\\right) med varians vi=1n−3v_i = \\frac{1}{n-3}, hvor nn er gruppenstørrelsen. Varians bruges som vægt via wi=1viw_i = \\frac{1}{v_i}, når Fishers z-score konverteres tilbage til en korrelation-coefficient, således ρpreposti\\rho^i_{prepost} med flest observationer/individer får størst vægt. Disse kan beregnes direkte de råt indtastede data således Den gennemsnitlige Fishers’ z-score på tværs af grupperne kan derefter beregnes således zr‾=∑=1gwizi∑=1gwi\\begin{equation}   \\tag{13}    \\bar{z_r} = \\frac{\\sum^g_{= 1}w_iz_i}{\\sum^g_{= 1}w_i} \\end{equation} Herefter kan den gennemsnitlige pre-posttest korrelation på tværs af grupper beregnes via ρ‾prepost=e(2zr‾)−1e(2zr‾)+1\\begin{equation}   \\tag{14}    \\bar\\rho_{prepost} = \\frac{e^{(2\\bar{z_r}})-1}{e^{(2\\bar{z_r})}+1} \\end{equation} Jeg viser, hvordan dette kan beregnes, som det første nedenstående effektstørrelsesudregninger næste sektion.","code":"Fisher1996 <-    Fisher1996 |>    mutate(      # Regnes som i formler (11) og (12). I kan finde disse i Cochrane handbook (Higgins & Thomas, 2019, p. 166).   r = (sd_pre^2 + sd_post^2-sd_diff^2)/(2 * sd_pre * sd_post ),      ) Fisher1996 <-    Fisher1996 |>    mutate(   z = 0.5 * log( (1+r)/(1-r) ),   v = 1/(N-3),   w = 1/v   )"},{"path":"https://mikkelvembye.github.io/VIVECampbell/articles/Entering-data.html","id":"omsætning-af-formlerne-til-beregninger-i-r","dir":"Articles","previous_headings":"","what":"Omsætning af formlerne til beregninger i R","title":"Indtastning af data, effektstørrelsesudregning og cluster bias justering, når der kun er clustering i en gruppe","text":"Nedenfor vil jeg vise, hvordan kan omsætte ovenstående formler, dvs. beregne Cohens’ dd, Hedges’ gg samt difference--differences effektstørrelser R, og senere også hvordan korrigere disse klusterfejl. eksemplet nedenfor fjerner jeg den ene treatment gruppe forsimple beregningerne. Jeg vil længere nede vise, hvordan let kan skabe de samme beregninger på tværs af forskellige treatment-grupper. Når jeg arbejder med effektstørrelsesdata R, har jeg en række regler jeg arbejder ud fra. Den første er, jeg altid opkalder det rå effekt-data med efternavnet på førteforfatteren og udgivelsesåret studiet, således objektnavnet bliver AuthorYear. Objektet som indeholder effektstørrelsesudregningerne kalder jeg altid AuthorYear_est. est står ‘Effect Sizes standardized Total variation’. Lad os springe ud det.","code":"Fisher1996_es_disease <-    Fisher1996 |>    # Her fjerner jeg den treatment gruppen \"Cognitive\" for at kunne beregne effektstørrelser   # mellem Diasease og kontrol treatment   dplyr::filter(treatment != \"Cognitive\") |>    dplyr::summarise(       study = \"Fisher1996\",       treatment = treatment[1],       main_es_method = \"diff-in-diffs\",              #Her regner vi den gennemsnitlige Fishers z-score som angivet i formel (13)       mean_z = sum(w*z)/sum(w),       #Her beregner vi den gennemsnitlige pre-posttest korrelation som angivet i formel (14)        ppcor = (exp(2*mean_z)-1)/(exp(2*mean_z)+1),       # Her dokumneterer jeg, hvor vi har fundet pre-posttest korrelationen        ppcor_calc_method = \"Calculated from study results\",              # Her laver vi variabler, som viser sample størrelser opdelt på treatment- og kontrolgrupperne       N_t = N[1],       N_c = N[2],       # Her laver vi en variabler med den totale samplestørrelse       N_tot = sum(N),              # Her laver vi variablen med antal frihedsgrader, som benyttes hhv. til        # beregne andet led i variansformlerne (3) og (9) samt til at skabe J faktoren       # der bruges til beregne Hedges' g       df_ind = N_tot,              # Her beregnes en pooled standardafvigelse som vist i formel (2)       sd_pool = sqrt(sum((N - 1) * sd_post^2) / df_ind),              # Beregning af tælleren i formler (1), (6) og (7)        # Jeg vender her skalen om, da et fald i scoren på de givne skalaer indikerer en positiv fremgang       m_diff_post = (m_post[1]-m_post[2])*-1,              # Beregning af Cohens' d fra formel (1)       d_post = m_diff_post/sd_pool,       # variansudregning fra formel (3)       vd_post = sum(1/N) + d_post^2/(2*df_ind),       # Her beregnes det variansled, som er angivet i formel (4) og benyttes til        # publikationsbias testning       Wd_post = sum(1/N),              # Beregnig af Hedges' g fra formel (6)       J = 1 - 3/(4*df_ind-1),       g_post = J * d_post,       vg_post = vd_post,       Wg_post = sum(1/N),              # Beregnig af Glass' delta fra formel (7). Vi bruger aldrig denne, så den        # er kun med her for eksemplets skyld       sd_control = sd_post[2],       delta_post = m_diff_post/sd_control,              # Difference-in-differences (DID) effektstørrelsen       # Her beregner jeg den raw pre-posteffekt forskelle for hhv. treatment og       # gruppen.       diff_t = (m_post[1] - m_pre[1])*-1,       diff_c = (m_post[2] - m_pre[2])*-1,              # Her skaber jeg så tælleren fra formel (8)       DD = (diff_t - diff_c),              # Her bergener jeg hele formel (8)       d_DID = (diff_t - diff_c) / sd_pool,       # Her beregner jeg formel (9)       vd_DID = sum(1/N) * (2*(1-ppcor)) + d_DID^2/(2*df_ind),       # Hvis man vil beregne standardfejlen istedet tager man blot kvadratroden af variansen       sed_DID = sqrt(vd_DID),       # Her skabes den variabel som benyttes når vi skal gennemføre publikationsbias tests       Wd_DID = sum(1/N) * (2*(1-ppcor)),              # Her gøres det samme bare hvor vi indregner sample sample bias korrektoreren J       g_DID = J * d_DID,       vg_DID = sum(1/N) * (2*(1-ppcor)) + g_DID^2/(2*df_ind),       Wg_DID = Wd_DID,            # Effektstørrelserne skal beregne indenfor hver setting og outcome,       # Derfor grupperer jeg beregninger således      .by = c(setting, outcome)                  ) |>      relocate(study)  Fisher1996_es_disease #> # A tibble: 8 × 33 #>   study      setting    outcome     treatment main_es_method mean_z  ppcor #>   <chr>      <chr>      <chr>       <chr>     <chr>           <dbl>  <dbl> #> 1 Fisher1996 Inpatient  Alcohol use Disease   diff-in-diffs   2.480 0.9861 #> 2 Fisher1996 Outpatient Alcohol use Disease   diff-in-diffs   2.598 0.9890 #> 3 Fisher1996 Inpatient  Drug use    Disease   diff-in-diffs   1.442 0.8941 #> 4 Fisher1996 Outpatient Drug use    Disease   diff-in-diffs   1.806 0.9475 #> 5 Fisher1996 Inpatient  Social      Disease   diff-in-diffs   1.996 0.9637 #> 6 Fisher1996 Outpatient Social      Disease   diff-in-diffs   1.795 0.9463 #> 7 Fisher1996 Inpatient  Psych func  Disease   diff-in-diffs   2.489 0.9863 #> 8 Fisher1996 Outpatient Psych func  Disease   diff-in-diffs   2.562 0.9882 #>   ppcor_calc_method               N_t   N_c N_tot df_ind sd_pool m_diff_post #>   <chr>                         <dbl> <dbl> <dbl>  <dbl>   <dbl>       <dbl> #> 1 Calculated from study results     6     7    13     13 0.1581      0.071   #> 2 Calculated from study results     6     7    13     13 0.1957     -0.02900 #> 3 Calculated from study results     6     7    13     13 0.08176     0.086   #> 4 Calculated from study results     6     7    13     13 0.1193      0.049   #> 5 Calculated from study results     6     7    13     13 0.1371      0.406   #> 6 Calculated from study results     6     7    13     13 0.08961    -0.127   #> 7 Calculated from study results     6     7    13     13 0.1500      0.282   #> 8 Calculated from study results     6     7    13     13 0.1656      0.0400  #>    d_post vd_post Wd_post      J  g_post vg_post Wg_post sd_control delta_post #>     <dbl>   <dbl>   <dbl>  <dbl>   <dbl>   <dbl>   <dbl>      <dbl>      <dbl> #> 1  0.4490  0.3173  0.3095 0.9412  0.4226  0.3173  0.3095       0.21     0.3381 #> 2 -0.1482  0.3104  0.3095 0.9412 -0.1395  0.3104  0.3095       0.27    -0.1074 #> 3  1.052   0.3521  0.3095 0.9412  0.9900  0.3521  0.3095       0.12     0.7167 #> 4  0.4108  0.3160  0.3095 0.9412  0.3866  0.3160  0.3095       0.15     0.3267 #> 5  2.961   0.6467  0.3095 0.9412  2.787   0.6467  0.3095       0.18     2.256  #> 6 -1.417   0.3868  0.3095 0.9412 -1.334   0.3868  0.3095       0.12    -1.058  #> 7  1.880   0.4455  0.3095 0.9412  1.770   0.4455  0.3095       0.18     1.567  #> 8  0.2416  0.3118  0.3095 0.9412  0.2274  0.3118  0.3095       0.18     0.2222 #>    diff_t    diff_c       DD    d_DID   vd_DID sed_DID   Wd_DID    g_DID #>     <dbl>     <dbl>    <dbl>    <dbl>    <dbl>   <dbl>    <dbl>    <dbl> #> 1 0.399    0.208     0.191    1.208   0.06473  0.2544  0.008626  1.137   #> 2 0.204    0.19      0.01400  0.07154 0.007011 0.08373 0.006814  0.06733 #> 3 0.106    0.03      0.076    0.9296  0.09882  0.3144  0.06558   0.8749  #> 4 0.052    0.106    -0.054   -0.4527  0.04040  0.2010  0.03252  -0.4260  #> 5 0.259   -0.0390    0.298    2.173   0.2041   0.4518  0.02246   2.046   #> 6 0.04200  0.05700  -0.01500 -0.1674  0.03433  0.1853  0.03326  -0.1575  #> 7 0.074    0.004000  0.07     0.4667  0.01685  0.1298  0.008471  0.4393  #> 8 0.03200  0.01500   0.01700  0.1027  0.007729 0.08791 0.007323  0.09663 #>     vg_DID   Wg_DID #>      <dbl>    <dbl> #> 1 0.05833  0.008626 #> 2 0.006989 0.006814 #> 3 0.09502  0.06558  #> 4 0.03950  0.03252  #> 5 0.1834   0.02246  #> 6 0.03421  0.03326  #> 7 0.01589  0.008471 #> 8 0.007682 0.007323"},{"path":"https://mikkelvembye.github.io/VIVECampbell/articles/Entering-data.html","id":"funktion-til-effektstørrelsesberegning-med-mere-end-to-treatment--ogeller-kontrolgrupper","dir":"Articles","previous_headings":"Omsætning af formlerne til beregninger i R","what":"Funktion til effektstørrelsesberegning med mere end to treatment- og/eller kontrolgrupper","title":"Indtastning af data, effektstørrelsesudregning og cluster bias justering, når der kun er clustering i en gruppe","text":"Ovenfor har jeg vist, hvordan man kan beregne effektstørrelser, når der er en treatment gruppe. Nu vil jeg vise, hvordan man brugen funktionskabning til lave de samme beregninger flere treatmentgrupper, der skal sammenlignes med den samme kontrolgruppe, som dette tilfælde vi beskæftiger os med.","code":"treat_label_fisher <- unique(Fisher1996$treatment)[1:2]  fisher_func <- function(label){      Fisher_effects <-    Fisher1996 |>    # Her fjerner jeg den treatment gruppen \"Cognitive\" for at kunne beregne effektstørrelser   # mellem Diasease og kontrol treatment   dplyr::filter(treatment != label) |>    dplyr::summarise(       study = \"Fisher1996\",       treatment = treatment[1],       main_es_method = \"diff-in-diffs\",              #Her regner vi den gennemsnitlige Fishers z-score som angivet i formel (12)       mean_z = sum(w*z)/sum(w),       #Her beregner vi den gennemsnitlige pre-posttest korrelation som angivet i formel (13)        ppcor = (exp(2*mean_z)-1)/(exp(2*mean_z)+1),       # Her dokumneterer jeg, hvor vi har fundet pre-posttest korrelationen        ppcor_calc_method = \"Calculated from study results\",              # Her laver vi variabler, som viser sample størrelser opdelt på treatment- og kontrolgrupperne       N_t = N[1],       N_c = N[2],       # Her laver vi en variabler med den totale samplestørrelse       N_tot = sum(N),              # Her laver vi variablen med antal frihedsgrader, som benyttes hhv. til        # beregne andet led i variansformlerne (3) og (9) samt til at skabe J faktoren       # der bruges til beregne Hedges' g       df_ind = N_tot,              # Her beregnes en pooled standardafvigelse som vist i formel (2)       sd_pool = sqrt(sum((N - 1) * sd_post^2) / df_ind),              # Beregning af tælleren i formler (1), (6) og (7)        # Jeg vender her skalen om, da et fald i scoren på de givne skalaer indikerer en positiv fremgang       m_diff_post = (m_post[1]-m_post[2])*-1,              # Beregning af Cohens' d fra formel (1)       d_post = m_diff_post/sd_pool,       # variansudregning fra formel (3)       vd_post = sum(1/N) + d_post^2/(2*df_ind),       # Her beregnes det variansled, som er angivet i formel (4) og benyttes til        # publikationsbias testning       Wd_post = sum(1/N),              # Beregnig af Hedges' g fra formel (6)       J = 1 - 3/(4*df_ind-1),       g_post = J * d_post,       vg_post = vd_post,       Wg_post = sum(1/N),              # Beregnig af Glass' delta fra formel (7). Vi bruger aldrig denne, så den        # er kun med her for eksemplets skyld       sd_control = sd_post[2],       delta_post = m_diff_post/sd_control,              # Difference-in-differences (DID) effektstørrelsen       # Her beregner jeg den raw pre-posteffekt forskelle for hhv. treatment og       # gruppen.       diff_t = (m_post[1] - m_pre[1])*-1,       diff_c = (m_post[2] - m_pre[2])*-1,              # Her skaber jeg så tælleren fra formel (8)       DD = (diff_t - diff_c),              # Her bergener jeg hele formel (8)       d_DID = (diff_t - diff_c) / sd_pool,       # Her beregner jeg formel (9)       vd_DID = sum(1/N) * (2*(1-ppcor)) + d_DID^2/(2*df_ind),       # Hvis man vil beregne standardfejlen istedet tager man blot kvadratroden af variansen       sed_DID = sqrt(vd_DID),       # Her skabes den variabel som benyttes når vi skal gennemføre publikationsbias tests       Wd_DID = sum(1/N) * (2*(1-ppcor)),              # Her gøres det samme bare hvor vi indregner sample sample bias korrektoreren J       g_DID = J * d_DID,       vg_DID = sum(1/N) * (2*(1-ppcor)) + g_DID^2/(2*df_ind),       Wg_DID = Wd_DID,            # Effektstørrelserne skal beregne indenfor hver setting og outcome,       # Derfor grupperer jeg beregninger således      .by = c(setting, outcome)                  ) |>      relocate(study)    # Her omformer jeg Fisher1996 til et wide format, så det har samme længde, som    # effect størrelsesdatasæt ovenfor   Fisher_raw_dat_wide <-     Fisher1996 |>     filter(treatment %in% c(label, \"TAU\")) |>     mutate(      treatment = if_else(treatment == label, \"t\", \"c\")    ) |>     pivot_wider(      names_from = treatment,       values_from = N:w    ) |>    mutate(     group_t = label,     group_c = \"TAU\"     ) |>    relocate(group_t:group_c, .after = setting)   # Her binder jeg de raw mål sammen med effectstørrelsesudregningerne  left_join(Fisher_raw_dat_wide, Fisher_effects, by = join_by(outcome, setting, N_t, N_c))       }  # Her bruger jeg funktionen til at beregne effekter for begge treatments holdt op imod den # samme kontrol gruppe Fisher1996_es <-    purrr::map(treat_label_fisher, ~ fisher_func(.x)) |>    list_rbind() |>    mutate(     study = \"Fisher (1996)\"   ) |>    relocate(study) |>    arrange(setting, outcome) |>    relocate(setting, .before = outcome)  Fisher1996_es #> # A tibble: 16 × 57 #>    study         setting    outcome     group_t   group_c   N_t   N_c m_pre_t #>    <chr>         <chr>      <chr>       <chr>     <chr>   <dbl> <dbl>   <dbl> #>  1 Fisher (1996) Inpatient  Alcohol use Disease   TAU         6     7   0.469 #>  2 Fisher (1996) Inpatient  Alcohol use Cognitive TAU         6     7   0.441 #>  3 Fisher (1996) Inpatient  Drug use    Disease   TAU         6     7   0.107 #>  4 Fisher (1996) Inpatient  Drug use    Cognitive TAU         6     7   0.116 #>  5 Fisher (1996) Inpatient  Psych func  Disease   TAU         6     7   0.393 #>  6 Fisher (1996) Inpatient  Psych func  Cognitive TAU         6     7   0.498 #>  7 Fisher (1996) Inpatient  Social      Disease   TAU         6     7   0.342 #>  8 Fisher (1996) Inpatient  Social      Cognitive TAU         6     7   0.419 #>  9 Fisher (1996) Outpatient Alcohol use Disease   TAU         6     7   0.725 #> 10 Fisher (1996) Outpatient Alcohol use Cognitive TAU         6     7   0.598 #> 11 Fisher (1996) Outpatient Drug use    Disease   TAU         6     7   0.219 #> 12 Fisher (1996) Outpatient Drug use    Cognitive TAU         6     7   0.2   #> 13 Fisher (1996) Outpatient Psych func  Disease   TAU         6     7   0.464 #> 14 Fisher (1996) Outpatient Psych func  Cognitive TAU         6     7   0.476 #> 15 Fisher (1996) Outpatient Social      Disease   TAU         6     7   0.683 #> 16 Fisher (1996) Outpatient Social      Cognitive TAU         6     7   0.584 #>    m_pre_c sd_pre_t sd_pre_c m_post_t m_post_c sd_post_t sd_post_c m_diff_t #>      <dbl>    <dbl>    <dbl>    <dbl>    <dbl>     <dbl>     <dbl>    <dbl> #>  1   0.349     0.12     0.22    0.07     0.141      0.11      0.21    0.399 #>  2   0.349     0.13     0.22    0.018    0.141      0.05      0.21    0.423 #>  3   0.117     0.09     0.12    0.001    0.087      0.01      0.12    0.106 #>  4   0.117     0.1      0.12    0.008    0.087      0.02      0.12    0.108 #>  5   0.605     0.17     0.15    0.319    0.601      0.14      0.18    0.074 #>  6   0.605     0.13     0.15    0.442    0.601      0.16      0.18    0.056 #>  7   0.45      0.21     0.24    0.083    0.489      0.1       0.18    0.259 #>  8   0.45      0.12     0.24    0.103    0.489      0.1       0.18    0.316 #>  9   0.682     0.11     0.17    0.521    0.492      0.11      0.27    0.204 #> 10   0.682     0.16     0.17    0.152    0.492      0.15      0.27    0.446 #> 11   0.322     0.11     0.05    0.167    0.216      0.1       0.15    0.052 #> 12   0.322     0.12     0.05    0.044    0.216      0.05      0.15    0.196 #> 13   0.487     0.14     0.16    0.432    0.472      0.18      0.18    0.032 #> 14   0.487     0.12     0.16    0.232    0.472      0.07      0.18    0.244 #> 15   0.571     0.04     0.09    0.641    0.514      0.06      0.12    0.042 #> 16   0.571     0.05     0.09    0.233    0.514      0.16      0.12    0.351 #>    m_diff_c sd_diff_t sd_diff_c mean_diff_test_t mean_diff_test_c     r_t    r_c #>       <dbl>     <dbl>     <dbl>            <dbl>            <dbl>   <dbl>  <dbl> #>  1    0.208      0.02      0.04          0.399           0.208    0.9886  0.9838 #>  2    0.208      0.09      0.04          0.423           0.208    0.8692  0.9838 #>  3    0.03       0.09      0.02          0.106           0.03     0.05556 0.9861 #>  4    0.03       0.09      0.02          0.108           0.03     0.5750  0.9861 #>  5    0.004      0.04      0.04          0.074           0.004000 0.9853  0.9870 #>  6    0.004      0.04      0.04          0.056           0.004000 0.9832  0.9870 #>  7   -0.039      0.13      0.07          0.259          -0.0390   0.8857  0.9850 #>  8   -0.039      0.03      0.07          0.316          -0.0390   0.9792  0.9850 #>  9    0.19       0.01      0.11          0.204           0.19     0.9959  0.9771 #> 10    0.19       0.02      0.11          0.446           0.19     0.9938  0.9771 #> 11    0.106      0.02      0.11          0.052           0.106    0.9864  0.86   #> 12    0.106      0.08      0.11          0.156           0.106    0.875   0.86   #> 13    0.015      0.05      0.03          0.03200         0.01500  0.9821  0.9913 #> 14    0.015      0.06      0.03          0.244           0.01500  0.9345  0.9913 #> 15    0.057      0.03      0.04          0.04200         0.05700  0.8958  0.9676 #> 16    0.057      0.12      0.04          0.351           0.05700  0.8562  0.9676 #>        z_t   z_c    v_t   v_c   w_t   w_c treatment main_es_method mean_z  ppcor #>      <dbl> <dbl>  <dbl> <dbl> <dbl> <dbl> <chr>     <chr>           <dbl>  <dbl> #>  1 2.582   2.403 0.3333  0.25     3     4 Cognitive diff-in-diffs   1.943 0.9598 #>  2 1.330   2.403 0.3333  0.25     3     4 Disease   diff-in-diffs   2.480 0.9861 #>  3 0.05561 2.481 0.3333  0.25     3     4 Cognitive diff-in-diffs   1.699 0.9352 #>  4 0.6550  2.481 0.3333  0.25     3     4 Disease   diff-in-diffs   1.442 0.8941 #>  5 2.453   2.516 0.3333  0.25     3     4 Cognitive diff-in-diffs   2.460 0.9855 #>  6 2.385   2.516 0.3333  0.25     3     4 Disease   diff-in-diffs   2.489 0.9863 #>  7 1.402   2.441 0.3333  0.25     3     4 Cognitive diff-in-diffs   2.371 0.9827 #>  8 2.277   2.441 0.3333  0.25     3     4 Disease   diff-in-diffs   1.996 0.9637 #>  9 3.090   2.230 0.3333  0.25     3     4 Cognitive diff-in-diffs   2.509 0.9869 #> 10 2.883   2.230 0.3333  0.25     3     4 Disease   diff-in-diffs   2.598 0.9890 #> 11 2.491   1.293 0.3333  0.25     3     4 Cognitive diff-in-diffs   1.319 0.8666 #> 12 1.354   1.293 0.3333  0.25     3     4 Disease   diff-in-diffs   1.806 0.9475 #> 13 2.355   2.718 0.3333  0.25     3     4 Cognitive diff-in-diffs   2.279 0.9792 #> 14 1.693   2.718 0.3333  0.25     3     4 Disease   diff-in-diffs   2.562 0.9882 #> 15 1.451   2.053 0.3333  0.25     3     4 Cognitive diff-in-diffs   1.721 0.9380 #> 16 1.279   2.053 0.3333  0.25     3     4 Disease   diff-in-diffs   1.795 0.9463 #>    ppcor_calc_method             N_tot df_ind sd_pool m_diff_post  d_post #>    <chr>                         <dbl>  <dbl>   <dbl>       <dbl>   <dbl> #>  1 Calculated from study results    13     13 0.1460      0.123    0.8425 #>  2 Calculated from study results    13     13 0.1581      0.071    0.4490 #>  3 Calculated from study results    13     13 0.08246     0.079    0.9580 #>  4 Calculated from study results    13     13 0.08176     0.086    1.052  #>  5 Calculated from study results    13     13 0.1575      0.159    1.010  #>  6 Calculated from study results    13     13 0.1500      0.282    1.880  #>  7 Calculated from study results    13     13 0.1371      0.386    2.815  #>  8 Calculated from study results    13     13 0.1371      0.406    2.961  #>  9 Calculated from study results    13     13 0.2057      0.34     1.653  #> 10 Calculated from study results    13     13 0.1957     -0.02900 -0.1482 #> 11 Calculated from study results    13     13 0.1065      0.172    1.615  #> 12 Calculated from study results    13     13 0.1193      0.049    0.4108 #> 13 Calculated from study results    13     13 0.1298      0.24     1.850  #> 14 Calculated from study results    13     13 0.1656      0.0400   0.2416 #> 15 Calculated from study results    13     13 0.1284      0.281    2.188  #> 16 Calculated from study results    13     13 0.08961    -0.127   -1.417  #>    vd_post Wd_post      J  g_post vg_post Wg_post sd_control delta_post  diff_t #>      <dbl>   <dbl>  <dbl>   <dbl>   <dbl>   <dbl>      <dbl>      <dbl>   <dbl> #>  1  0.3368  0.3095 0.9412  0.7929  0.3368  0.3095       0.21     0.5857 0.423   #>  2  0.3173  0.3095 0.9412  0.4226  0.3173  0.3095       0.21     0.3381 0.399   #>  3  0.3448  0.3095 0.9412  0.9017  0.3448  0.3095       0.12     0.6583 0.108   #>  4  0.3521  0.3095 0.9412  0.9900  0.3521  0.3095       0.12     0.7167 0.106   #>  5  0.3487  0.3095 0.9412  0.9503  0.3487  0.3095       0.18     0.8833 0.056   #>  6  0.4455  0.3095 0.9412  1.770   0.4455  0.3095       0.18     1.567  0.074   #>  7  0.6143  0.3095 0.9412  2.650   0.6143  0.3095       0.18     2.144  0.316   #>  8  0.6467  0.3095 0.9412  2.787   0.6467  0.3095       0.18     2.256  0.259   #>  9  0.4146  0.3095 0.9412  1.556   0.4146  0.3095       0.27     1.259  0.446   #> 10  0.3104  0.3095 0.9412 -0.1395  0.3104  0.3095       0.27    -0.1074 0.204   #> 11  0.4098  0.3095 0.9412  1.520   0.4098  0.3095       0.15     1.147  0.156   #> 12  0.3160  0.3095 0.9412  0.3866  0.3160  0.3095       0.15     0.3267 0.052   #> 13  0.4411  0.3095 0.9412  1.741   0.4411  0.3095       0.18     1.333  0.244   #> 14  0.3118  0.3095 0.9412  0.2274  0.3118  0.3095       0.18     0.2222 0.03200 #> 15  0.4937  0.3095 0.9412  2.059   0.4937  0.3095       0.12     2.342  0.351   #> 16  0.3868  0.3095 0.9412 -1.334   0.3868  0.3095       0.12    -1.058  0.04200 #>       diff_c       DD    d_DID   vd_DID sed_DID   Wd_DID    g_DID   vg_DID #>        <dbl>    <dbl>    <dbl>    <dbl>   <dbl>    <dbl>    <dbl>    <dbl> #>  1  0.208     0.215    1.473   0.1083   0.3291  0.02490   1.386   0.09879  #>  2  0.208     0.191    1.208   0.06473  0.2544  0.008626  1.137   0.05833  #>  3  0.03      0.078    0.9459  0.07450  0.2729  0.04009   0.8902  0.07057  #>  4  0.03      0.076    0.9296  0.09882  0.3144  0.06558   0.8749  0.09502  #>  5  0.004000  0.052    0.3302  0.01317  0.1148  0.008975  0.3108  0.01269  #>  6  0.004000  0.07     0.4667  0.01685  0.1298  0.008471  0.4393  0.01589  #>  7 -0.0390    0.355    2.589   0.2685   0.5182  0.01071   2.437   0.2391   #>  8 -0.0390    0.298    2.173   0.2041   0.4518  0.02246   2.046   0.1834   #>  9  0.19      0.256    1.245   0.06772  0.2602  0.008132  1.171   0.06092  #> 10  0.19      0.01400  0.07154 0.007011 0.08373 0.006814  0.06733 0.006989 #> 11  0.106     0.05     0.4694  0.09104  0.3017  0.08257   0.4418  0.09007  #> 12  0.106    -0.054   -0.4527  0.04040  0.2010  0.03252  -0.4260  0.03950  #> 13  0.01500   0.229    1.765   0.1326   0.3642  0.01286   1.661   0.1190   #> 14  0.01500   0.01700  0.1027  0.007729 0.08791 0.007323  0.09663 0.007682 #> 15  0.05700   0.294    2.289   0.2399   0.4898  0.03836   2.155   0.2169   #> 16  0.05700  -0.01500 -0.1674  0.03433  0.1853  0.03326  -0.1575  0.03421  #>      Wg_DID #>       <dbl> #>  1 0.02490  #>  2 0.008626 #>  3 0.04009  #>  4 0.06558  #>  5 0.008975 #>  6 0.008471 #>  7 0.01071  #>  8 0.02246  #>  9 0.008132 #> 10 0.006814 #> 11 0.08257  #> 12 0.03252  #> 13 0.01286  #> 14 0.007323 #> 15 0.03836  #> 16 0.03326"},{"path":"https://mikkelvembye.github.io/VIVECampbell/articles/Entering-data.html","id":"cluster-bias-korrektion-når-der-kun-er-klustering-i-en-gruppe","dir":"Articles","previous_headings":"Omsætning af formlerne til beregninger i R","what":"Cluster bias korrektion når der kun er klustering i en gruppe","title":"Indtastning af data, effektstørrelsesudregning og cluster bias justering, når der kun er clustering i en gruppe","text":"gtDID=ω(MpostT−MpostCSDpool)γ\\begin{equation}   \\tag{15}    gt_{} = \\omega\\left(\\frac{M^T_{post} - M^C_{post}}{SD_{pool}}\\right)\\gamma \\end{equation} hvor ω=1−3/(4−dfh−1)\\omega = 1 - 3/(4-df_h-1), hvor dfhdf_h er de klusterjusterede frihedsgrader, som beregnes således når der kun er klustering en gruppe h=[(N−2)−2(n−1)ρ]2(N−2)(1−ρ)2+n(N−2n)ρ2+2(N−2n)ρ(1−ρ)\\begin{equation}   \\tag{16}    h = \\dfrac{[(N-2)-2(n-1)\\rho]^2}{(N-2)(1-\\rho)^2 + n(N-2n)\\rho^2 + 2(N-2n)\\rho(1-\\rho)} \\end{equation} formel 14 er γ=1−(Nc+n−2)ρICC\\gamma = \\sqrt{1-\\frac{(N^c +n-2)\\rho_{ICC}}{}}","code":"# Imputerede ICC-værdier icc_005 <- 0.05 # Bruges til sensitivitetsanalyse icc_01 <- 0.1 icc_02 <- 0.2 # Bruges til sensitivitetsanalyse  Fisher1996_est <-    Fisher1996_es |>    rowwise() |>    # klusterkorrigering   mutate(          # Gruppestørrelsen kan ikke findes i Fisher 1996, så her imputerer vi blot den      # gennemsnitlige gruppestørrelse for eksemplet skyld     n_group = 5,     # Laver variabel med den imputere ICC værdi     icc = icc_01,     # Laver variabel som dokumenterer hvor vi fandt ICC-værdieen     icc_type = \"Imputed\",          gamma_sqrt = VIVECampbell::gamma_1armcluster(       N_total = N_tot, Nc = N_c, avg_grp_size = n_group, ICC = icc, sqrt = TRUE     ),      gamma_sqrt_test = sqrt(1 - (N_c + n_group-2)*icc/(N_tot-2)),           h = df_h_1armcluster(N_total = N_tot, ICC = icc, N_grp = N_t, avg_grp_size = n_group),     omega = 1 - 3/(4*h-1),            gt_post = omega * d_post * gamma_sqrt,     VIVECampbell::vgt_smd_1armcluster(       N_cl_grp = N_t,        N_ind_grp = N_c,        avg_grp_size = n_group,       ICC = icc,        g = gt_post,        model = \"posttest\",       add_name_to_vars = \"_post\",       vars = c(vgt_post, Wgt_post)     ),          gt_DID = omega * d_DID * gamma_sqrt,     VIVECampbell::vgt_smd_1armcluster(       N_cl_grp = N_t,        N_ind_grp = N_c,        avg_grp_size = n_group,       ICC = icc,        g = gt_DID,        model = \"DiD\",       prepost_cor = ppcor,       add_name_to_vars = \"_DID\",       vars = -var_term1_DID     ),          # Disse variabler skabes til at lave sensitivitetsanalyser          # Her antager vi at ICC = 0.05     gamma_sqrt_005 = VIVECampbell::gamma_1armcluster(       N_total = N_tot, Nc = N_c, avg_grp_size = n_group, ICC = icc_005, sqrt = TRUE     ),      h_005 = df_h_1armcluster(N_total = N_tot, ICC = icc_005, N_grp = N_t, avg_grp_size = n_group),     omega_005 = 1 - 3/(4*h_005-1),          gt_DID_005 = omega_005 * d_DID * gamma_sqrt_005,     VIVECampbell::vgt_smd_1armcluster(       N_cl_grp = N_t,        N_ind_grp = N_c,        avg_grp_size = n_group,       ICC = icc_005, # Husk at ændre denne       g = gt_DID_005, #Husk at ændre denne       model = \"DiD\",       prepost_cor = ppcor,       add_name_to_vars = \"_DID_005\",       vars = c(vgt_DID_005, Wgt_DID_005)     ),          # Her antager vi at ICC = 0.2     gamma_sqrt_02 = VIVECampbell::gamma_1armcluster(       N_total = N_tot, Nc = N_c, avg_grp_size = n_group, ICC = icc_02, sqrt = TRUE     ),      h_02 = df_h_1armcluster(N_total = N_tot, ICC = icc_02, N_grp = N_t, avg_grp_size = n_group),     omega_02 = 1 - 3/(4*h_02-1),          gt_DID_02 = omega_02 * d_DID * gamma_sqrt_02,     VIVECampbell::vgt_smd_1armcluster(       N_cl_grp = N_t,        N_ind_grp = N_c,        avg_grp_size = n_group,       ICC = icc_02,        g = gt_DID_02,        model = \"DiD\",       prepost_cor = ppcor,       add_name_to_vars = \"_DID_02\",       vars = c(vgt_DID_02, Wgt_DID_02)     ),          vary_id = paste(setting, outcome, treatment, sep = \"/\")   ) |>    ungroup()  Fisher1996_est #> # A tibble: 16 × 90 #>    study         setting    outcome     group_t   group_c   N_t   N_c m_pre_t #>    <chr>         <chr>      <chr>       <chr>     <chr>   <dbl> <dbl>   <dbl> #>  1 Fisher (1996) Inpatient  Alcohol use Disease   TAU         6     7   0.469 #>  2 Fisher (1996) Inpatient  Alcohol use Cognitive TAU         6     7   0.441 #>  3 Fisher (1996) Inpatient  Drug use    Disease   TAU         6     7   0.107 #>  4 Fisher (1996) Inpatient  Drug use    Cognitive TAU         6     7   0.116 #>  5 Fisher (1996) Inpatient  Psych func  Disease   TAU         6     7   0.393 #>  6 Fisher (1996) Inpatient  Psych func  Cognitive TAU         6     7   0.498 #>  7 Fisher (1996) Inpatient  Social      Disease   TAU         6     7   0.342 #>  8 Fisher (1996) Inpatient  Social      Cognitive TAU         6     7   0.419 #>  9 Fisher (1996) Outpatient Alcohol use Disease   TAU         6     7   0.725 #> 10 Fisher (1996) Outpatient Alcohol use Cognitive TAU         6     7   0.598 #> 11 Fisher (1996) Outpatient Drug use    Disease   TAU         6     7   0.219 #> 12 Fisher (1996) Outpatient Drug use    Cognitive TAU         6     7   0.2   #> 13 Fisher (1996) Outpatient Psych func  Disease   TAU         6     7   0.464 #> 14 Fisher (1996) Outpatient Psych func  Cognitive TAU         6     7   0.476 #> 15 Fisher (1996) Outpatient Social      Disease   TAU         6     7   0.683 #> 16 Fisher (1996) Outpatient Social      Cognitive TAU         6     7   0.584 #>    m_pre_c sd_pre_t sd_pre_c m_post_t m_post_c sd_post_t sd_post_c m_diff_t #>      <dbl>    <dbl>    <dbl>    <dbl>    <dbl>     <dbl>     <dbl>    <dbl> #>  1   0.349     0.12     0.22    0.07     0.141      0.11      0.21    0.399 #>  2   0.349     0.13     0.22    0.018    0.141      0.05      0.21    0.423 #>  3   0.117     0.09     0.12    0.001    0.087      0.01      0.12    0.106 #>  4   0.117     0.1      0.12    0.008    0.087      0.02      0.12    0.108 #>  5   0.605     0.17     0.15    0.319    0.601      0.14      0.18    0.074 #>  6   0.605     0.13     0.15    0.442    0.601      0.16      0.18    0.056 #>  7   0.45      0.21     0.24    0.083    0.489      0.1       0.18    0.259 #>  8   0.45      0.12     0.24    0.103    0.489      0.1       0.18    0.316 #>  9   0.682     0.11     0.17    0.521    0.492      0.11      0.27    0.204 #> 10   0.682     0.16     0.17    0.152    0.492      0.15      0.27    0.446 #> 11   0.322     0.11     0.05    0.167    0.216      0.1       0.15    0.052 #> 12   0.322     0.12     0.05    0.044    0.216      0.05      0.15    0.196 #> 13   0.487     0.14     0.16    0.432    0.472      0.18      0.18    0.032 #> 14   0.487     0.12     0.16    0.232    0.472      0.07      0.18    0.244 #> 15   0.571     0.04     0.09    0.641    0.514      0.06      0.12    0.042 #> 16   0.571     0.05     0.09    0.233    0.514      0.16      0.12    0.351 #>    m_diff_c sd_diff_t sd_diff_c mean_diff_test_t mean_diff_test_c     r_t    r_c #>       <dbl>     <dbl>     <dbl>            <dbl>            <dbl>   <dbl>  <dbl> #>  1    0.208      0.02      0.04          0.399           0.208    0.9886  0.9838 #>  2    0.208      0.09      0.04          0.423           0.208    0.8692  0.9838 #>  3    0.03       0.09      0.02          0.106           0.03     0.05556 0.9861 #>  4    0.03       0.09      0.02          0.108           0.03     0.5750  0.9861 #>  5    0.004      0.04      0.04          0.074           0.004000 0.9853  0.9870 #>  6    0.004      0.04      0.04          0.056           0.004000 0.9832  0.9870 #>  7   -0.039      0.13      0.07          0.259          -0.0390   0.8857  0.9850 #>  8   -0.039      0.03      0.07          0.316          -0.0390   0.9792  0.9850 #>  9    0.19       0.01      0.11          0.204           0.19     0.9959  0.9771 #> 10    0.19       0.02      0.11          0.446           0.19     0.9938  0.9771 #> 11    0.106      0.02      0.11          0.052           0.106    0.9864  0.86   #> 12    0.106      0.08      0.11          0.156           0.106    0.875   0.86   #> 13    0.015      0.05      0.03          0.03200         0.01500  0.9821  0.9913 #> 14    0.015      0.06      0.03          0.244           0.01500  0.9345  0.9913 #> 15    0.057      0.03      0.04          0.04200         0.05700  0.8958  0.9676 #> 16    0.057      0.12      0.04          0.351           0.05700  0.8562  0.9676 #>        z_t   z_c    v_t   v_c   w_t   w_c treatment main_es_method mean_z  ppcor #>      <dbl> <dbl>  <dbl> <dbl> <dbl> <dbl> <chr>     <chr>           <dbl>  <dbl> #>  1 2.582   2.403 0.3333  0.25     3     4 Cognitive diff-in-diffs   1.943 0.9598 #>  2 1.330   2.403 0.3333  0.25     3     4 Disease   diff-in-diffs   2.480 0.9861 #>  3 0.05561 2.481 0.3333  0.25     3     4 Cognitive diff-in-diffs   1.699 0.9352 #>  4 0.6550  2.481 0.3333  0.25     3     4 Disease   diff-in-diffs   1.442 0.8941 #>  5 2.453   2.516 0.3333  0.25     3     4 Cognitive diff-in-diffs   2.460 0.9855 #>  6 2.385   2.516 0.3333  0.25     3     4 Disease   diff-in-diffs   2.489 0.9863 #>  7 1.402   2.441 0.3333  0.25     3     4 Cognitive diff-in-diffs   2.371 0.9827 #>  8 2.277   2.441 0.3333  0.25     3     4 Disease   diff-in-diffs   1.996 0.9637 #>  9 3.090   2.230 0.3333  0.25     3     4 Cognitive diff-in-diffs   2.509 0.9869 #> 10 2.883   2.230 0.3333  0.25     3     4 Disease   diff-in-diffs   2.598 0.9890 #> 11 2.491   1.293 0.3333  0.25     3     4 Cognitive diff-in-diffs   1.319 0.8666 #> 12 1.354   1.293 0.3333  0.25     3     4 Disease   diff-in-diffs   1.806 0.9475 #> 13 2.355   2.718 0.3333  0.25     3     4 Cognitive diff-in-diffs   2.279 0.9792 #> 14 1.693   2.718 0.3333  0.25     3     4 Disease   diff-in-diffs   2.562 0.9882 #> 15 1.451   2.053 0.3333  0.25     3     4 Cognitive diff-in-diffs   1.721 0.9380 #> 16 1.279   2.053 0.3333  0.25     3     4 Disease   diff-in-diffs   1.795 0.9463 #>    ppcor_calc_method             N_tot df_ind sd_pool m_diff_post  d_post #>    <chr>                         <dbl>  <dbl>   <dbl>       <dbl>   <dbl> #>  1 Calculated from study results    13     13 0.1460      0.123    0.8425 #>  2 Calculated from study results    13     13 0.1581      0.071    0.4490 #>  3 Calculated from study results    13     13 0.08246     0.079    0.9580 #>  4 Calculated from study results    13     13 0.08176     0.086    1.052  #>  5 Calculated from study results    13     13 0.1575      0.159    1.010  #>  6 Calculated from study results    13     13 0.1500      0.282    1.880  #>  7 Calculated from study results    13     13 0.1371      0.386    2.815  #>  8 Calculated from study results    13     13 0.1371      0.406    2.961  #>  9 Calculated from study results    13     13 0.2057      0.34     1.653  #> 10 Calculated from study results    13     13 0.1957     -0.02900 -0.1482 #> 11 Calculated from study results    13     13 0.1065      0.172    1.615  #> 12 Calculated from study results    13     13 0.1193      0.049    0.4108 #> 13 Calculated from study results    13     13 0.1298      0.24     1.850  #> 14 Calculated from study results    13     13 0.1656      0.0400   0.2416 #> 15 Calculated from study results    13     13 0.1284      0.281    2.188  #> 16 Calculated from study results    13     13 0.08961    -0.127   -1.417  #>    vd_post Wd_post      J  g_post vg_post Wg_post sd_control delta_post  diff_t #>      <dbl>   <dbl>  <dbl>   <dbl>   <dbl>   <dbl>      <dbl>      <dbl>   <dbl> #>  1  0.3368  0.3095 0.9412  0.7929  0.3368  0.3095       0.21     0.5857 0.423   #>  2  0.3173  0.3095 0.9412  0.4226  0.3173  0.3095       0.21     0.3381 0.399   #>  3  0.3448  0.3095 0.9412  0.9017  0.3448  0.3095       0.12     0.6583 0.108   #>  4  0.3521  0.3095 0.9412  0.9900  0.3521  0.3095       0.12     0.7167 0.106   #>  5  0.3487  0.3095 0.9412  0.9503  0.3487  0.3095       0.18     0.8833 0.056   #>  6  0.4455  0.3095 0.9412  1.770   0.4455  0.3095       0.18     1.567  0.074   #>  7  0.6143  0.3095 0.9412  2.650   0.6143  0.3095       0.18     2.144  0.316   #>  8  0.6467  0.3095 0.9412  2.787   0.6467  0.3095       0.18     2.256  0.259   #>  9  0.4146  0.3095 0.9412  1.556   0.4146  0.3095       0.27     1.259  0.446   #> 10  0.3104  0.3095 0.9412 -0.1395  0.3104  0.3095       0.27    -0.1074 0.204   #> 11  0.4098  0.3095 0.9412  1.520   0.4098  0.3095       0.15     1.147  0.156   #> 12  0.3160  0.3095 0.9412  0.3866  0.3160  0.3095       0.15     0.3267 0.052   #> 13  0.4411  0.3095 0.9412  1.741   0.4411  0.3095       0.18     1.333  0.244   #> 14  0.3118  0.3095 0.9412  0.2274  0.3118  0.3095       0.18     0.2222 0.03200 #> 15  0.4937  0.3095 0.9412  2.059   0.4937  0.3095       0.12     2.342  0.351   #> 16  0.3868  0.3095 0.9412 -1.334   0.3868  0.3095       0.12    -1.058  0.04200 #>       diff_c       DD    d_DID   vd_DID sed_DID   Wd_DID    g_DID   vg_DID #>        <dbl>    <dbl>    <dbl>    <dbl>   <dbl>    <dbl>    <dbl>    <dbl> #>  1  0.208     0.215    1.473   0.1083   0.3291  0.02490   1.386   0.09879  #>  2  0.208     0.191    1.208   0.06473  0.2544  0.008626  1.137   0.05833  #>  3  0.03      0.078    0.9459  0.07450  0.2729  0.04009   0.8902  0.07057  #>  4  0.03      0.076    0.9296  0.09882  0.3144  0.06558   0.8749  0.09502  #>  5  0.004000  0.052    0.3302  0.01317  0.1148  0.008975  0.3108  0.01269  #>  6  0.004000  0.07     0.4667  0.01685  0.1298  0.008471  0.4393  0.01589  #>  7 -0.0390    0.355    2.589   0.2685   0.5182  0.01071   2.437   0.2391   #>  8 -0.0390    0.298    2.173   0.2041   0.4518  0.02246   2.046   0.1834   #>  9  0.19      0.256    1.245   0.06772  0.2602  0.008132  1.171   0.06092  #> 10  0.19      0.01400  0.07154 0.007011 0.08373 0.006814  0.06733 0.006989 #> 11  0.106     0.05     0.4694  0.09104  0.3017  0.08257   0.4418  0.09007  #> 12  0.106    -0.054   -0.4527  0.04040  0.2010  0.03252  -0.4260  0.03950  #> 13  0.01500   0.229    1.765   0.1326   0.3642  0.01286   1.661   0.1190   #> 14  0.01500   0.01700  0.1027  0.007729 0.08791 0.007323  0.09663 0.007682 #> 15  0.05700   0.294    2.289   0.2399   0.4898  0.03836   2.155   0.2169   #> 16  0.05700  -0.01500 -0.1674  0.03433  0.1853  0.03326  -0.1575  0.03421  #>      Wg_DID n_group   icc icc_type gamma_sqrt gamma_sqrt_test     h  omega #>       <dbl>   <dbl> <dbl> <chr>         <dbl>           <dbl> <dbl>  <dbl> #>  1 0.02490        5   0.1 Imputed       0.953          0.9535 10.94 0.9298 #>  2 0.008626       5   0.1 Imputed       0.953          0.9535 10.94 0.9298 #>  3 0.04009        5   0.1 Imputed       0.953          0.9535 10.94 0.9298 #>  4 0.06558        5   0.1 Imputed       0.953          0.9535 10.94 0.9298 #>  5 0.008975       5   0.1 Imputed       0.953          0.9535 10.94 0.9298 #>  6 0.008471       5   0.1 Imputed       0.953          0.9535 10.94 0.9298 #>  7 0.01071        5   0.1 Imputed       0.953          0.9535 10.94 0.9298 #>  8 0.02246        5   0.1 Imputed       0.953          0.9535 10.94 0.9298 #>  9 0.008132       5   0.1 Imputed       0.953          0.9535 10.94 0.9298 #> 10 0.006814       5   0.1 Imputed       0.953          0.9535 10.94 0.9298 #> 11 0.08257        5   0.1 Imputed       0.953          0.9535 10.94 0.9298 #> 12 0.03252        5   0.1 Imputed       0.953          0.9535 10.94 0.9298 #> 13 0.01286        5   0.1 Imputed       0.953          0.9535 10.94 0.9298 #> 14 0.007323       5   0.1 Imputed       0.953          0.9535 10.94 0.9298 #> 15 0.03836        5   0.1 Imputed       0.953          0.9535 10.94 0.9298 #> 16 0.03326        5   0.1 Imputed       0.953          0.9535 10.94 0.9298 #>    gt_post vgt_post Wgt_post   gt_DID  vgt_DID  Wgt_DID  hg_DID vhg_DID h_DID #>      <dbl>    <dbl>    <dbl>    <dbl>    <dbl>    <dbl>   <dbl>   <dbl> <dbl> #>  1  0.7466   0.3873   0.3618  1.305   0.1069   0.02911   1.792  0.09141 10.94 #>  2  0.3979   0.3691   0.3618  1.070   0.06244  0.01008   2.209  0.09141 10.94 #>  3  0.8489   0.3948   0.3618  0.8382  0.07897  0.04686   1.067  0.09141 10.94 #>  4  0.9321   0.4015   0.3618  0.8237  0.1077   0.07667   0.8477 0.09141 10.94 #>  5  0.8947   0.3984   0.3618  0.2926  0.01440  0.01049   0.8174 0.09141 10.94 #>  6  1.666    0.4887   0.3618  0.4136  0.01772  0.009902  1.132  0.09141 10.94 #>  7  2.495    0.6463   0.3618  2.294   0.2531   0.01252   3.088  0.09141 10.94 #>  8  2.624    0.6765   0.3618  1.926   0.1958   0.02626   2.351  0.09141 10.94 #>  9  1.465    0.4599   0.3618  1.103   0.06511  0.009506  2.286  0.09141 10.94 #> 10 -0.1313   0.3626   0.3618  0.06339 0.008150 0.007966  0.2139 0.09141 10.94 #> 11  1.431    0.4554   0.3618  0.4160  0.1044   0.09652   0.3995 0.09141 10.94 #> 12  0.3640   0.3679   0.3618 -0.4011  0.04537  0.03801  -0.6035 0.09141 10.94 #> 13  1.639    0.4846   0.3618  1.564   0.1268   0.01503   2.444  0.09141 10.94 #> 14  0.2141   0.3639   0.3618  0.09098 0.008939 0.008561  0.2951 0.09141 10.94 #> 15  1.939    0.5337   0.3618  2.029   0.2329   0.04485   2.072  0.09141 10.94 #> 16 -1.256    0.4339   0.3618 -0.1483  0.03988  0.03888  -0.2265 0.09141 10.94 #>    df_DID n_covariates_DID adj_fct_DID adj_value_DID gamma_sqrt_005 h_005 #>     <dbl>            <dbl> <chr>               <dbl>          <dbl> <dbl> #>  1  10.94                1 eta                 1.169          0.977 10.99 #>  2  10.94                1 eta                 1.169          0.977 10.99 #>  3  10.94                1 eta                 1.169          0.977 10.99 #>  4  10.94                1 eta                 1.169          0.977 10.99 #>  5  10.94                1 eta                 1.169          0.977 10.99 #>  6  10.94                1 eta                 1.169          0.977 10.99 #>  7  10.94                1 eta                 1.169          0.977 10.99 #>  8  10.94                1 eta                 1.169          0.977 10.99 #>  9  10.94                1 eta                 1.169          0.977 10.99 #> 10  10.94                1 eta                 1.169          0.977 10.99 #> 11  10.94                1 eta                 1.169          0.977 10.99 #> 12  10.94                1 eta                 1.169          0.977 10.99 #> 13  10.94                1 eta                 1.169          0.977 10.99 #> 14  10.94                1 eta                 1.169          0.977 10.99 #> 15  10.94                1 eta                 1.169          0.977 10.99 #> 16  10.94                1 eta                 1.169          0.977 10.99 #>    omega_005 gt_DID_005 vgt_DID_005 Wgt_DID_005 gamma_sqrt_02  h_02 omega_02 #>        <dbl>      <dbl>       <dbl>       <dbl>         <dbl> <dbl>    <dbl> #>  1    0.9302    1.338      0.1085      0.02702          0.905 10.71   0.9283 #>  2    0.9302    1.098      0.06417     0.009359         0.905 10.71   0.9283 #>  3    0.9302    0.8596     0.07711     0.04350          0.905 10.71   0.9283 #>  4    0.9302    0.8448     0.1036      0.07116          0.905 10.71   0.9283 #>  5    0.9302    0.3001     0.01383     0.009737         0.905 10.71   0.9283 #>  6    0.9302    0.4242     0.01738     0.009191         0.905 10.71   0.9283 #>  7    0.9302    2.353      0.2635      0.01162          0.905 10.71   0.9283 #>  8    0.9302    1.975      0.2019      0.02437          0.905 10.71   0.9283 #>  9    0.9302    1.131      0.06704     0.008823         0.905 10.71   0.9283 #> 10    0.9302    0.06501    0.007586    0.007394         0.905 10.71   0.9283 #> 11    0.9302    0.4266     0.09786     0.08959          0.905 10.71   0.9283 #> 12    0.9302   -0.4114     0.04298     0.03528          0.905 10.71   0.9283 #> 13    0.9302    1.604      0.1310      0.01395          0.905 10.71   0.9283 #> 14    0.9302    0.09331    0.008342    0.007946         0.905 10.71   0.9283 #> 15    0.9302    2.080      0.2385      0.04162          0.905 10.71   0.9283 #> 16    0.9302   -0.1521     0.03714     0.03608          0.905 10.71   0.9283 #>    gt_DID_02 vgt_DID_02 Wgt_DID_02 vary_id                          #>        <dbl>      <dbl>      <dbl> <chr>                            #>  1   1.237     0.1048     0.03332  Inpatient/Alcohol use/Cognitive  #>  2   1.015     0.05961    0.01154  Inpatient/Alcohol use/Disease    #>  3   0.7947    0.08312    0.05364  Inpatient/Drug use/Cognitive     #>  4   0.7809    0.1162     0.08775  Inpatient/Drug use/Disease       #>  5   0.2774    0.01560    0.01201  Inpatient/Psych func/Cognitive   #>  6   0.3921    0.01851    0.01133  Inpatient/Psych func/Disease     #>  7   2.175     0.2352     0.01433  Inpatient/Social/Cognitive       #>  8   1.826     0.1857     0.03005  Inpatient/Social/Disease         #>  9   1.046     0.06193    0.01088  Outpatient/Alcohol use/Cognitive #> 10   0.06010   0.009286   0.009118 Outpatient/Alcohol use/Disease   #> 11   0.3943    0.1177     0.1105   Outpatient/Drug use/Cognitive    #> 12  -0.3803    0.05026    0.04351  Outpatient/Drug use/Disease      #> 13   1.483     0.1198     0.01720  Outpatient/Psych func/Cognitive  #> 14   0.08626   0.01015    0.009798 Outpatient/Psych func/Disease    #> 15   1.923     0.2240     0.05133  Outpatient/Social/Cognitive      #> 16  -0.1406    0.04542    0.04450  Outpatient/Social/Disease"},{"path":"https://mikkelvembye.github.io/VIVECampbell/articles/Entering-data.html","id":"konstruktion-af-varians-covarians-matrix-når-man-har-mere-end-en-treatment-ogeller-kontrol-gruppe","dir":"Articles","previous_headings":"Omsætning af formlerne til beregninger i R","what":"Konstruktion af varians-covarians matrix når man har mere end en treatment (og/eller kontrol) gruppe","title":"Indtastning af data, effektstørrelsesudregning og cluster bias justering, når der kun er clustering i en gruppe","text":"","code":"V_dat_test <-    Fisher1996_es |>    #dplyr::filter(setting == \"Inpatient\") |>    metafor::escalc(measure=\"SMD\", yi = g_DID, vi = vg_DID, data = _) |>    mutate(esid = 1:n())  V_vcalc <-    metafor::vcalc(     data = V_dat_test,     vi = vi,      cluster = study,     subgroup = setting,     obs = outcome,      grp1 = group_t,     w1 = N_t,      grp2 = group_c,     w2 = N_c,     rho = 0.7,      sparse = TRUE   )  V_vcalc |> as.matrix() |> as.data.frame() #>            V1          V2         V3         V4          V5          V6 #> 1  0.09878727 0.035034135 0.05844718 0.03130179 0.024783717 0.012801364 #> 2  0.03503413 0.058326513 0.02072784 0.05211272 0.008789352 0.021312326 #> 3  0.05844718 0.020727838 0.07057162 0.03779511 0.020947442 0.010819839 #> 4  0.03130179 0.052112719 0.03779511 0.09502226 0.011218545 0.027202607 #> 5  0.02478372 0.008789352 0.02094744 0.01121854 0.012689246 0.006554289 #> 6  0.01280136 0.021312326 0.01081984 0.02720261 0.006554289 0.015892771 #> 7  0.10758047 0.038152575 0.09092808 0.04869715 0.038556789 0.019915475 #> 8  0.04348578 0.072397216 0.03675461 0.09240629 0.015585282 0.037791025 #> 9  0.00000000 0.000000000 0.00000000 0.00000000 0.000000000 0.000000000 #> 10 0.00000000 0.000000000 0.00000000 0.00000000 0.000000000 0.000000000 #> 11 0.00000000 0.000000000 0.00000000 0.00000000 0.000000000 0.000000000 #> 12 0.00000000 0.000000000 0.00000000 0.00000000 0.000000000 0.000000000 #> 13 0.00000000 0.000000000 0.00000000 0.00000000 0.000000000 0.000000000 #> 14 0.00000000 0.000000000 0.00000000 0.00000000 0.000000000 0.000000000 #> 15 0.00000000 0.000000000 0.00000000 0.00000000 0.000000000 0.000000000 #> 16 0.00000000 0.000000000 0.00000000 0.00000000 0.000000000 0.000000000 #>            V7         V8          V9         V10         V11        V12 #> 1  0.10758047 0.04348578 0.000000000 0.000000000 0.000000000 0.00000000 #> 2  0.03815258 0.07239722 0.000000000 0.000000000 0.000000000 0.00000000 #> 3  0.09092808 0.03675461 0.000000000 0.000000000 0.000000000 0.00000000 #> 4  0.04869715 0.09240629 0.000000000 0.000000000 0.000000000 0.00000000 #> 5  0.03855679 0.01558528 0.000000000 0.000000000 0.000000000 0.00000000 #> 6  0.01991547 0.03779103 0.000000000 0.000000000 0.000000000 0.00000000 #> 7  0.23909463 0.09664594 0.000000000 0.000000000 0.000000000 0.00000000 #> 8  0.09664594 0.18339253 0.000000000 0.000000000 0.000000000 0.00000000 #> 9  0.00000000 0.00000000 0.060916367 0.009523074 0.051851916 0.01584747 #> 10 0.00000000 0.00000000 0.009523074 0.006988831 0.008106026 0.01163020 #> 11 0.00000000 0.00000000 0.051851916 0.008106026 0.090074018 0.02752927 #> 12 0.00000000 0.00000000 0.015847470 0.011630203 0.027529268 0.03949790 #> 13 0.00000000 0.00000000 0.059589219 0.009315601 0.072460356 0.02214601 #> 14 0.00000000 0.00000000 0.006989072 0.005129168 0.008498696 0.01219359 #> 15 0.00000000 0.00000000 0.080466733 0.012579389 0.097847366 0.02990503 #> 16 0.00000000 0.00000000 0.014748754 0.010823874 0.017934451 0.02573164 #>            V13         V14        V15        V16 #> 1  0.000000000 0.000000000 0.00000000 0.00000000 #> 2  0.000000000 0.000000000 0.00000000 0.00000000 #> 3  0.000000000 0.000000000 0.00000000 0.00000000 #> 4  0.000000000 0.000000000 0.00000000 0.00000000 #> 5  0.000000000 0.000000000 0.00000000 0.00000000 #> 6  0.000000000 0.000000000 0.00000000 0.00000000 #> 7  0.000000000 0.000000000 0.00000000 0.00000000 #> 8  0.000000000 0.000000000 0.00000000 0.00000000 #> 9  0.059589219 0.006989072 0.08046673 0.01474875 #> 10 0.009315601 0.005129168 0.01257939 0.01082387 #> 11 0.072460356 0.008498696 0.09784737 0.01793445 #> 12 0.022146015 0.012193591 0.02990503 0.02573164 #> 13 0.118961192 0.013952664 0.11244808 0.02061062 #> 14 0.013952664 0.007682334 0.01318876 0.01134820 #> 15 0.112448075 0.013188757 0.21692153 0.03975956 #> 16 0.020610617 0.011348201 0.03975956 0.03421092 V_vcalc |> cov2cor() #> 16 x 16 sparse Matrix of class \"dsCMatrix\" #>                                                                             #>  [1,] 1.0000000 0.4615385 0.7000000 0.3230769 0.7000000 0.3230769 0.7000000 #>  [2,] 0.4615385 1.0000000 0.3230769 0.7000000 0.3230769 0.7000000 0.3230769 #>  [3,] 0.7000000 0.3230769 1.0000000 0.4615385 0.7000000 0.3230769 0.7000000 #>  [4,] 0.3230769 0.7000000 0.4615385 1.0000000 0.3230769 0.7000000 0.3230769 #>  [5,] 0.7000000 0.3230769 0.7000000 0.3230769 1.0000000 0.4615385 0.7000000 #>  [6,] 0.3230769 0.7000000 0.3230769 0.7000000 0.4615385 1.0000000 0.3230769 #>  [7,] 0.7000000 0.3230769 0.7000000 0.3230769 0.7000000 0.3230769 1.0000000 #>  [8,] 0.3230769 0.7000000 0.3230769 0.7000000 0.3230769 0.7000000 0.4615385 #>  [9,] .         .         .         .         .         .         .         #> [10,] .         .         .         .         .         .         .         #> [11,] .         .         .         .         .         .         .         #> [12,] .         .         .         .         .         .         .         #> [13,] .         .         .         .         .         .         .         #> [14,] .         .         .         .         .         .         .         #> [15,] .         .         .         .         .         .         .         #> [16,] .         .         .         .         .         .         .         #>                                                                             #>  [1,] 0.3230769 .         .         .         .         .         .         #>  [2,] 0.7000000 .         .         .         .         .         .         #>  [3,] 0.3230769 .         .         .         .         .         .         #>  [4,] 0.7000000 .         .         .         .         .         .         #>  [5,] 0.3230769 .         .         .         .         .         .         #>  [6,] 0.7000000 .         .         .         .         .         .         #>  [7,] 0.4615385 .         .         .         .         .         .         #>  [8,] 1.0000000 .         .         .         .         .         .         #>  [9,] .         1.0000000 0.4615385 0.7000000 0.3230769 0.7000000 0.3230769 #> [10,] .         0.4615385 1.0000000 0.3230769 0.7000000 0.3230769 0.7000000 #> [11,] .         0.7000000 0.3230769 1.0000000 0.4615385 0.7000000 0.3230769 #> [12,] .         0.3230769 0.7000000 0.4615385 1.0000000 0.3230769 0.7000000 #> [13,] .         0.7000000 0.3230769 0.7000000 0.3230769 1.0000000 0.4615385 #> [14,] .         0.3230769 0.7000000 0.3230769 0.7000000 0.4615385 1.0000000 #> [15,] .         0.7000000 0.3230769 0.7000000 0.3230769 0.7000000 0.3230769 #> [16,] .         0.3230769 0.7000000 0.3230769 0.7000000 0.3230769 0.7000000 #>                           #>  [1,] .         .         #>  [2,] .         .         #>  [3,] .         .         #>  [4,] .         .         #>  [5,] .         .         #>  [6,] .         .         #>  [7,] .         .         #>  [8,] .         .         #>  [9,] 0.7000000 0.3230769 #> [10,] 0.3230769 0.7000000 #> [11,] 0.7000000 0.3230769 #> [12,] 0.3230769 0.7000000 #> [13,] 0.7000000 0.3230769 #> [14,] 0.3230769 0.7000000 #> [15,] 1.0000000 0.4615385 #> [16,] 0.4615385 1.0000000    # Assuming constant correlation  V_vcalc_constant <-    metafor::vcalc(     data = V_dat_test,     vi = vi,      cluster = study,     obs = esid,      rho = 0.7,      sparse = TRUE   )  V_vcalc_constant #> 16 x 16 sparse Matrix of class \"dgCMatrix\" #>                                                                           #>  [1,] 0.09878727 0.05313510 0.05844718 0.06782054 0.024783717 0.027736288 #>  [2,] 0.05313510 0.05832651 0.04491031 0.05211272 0.019043596 0.021312326 #>  [3,] 0.05844718 0.04491031 0.07057162 0.05732259 0.020947442 0.023442985 #>  [4,] 0.06782054 0.05211272 0.05732259 0.09502226 0.024306847 0.027202607 #>  [5,] 0.02478372 0.01904360 0.02094744 0.02430685 0.012689246 0.009940672 #>  [6,] 0.02773629 0.02131233 0.02344298 0.02720261 0.009940672 0.015892771 #>  [7,] 0.10758047 0.08266391 0.09092808 0.10551049 0.038556789 0.043150195 #>  [8,] 0.09421919 0.07239722 0.07963499 0.09240629 0.033768111 0.037791025 #>  [9,] 0.05430196 0.04172516 0.04589656 0.05325713 0.019461797 0.021780350 #> [10,] 0.01839293 0.01413297 0.01554588 0.01803902 0.006592016 0.007377346 #> [11,] 0.06603106 0.05073770 0.05581011 0.06476054 0.023665502 0.026484856 #> [12,] 0.04372557 0.03359836 0.03695729 0.04288424 0.015671225 0.017538193 #> [13,] 0.07588417 0.05830875 0.06413805 0.07442406 0.027196850 0.030436906 #> [14,] 0.01928391 0.01481759 0.01629895 0.01891286 0.006911344 0.007734717 #> [15,] 0.10247074 0.07873764 0.08660928 0.10049907 0.036725463 0.041100697 #> [16,] 0.04069405 0.03126896 0.03439501 0.03991105 0.014584728 0.016322258 #>                                                                          #>  [1,] 0.10758047 0.09421919 0.05430196 0.018392926 0.06603106 0.04372557 #>  [2,] 0.08266391 0.07239722 0.04172516 0.014132966 0.05073770 0.03359836 #>  [3,] 0.09092808 0.07963499 0.04589656 0.015545882 0.05581011 0.03695729 #>  [4,] 0.10551049 0.09240629 0.05325713 0.018039023 0.06476054 0.04288424 #>  [5,] 0.03855679 0.03376811 0.01946180 0.006592016 0.02366550 0.01567122 #>  [6,] 0.04315019 0.03779103 0.02178035 0.007377346 0.02648486 0.01753819 #>  [7,] 0.23909463 0.14657968 0.08447923 0.028614439 0.10272655 0.06802522 #>  [8,] 0.14657968 0.18339253 0.07398708 0.025060581 0.08996812 0.05957662 #>  [9,] 0.08447923 0.07398708 0.06091637 0.014443329 0.05185192 0.03433618 #> [10,] 0.02861444 0.02506058 0.01444333 0.006988831 0.01756306 0.01163020 #> [11,] 0.10272655 0.08996812 0.05185192 0.017563056 0.09007402 0.04175272 #> [12,] 0.06802522 0.05957662 0.03433618 0.011630203 0.04175272 0.03949790 #> [13,] 0.11805533 0.10339309 0.05958922 0.020183802 0.07246036 0.04798303 #> [14,] 0.03000057 0.02627456 0.01514299 0.005129168 0.01841384 0.01219359 #> [15,] 0.15941687 0.13961761 0.08046673 0.027255343 0.09784737 0.06479423 #> [16,] 0.06330898 0.05544613 0.03195563 0.010823874 0.03885798 0.02573164 #>                                                    #>  [1,] 0.07588417 0.019283911 0.10247074 0.04069405 #>  [2,] 0.05830875 0.014817592 0.07873764 0.03126896 #>  [3,] 0.06413805 0.016298952 0.08660928 0.03439501 #>  [4,] 0.07442406 0.018912865 0.10049907 0.03991105 #>  [5,] 0.02719685 0.006911344 0.03672546 0.01458473 #>  [6,] 0.03043691 0.007734717 0.04110070 0.01632226 #>  [7,] 0.11805533 0.030000572 0.15941687 0.06330898 #>  [8,] 0.10339309 0.026274560 0.13961761 0.05544613 #>  [9,] 0.05958922 0.015142990 0.08046673 0.03195563 #> [10,] 0.02018380 0.005129168 0.02725534 0.01082387 #> [11,] 0.07246036 0.018413841 0.09784737 0.03885798 #> [12,] 0.04798303 0.012193591 0.06479423 0.02573164 #> [13,] 0.11896119 0.021161541 0.11244808 0.04465634 #> [14,] 0.02116154 0.007682334 0.02857564 0.01134820 #> [15,] 0.11244808 0.028575640 0.21692153 0.06030201 #> [16,] 0.04465634 0.011348201 0.06030201 0.03421092 V_vcalc_constant |> cov2cor() #> 16 x 16 sparse Matrix of class \"dsCMatrix\" #>                                                                       #>  [1,] 1.0 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 #>  [2,] 0.7 1.0 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 #>  [3,] 0.7 0.7 1.0 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 #>  [4,] 0.7 0.7 0.7 1.0 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 #>  [5,] 0.7 0.7 0.7 0.7 1.0 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 #>  [6,] 0.7 0.7 0.7 0.7 0.7 1.0 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 #>  [7,] 0.7 0.7 0.7 0.7 0.7 0.7 1.0 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 #>  [8,] 0.7 0.7 0.7 0.7 0.7 0.7 0.7 1.0 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 #>  [9,] 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 1.0 0.7 0.7 0.7 0.7 0.7 0.7 0.7 #> [10,] 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 1.0 0.7 0.7 0.7 0.7 0.7 0.7 #> [11,] 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 1.0 0.7 0.7 0.7 0.7 0.7 #> [12,] 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 1.0 0.7 0.7 0.7 0.7 #> [13,] 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 1.0 0.7 0.7 0.7 #> [14,] 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 1.0 0.7 0.7 #> [15,] 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 1.0 0.7 #> [16,] 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 1.0"},{"path":"https://mikkelvembye.github.io/VIVECampbell/articles/Entering-data.html","id":"long-and-wide-format-data","dir":"Articles","previous_headings":"Omsætning af formlerne til beregninger i R","what":"Long and wide format data","title":"Indtastning af data, effektstørrelsesudregning og cluster bias justering, når der kun er clustering i en gruppe","text":"Begge formater har hver deres ulemper. Man skal skrive mindre kode, når man beregner effektstørrelser med long format data, men man har dermed også et datasæt som antal af rækker ikke passer sammen med den endelige effektstørrelsesdata. Omvendt, kræver det længere koder kode wide format data, men får man tilgengæld også et datasæt som passer antal med dette endelige effektstørrelses datasæt. På mange af vores andre review indtastes den raw data (som den fra Tabel 1) direkte excel stedet R. Det kan igen måde fordele og ulemper. Ved indtaste det studie studie R, bliver det noget tydeligere læsere, hvor man præcist har udtrykket data, men det kræver også man skriver langt, langt flere koder, som på mange måder kan være meget tidskrævende. Igen det er meget en smagssag.","code":"pivot_wider(   Fisher1996,   values_from = m_pre:v,   names_from = treatment   )"},{"path":"https://mikkelvembye.github.io/VIVECampbell/articles/Entering-data.html","id":"visualize-effect-size-data","dir":"Articles","previous_headings":"","what":"Visualize effect size data","title":"Indtastning af data, effektstørrelsesudregning og cluster bias justering, når der kun er clustering i en gruppe","text":"","code":"Fisher1996_est |>    tidyr::pivot_longer(     cols = -c(study:diff_c, J),     names_to = c('.value', 'Category'),      names_sep = '_'   ) |>    mutate(     CI_L = es - se * qnorm(.975),     CI_U = es + se * qnorm(.975)   ) |>    filter(treatment == \"Cognitive\") |>    ggplot(aes(x = es, y = Category, xmin = CI_L, xmax = CI_U,         color = Category)) +    geom_pointrange(position = position_dodge2(width = 0.5, padding = 0.5)) +   geom_vline(xintercept = 0, linetype = \"dashed\", color = \"black\", alpha = 0.5) +   facet_grid(setting~outcome, scales = \"free\") +   theme_bw() +   theme(legend.position = \"bottom\") +   ylab(\"Effect size type\")"},{"path":[]},{"path":"https://mikkelvembye.github.io/VIVECampbell/articles/Github.html","id":"kobling-til-git-og-github","dir":"Articles","previous_headings":"","what":"Kobling til Git og GitHub","title":"Forbind GitHub og RStudio plus adgang til Adobe Pro","text":"Først og fremmest skal du downloade R og Rstudio fra softwarecenteret. Det er vigtigt, du som minimum har Rstudio 2022.02.3-492 og R 4.1.0. Har du ikke det, skal du opdatere, ellers vil du ikke kunne køre vores scripts og dokumenter. Desuden er der en alvorlig fejl på RStudio 2021.09.2, så kører du på denne version, så SKAL du også opdatere. kunne forbinde RStudio med Github, skal du dernæst hente Git via https://git-scm.com/. Jeg har hørt, nogen af vores kollegaer er stand til hente Git uden tilladelse fra STATENS , så det kan man starte med prøve. Ellers skal du fat Niels Koldsø og oprette sag på serviceportalen https://statensitprod.service-now.com/serviceportal/. tilfælde af Niels spørger, hvad skal bruge Git til, skal bare svare, det er et versionskontrolprogram og intet følsom data vil lægge der. Nu kommer vi til det mere komplicerede og skal jeg nok hjælpe, hvis du støder på problemer, så ingen stress, men sikkert forbinde RStudio og GitHub skal Git en sikkerskode (token). sætte dette op skal man følge guiden dette link https://usethis.r-lib.org/articles/git-credentials.html. Hjælp gerne hinanden, og spørg de andre, hvordan de har fået koblet RStudio, Git og GitHub sammen. Guiden ser kompleks ud, men er essencen ret simpel og usethis:: kommandoer gør det hårde arbejde jer. Sidst men ikke mindst skal du oprette en bruger på GitHub. Det kan forekomme som værende meget information, men tag det bidder. Hent eller opdatér R og Rstudio Software Centeret Få adgang til hente/installere Git https://git-scm.com/. Opret profil på GitHub (kan gøres med det samme). Opsæt gerne tofaktorgodkendelse, så vi undgår blive hacket. Se og følg opsætning https://docs.github.com/en/authentication/securing--account--two-factor-authentication-2fa/configuring-two-factor-authentication Genere token og send til git med usethis:: kommado RStudio ved følge guiden https://usethis.r-lib.org/articles/git-credentials.html (jeg skal nok hjælpe, hvis ikke lykkes) God fornøjelse.","code":""},{"path":"https://mikkelvembye.github.io/VIVECampbell/articles/Github.html","id":"adgang-til-adobe-reader-pro","dir":"Articles","previous_headings":"","what":"Adgang til Adobe Reader Pro","title":"Forbind GitHub og RStudio plus adgang til Adobe Pro","text":"Når vi skal trække information og data ud af ældre artikler, er det en klar fordel programmet Adobe Reader Pro, således ældre pdf’er skal konverteres om til Word-format. få adgang til dette program skal du først bede Niels om få oprettet en profil på Adobe. Derefter downloader du Adobe Creative Cloud Software Centeret. Se herunder  Åben derefter Adobe Creative Cloud, hvori du har adgang til opdatere din Adobe Reader til pro-versionen. Se nedenfor.  Du skulle nu gerne kunne se, når du åbner din Adobe Reader igen, denne er opdateret til Pro.","code":""},{"path":"https://mikkelvembye.github.io/VIVECampbell/articles/Pooling-subgroups.html","id":"multiple-sub-groups","dir":"Articles","previous_headings":"","what":"Multiple sub-groups","title":"Pooling across (multiple) subgroups","text":"Now suppose data , reported separately GG different sub-groups, indexed g=1,...,Gg = 1,...,G. Let ngjn_{gj} sample size sub-group g=1,...,Gg = 1,...,G condition j=0,1j = 0, 1. Let y‾gjt\\bar{y}_{gjt} sample mean outcome time t=0,1t = 0,1 (t=0t = 0 pre-test t=1t = 1 post-test), let sgjts_{gjt} sample standard deviation time t=0,1t = 0,1. recover summary statistics full sample (pooled across sub-groups), can following: total sample size condition jj n•j=∑g=1Gngj.   n_{\\bullet j} = \\sum_{g = 1}^G n_{gj}. average outcome condition jj time tt y•jt=1n•j∑g=1Gngjy‾gjt.   y_{\\bullet jt} = \\frac{1}{n_{\\bullet j}} \\sum_{g = 1}^G n_{gj} \\bar{y}_{gjt}. full-sample variance condition jj time tt s•jt2=1n•j−1∑g=1G[(ngj−1)sgjt2+ngj(y‾gjt−y‾•jt)2]   s_{\\bullet jt}^2 = \\frac{1}{n_{\\bullet j} - 1} \\sum_{g = 1}^G \\left[\\left(n_{gj}  - 1 \\right) s_{gjt}^2 + n_{gj}\\left(\\bar{y}_{gjt} - \\bar{y}_{\\bullet jt}\\right)^2\\right] “rehydrated” summary statistics, one calculate standardized mean difference post-test, adjusting pre-test differences, described . Alternately, one calculate numerator SMD adjusted mean difference, pooled across sub-groups. average difference--differences DD•=1n••∑g=1Gng•DDg, DD_{\\bullet} = \\frac{1}{n_{\\bullet \\bullet}} \\sum_{g=1}^G n_{g \\bullet} \\ DD_{g},  ng•=ng0+ng1n_{g\\bullet} = n_{g 0} + n_{g 1} n••=∑g=1Gng•n_{\\bullet \\bullet} = \\sum_{g = 1}^G n_{g\\bullet}. average difference--differences used numerator SMD, dsg=DD•s••1. d_{sg} = \\frac{DD_\\bullet}{s_{\\bullet \\bullet 1}}.  sampling variance dsgd_{sg} can approximated Var(dsg)≈2(1−ρ)[∑g=1Gng•2n••2(1ng0+1ng1)]+d22(n••−2). \\text{Var}(d_{sg}) \\approx 2\\left(1 - \\rho\\right)\\left[\\sum_{g=1}^G \\frac{n_{g\\bullet}^2}{n_{\\bullet \\bullet}^2} \\left(\\frac{1}{n_{g0}} + \\frac{1}{n_{g1}}\\right)\\right] + \\frac{d^2}{2\\left(n_{\\bullet \\bullet} - 2\\right)}.","code":""},{"path":[]},{"path":"https://mikkelvembye.github.io/VIVECampbell/articles/VIVECampbell.html","id":"welcome-to-the-vivecampbell-r-package-","dir":"Articles","previous_headings":"","what":"Welcome to the VIVECampbell R package.","title":"VIVECampbell","text":"Add text time.","code":""},{"path":"https://mikkelvembye.github.io/VIVECampbell/articles/ancova-puzzler.html","id":"for-realz","dir":"Articles","previous_headings":"","what":"For realz?","title":"An ANCOVA puzzler","text":"’s example real data, drawn Table 2 Murawski (2006): study reported information several outcomes, separate analyses two sub-groups (LD NLD). text also reports used two-level hierarchical linear model ANCOVA adjustment. simplicity, let’s just ignore hierarchical linear model aspect assume ’s straight, one-level ANCOVA.","code":""},{"path":"https://mikkelvembye.github.io/VIVECampbell/articles/ancova-puzzler.html","id":"the-puzzler","dir":"Articles","previous_headings":"","what":"The puzzler","title":"An ANCOVA puzzler","text":"Calculate estimate standardized mean difference group BB group AA, along sampling variance SMD estimate, adjusts pre-test differences groups. Candidates numerator SMD include adjusted mean difference, ỹB−ỹ\\tilde{y}_B - \\tilde{y}_A difference--differences, (y‾B−x‾B)−(y‾−x‾)\\left(\\bar{y}_B - \\bar{x}_B\\right) - \\left(\\bar{y}_A - \\bar{x}_A\\right). either case, tricky bit finding sampling variance quantity, involves pre-post correlation. denominator SMD, use post-test SD, either pooled across just groups AA BB pooled across GG groups, assuming common population variance.","code":""},{"path":"https://mikkelvembye.github.io/VIVECampbell/articles/ancova-puzzler.html","id":"the-solution","dir":"Articles","previous_headings":"","what":"The solution","title":"An ANCOVA puzzler","text":"key recognize can calculate β̂\\hat\\beta, estimated slope within-group pre-post relationship, based difference adjusted group means raw post-test means. pre-post correlation can derived β̂\\hat\\beta. ANCOVA model, ỹg=y‾g−β̂(x‾g−x‾‾), \\tilde{y}_g = \\bar{y}_g - \\hat\\beta \\left(\\bar{x}_g - \\bar{\\bar{x}}\\right),  x‾‾\\bar{\\bar{x}} overall mean across groups, x‾‾=1n•∑g=1Gngx‾g, \\bar{\\bar{x}} = \\frac{1}{n_{\\bullet}} \\sum_{g=1}^G n_g \\bar{x}_g,  n•=∑g=1Gngn_{\\bullet} = \\sum_{g=1}^{G} n_g. Thus, can back β̂\\hat\\beta reported summary statistics group gg β̂g=y‾g−ỹgx‾g−x‾‾. \\hat\\beta_g = \\frac{\\bar{y}_g - \\tilde{y}_g}{\\bar{x}_g - \\bar{\\bar{x}}}.  Actually, get GG estimates β̂g\\hat\\beta_g—one group. Taking weighted average seems sensible , end β̂=1n•∑g=1Gng(y‾g−ỹgx‾g−x‾‾). \\hat\\beta = \\frac{1}{n_{\\bullet}} \\sum_{g=1}^G n_g \\left(\\frac{\\bar{y}_g - \\tilde{y}_g}{\\bar{x}_g - \\bar{\\bar{x}}}\\right).  Now, let rr denote sample correlation pre-test post-test, partialing differences means group. correlation related β̂\\hat\\beta r=β̂×spxspy, r = \\hat\\beta \\times \\frac{s_{px}}{s_{py}},  spxs_{px} spys_{py} standard deviations pre-test post-test, respectively, pooled across gg groups. ’s result carrying calculations example data Murawski (2006): , can calculate numerator SMD different ways.","code":"# UPDATE EXAMPLE WHEN READY  library(dplyr)  dat <- tibble(   Group = c(\"A\",\"B\",\"C\"),   N = c(25, 26, 16),   m_pre = c(37.48, 36.85, 37.88),   sd_pre = c(4.64, 5.18, 3.88),   m_post = c(37.96, 36.46, 37.38),   sd_post = c(4.35, 3.86, 4.76),   m_adj = c(37.84, 36.66, 36.98) )  corr_est <-    dat %>%   mutate(     m_pre_pooled = weighted.mean(m_pre, w = N),     beta_hat = (m_post - m_adj) / (m_pre - m_pre_pooled)   ) %>%   summarise(     df = sum(N - 1),     s_sq_x = sum((N - 1) * sd_pre^2) / df,     s_sq_y = sum((N - 1) * sd_post^2) / df,     beta_hat = weighted.mean(beta_hat, w = N)   ) %>%   mutate(     r = beta_hat * sqrt(s_sq_x / s_sq_y)   )  corr_est #> # A tibble: 1 × 5 #>      df s_sq_x s_sq_y beta_hat     r #>   <dbl>  <dbl>  <dbl>    <dbl> <dbl> #> 1    64   22.1   18.2    0.636 0.700"},{"path":"https://mikkelvembye.github.io/VIVECampbell/articles/ancova-puzzler.html","id":"diff-in-diff","dir":"Articles","previous_headings":"The solution","what":"Diff-in-diff","title":"An ANCOVA puzzler","text":"One option take -group difference pre-post differences (.k.., diff--diff): DD=(y‾B−x‾B)−(y‾−x‾). DD = (\\bar{y}_B - \\bar{x}_B) - (\\bar{y}_A - \\bar{x}_A).  Assuming within-group variance pre-test within-group variance post-test equal (constant across groups), Var(DD)=2σ2(1−ρ)(1nA+1nB), \\text{Var}(DD) = 2\\sigma^2(1 - \\rho)\\left(\\frac{1}{n_A} + \\frac{1}{n_B}\\right),  σ2\\sigma^2 within-group population variance post-test ρ\\rho population correlation pre- post. Dividing DDDD spys_{py} gives estimate standardized mean difference group B group , dDD=DDspy, d_{DD} = \\frac{DD}{s_{py}},  approximate sampling variance Var(dDD)≈2(1−ρ)(1nA+1nB)+δ22(n•−G), \\text{Var}(d_{DD}) \\approx 2(1 - \\rho)\\left(\\frac{1}{n_A} + \\frac{1}{n_B}\\right) + \\frac{\\delta^2}{2(n_\\bullet - G)},  δ\\delta SMD parameter. variance can estimated substituting estimates ρ\\rho δ\\delta: VDD=2(1−r)(1nA+1nB)+d22(n•−G). V_{DD} = 2(1 - r)\\left(\\frac{1}{n_A} + \\frac{1}{n_B}\\right) + \\frac{d^2}{2(n_\\bullet - G)}.  prefer pool post-test standard deviation across groups AA BB , replace (n•−G)(n_\\bullet - G) (nA+nB−2)(n_A + n_B - 2) second term VDDV_{DD}.","code":""},{"path":"https://mikkelvembye.github.io/VIVECampbell/articles/ancova-puzzler.html","id":"regression-adjustment","dir":"Articles","previous_headings":"The solution","what":"Regression adjustment","title":"An ANCOVA puzzler","text":"alternative diff--diff approach use regression-adjusted mean difference group BB group AA numerator SMD. , calculate standardized mean difference dreg=ỹB−ỹAspy. d_{reg} = \\frac{\\tilde{y}_B - \\tilde{y}_A}{s_{py}}.  Now, variance regression-adjusted mean difference approximately Var(ỹB−ỹ)≈σ2(1−ρ2)(1nA+1nB), \\text{Var}(\\tilde{y}_B - \\tilde{y}_A) \\approx \\sigma^2 (1 - \\rho^2) \\left(\\frac{1}{n_A} + \\frac{1}{n_B}\\right),   follows variance regression-adjusted SMD approximately Var(dreg)≈(1−ρ2)(1nA+1nB)+δ22(n•−G). \\text{Var}(d_{reg}) \\approx (1 - \\rho^2)\\left(\\frac{1}{n_A} + \\frac{1}{n_B}\\right) + \\frac{\\delta^2}{2(n_\\bullet - G)}.  , variance can estimated substituting estimates ρ\\rho δ\\delta: Vreg=(1−r2)(1nA+1nB)+d22(n•−G). V_{reg} = (1 - r^2)\\left(\\frac{1}{n_A} + \\frac{1}{n_B}\\right) + \\frac{d^2}{2(n_\\bullet - G)}.  prefer pool post-test standard deviation across groups AA BB , replace (n•−G)(n_\\bullet - G) (nA+nB−2)(n_A + n_B - 2) second term VDDV_{DD}. regression-adjusted effect size estimator always smaller sampling variance diff--diff estimator (assumptions given ) seem generally preferable. main reason see using diff--diff estimator thing calculated studies included synthesis.","code":""},{"path":"https://mikkelvembye.github.io/VIVECampbell/articles/ancova-puzzler.html","id":"numerical-example","dir":"Articles","previous_headings":"The solution","what":"Numerical example","title":"An ANCOVA puzzler","text":"calculate estimates corresponding variances example data Murawski (2006): effect size estimates rather discrepant, bit worrisome.","code":"diffs <-    dat %>%   filter(Group %in% c(\"A\",\"B\")) %>%   summarise(     diff_pre = diff(m_pre),     diff_post = diff(m_post),     diff_adj = diff(m_adj),     inv_n = sum(1 / N)   )  d_est <-   diffs %>%   mutate(     d_DD = (diff_post - diff_pre) / sqrt(corr_est$s_sq_y),     V_DD = 2 * (1 - corr_est$r) * inv_n + d_DD^2 / (2 * corr_est$df),     d_reg = diff_adj / sqrt(corr_est$s_sq_y),     V_reg = (1 - corr_est$r^2) * inv_n + d_DD^2 / (2 * corr_est$df),   )  d_est %>%   select(d_DD, V_DD, d_reg, V_reg) #> # A tibble: 1 × 4 #>     d_DD   V_DD  d_reg  V_reg #>    <dbl>  <dbl>  <dbl>  <dbl> #> 1 -0.204 0.0474 -0.276 0.0403"},{"path":[]},{"path":"https://mikkelvembye.github.io/VIVECampbell/articles/eppi-tips.html","id":"at-oprette-en-pilotscreening-på-title-and-abstract","dir":"Articles","previous_headings":"1. Screening","what":"1.1. At oprette en pilotscreening (på Title and abstract)","title":"Tips og tricks til EPPI","text":"Opret en child code Allocations –> Screening Title Abstract og giv den titlen “Pilotscreening T/” (brug højreklik og Add child code) Tildel derefter denne kode 150 hits. Det kan gøres smart ved, på startsiden, hvor alle inkluderede dokumenter ligger, vælge: Select fields want display Sæt Maximum number rows til 150 Vælg alle hits på første side (150 stk) Overfør dem til din Pilotscreenings-child code (højreklik og Assign selected items code). Alternativt kan man få EPPI til udtrække en tilfældig gruppe (fx 5 %) med Assign documents specified codes randomly og så allokere de første 150 hits fra den. Næste skridt er tildele pilotscreeningen til dine reviewdeltagere. Det er punkt 1.2.","code":""},{"path":"https://mikkelvembye.github.io/VIVECampbell/articles/eppi-tips.html","id":"at-tildele-screeningsgrupper-til-reviewdeltagere","dir":"Articles","previous_headings":"1. Screening","what":"1.2. At tildele screeningsgrupper til reviewdeltagere","title":"Tips og tricks til EPPI","text":"Create new (coding assignment) Tilpas (skal du fx assigne ”Pilotscreening T/” eller en anden screeningsgruppe), vælg deltagere og Assign work Deltagere vil nu kunne se deres respektive assignments info og følge egen progression, ligesom alle opgaver og deres status vises samlet Collaborate","code":""},{"path":"https://mikkelvembye.github.io/VIVECampbell/articles/eppi-tips.html","id":"at-oprette-grupper-i-eppi-til-screening-på-title-and-abstract","dir":"Articles","previous_headings":"1. Screening","what":"1.3. At oprette grupper i EPPI til screening på ”Title and abstract”","title":"Tips og tricks til EPPI","text":"Det er lettest oprette alle screeningsgrupper til ”Title abstract” fra starten af. På den måde undgår man, der kommer til være studier, som overlapper mellem grupper. Når man vælger oprette alle grupper fra starten af, skal man blot huske frasortere pilotsøgningen, så den ikke overlapper med ens ”Title abstract”-screeningsgrupper. Det gøres sådan : Vælg “Pilotscreening T/” Create codes code/set –> Vælg “Screening Title abstract” Vælg 100 % samt antal grupper, du ønsker oprette. kan det være en god ide på forhånd dannet sig et overblik antallet af referencer, så man ved, hvor mange grupper, man gerne vil . Det kan man nemlig ikke tjekke samtidig denne funktion. Nu opretter EPPI alle screeningsgrupperne, med pilotsøgningen frasorteret. Tildel herefter screeningsgrupper til dine reviewdeltagere, se 1.2. Det kan ske, man ikke får oprettet alle sine screeningsgrupper fra starten af, men begynder med oprette et par grupper, dernæst ville tilføje flere. de tilfælde kan man ende med få en del studier, som overlapper mellem de først oprettede (og allerede screenede) grupper og de nye (u-screenede) grupper - medmindre man gør følgende: Tildel allerede screenede grupper til dummy-koden (Assign selected items code) Select –> without code –> Vælg din dummy-kode Create codes code/set –> Vælg “Screening Title abstract” Vælg 100 % samt antal grupper, du ønsker oprette. Igen kræver det, man på forhånd har overblik antal resterende referencer og antal grupper, man ønsker inddele . Nu opretter EPPI dine nye screeningsgrupper, med de allerede screenede fra din dummy-kode frasorteret. Tildel herefter screeningsgrupper til dine reviewdeltagere, se 1.2. Hvis du ikke har fået gjort ovenstående, men har grupper med overlap, kan du fjerne de overlappende studier på følgende måde: Vælg gruppekoder Kombinér med ”” Combine –> overlap vises Marker alle items Remove selected items fra gruppe","code":""},{"path":"https://mikkelvembye.github.io/VIVECampbell/articles/eppi-tips.html","id":"når-forskellige-deltageres-screening-skal-sammenlignes-og-afstemmes","dir":"Articles","previous_headings":"1. Screening","what":"1.4. Når forskellige deltageres screening skal sammenlignes og afstemmes","title":"Tips og tricks til EPPI","text":"Vælg: Collaborate –> Create comparison Vælg deltagere og kør Nu kan enighed/uoverensstemmelser ses og der kan træffes endelige beslutninger om inklusion/eksklusion (på det pågældende screeningsniveau). OBS: EPPI kan kun køre sammenligninger mellem max 3 reviewere. Hvis du vil lave sammenligninger mellem flere deltagere, fx fire, så kan du gøre følgende: Lav sammenligninger og løs de uenigheder, der er. Når én uenighed er løst, bliver den automatisk completed, og dermed ’løst’ fra systemet, så alle kan se den. Når du har gennemgået alle uenighederne mellem alle kombinationer af screenere (og er sikker på, alle uenigheder er løst), kan du complete enighederne, bare én af screener-kombinationerne. Det spiller ikke den store rolle, hvilken man vælger. OBS: den øvelse er det ALTID nødvendigt tjekke frequencies efterfølgende, se om man har fået completed sin pilotscreening rigtigt. Altså, er alle referencer completed, er det de rigtige der er inkluderet og ekskluderet m.v.","code":""},{"path":"https://mikkelvembye.github.io/VIVECampbell/articles/eppi-tips.html","id":"når-man-vil-ændre-ellers-completede-koder-ved-at-un-complete-og-så-complete-på-ny","dir":"Articles","previous_headings":"1. Screening","what":"1.5. Når man vil ændre ellers completede koder ved at un-complete og så complete på ny","title":"Tips og tricks til EPPI","text":"Du går ind studiet og kigger på fanen til venstre, hvor du kan se kodningen af studiet (screen title abstract, screen full text, allocation osv. osv.). kan du så højreklikke på ”Screen title abstract”. Det åbner en boks, hvor du skal vælge ”Properties”. ”Properties” kan du så afklikke ”Coding completed”, således kodningen åbnes igen. Derefter omkoder du studiet (altså vælger Exclude stedet Include). Dernæst højreklikker du igen, vælger ”Properties” og klikker ”Coding completed”. Så burde studiet være omdirigeret til ”Exclude” – og du kan tjekke, det nu findes listen ekskluderede studier på Titel og abstract.","code":""},{"path":[]},{"path":"https://mikkelvembye.github.io/VIVECampbell/articles/es-calc-uden-means-og-sds.html","id":"hvad-gør-vi-når-vi-ikke-kender-pre-posttest-korrelationen","dir":"Articles","previous_headings":"Eksempel 1 - Michalak et al. (2015)","what":"Hvad gør vi når vi ikke kender pre-posttest korrelationen?","title":"Effektstørrelsesudregning uden means og SDs (med eksempler)","text":"Lad os starte udregne effektstørrelser baseret på HAM-D og BDI målene fra Michalak et al. (2015). og med forfatterne afrapporterer raw means både på baseline og posttest niveau, så kan vi teorien både beregne en ren posttest-baseret effektstørrelse og/eller baseline/pretest adjusted effektstørrelse (kald det hvad vil – jeg kalder den også nogen gange en diffencence--differences effektstørrelse []), hvor vi kontrollerer eventuelle baseline forskelle mellem grupperne. Vi vil ofte beregne begge, men jeg er ret stor fan af den baseline-adjusted effektstørrelse, dels fordi denne kan reducere bias og dels fordi den kan estimateres mere præcist (se Hedges et al. 2023). Formlen effektstørrelsen, som kan beregne ud fra Tabel 2 Michalak et al. (2015), er givet ved  gDID=J([MpostT−MbaselineT]−[MpostC−MbaselineC]SDpool)\\begin{equation}   \\tag{1}    g_{} = J \\left(\\frac{[M^T_{post} - M^T_{baseline}] - [M^C_{post} - M^C_{baseline}]}{SD_{pool}}\\right) \\end{equation} hvor MpostTM^T_{post} og MpostCM^C_{post} samt MbaselineTM^T_{baseline} og MbaselineCM^C_{baseline} er post- og baselinemål hhv. treatment og kontrolgruppen, og SDpool=(npostT−1)×(SDpostT)2+(npostC−1)×(SDpostC)2nT+nC−2SD_{pool}  = \\sqrt{\\frac{(n^T_{post} -1)\\times(SD^T_{post})^2 + (n^C_{post} -1)\\times(SD^C_{post})^2}{n^T + n^C - 2}}, mens nTn^T og nCn^C samt SDpostTSD^T_{post} og SDpostCSD^C_{post} er samplestørrelsen og standardafvigelsen hhv. treatment og kontrolgruppen. JJ formel (1) er Hedges’ sample sample korrektor lige med 1−34df−11 - \\frac{3}{4df-1} (nogen trækker 9 fra dfdf stedet 1, men det har ingen substantiel betydning).  Hvis vi antager, der ikke er klusterproblmer, så er df=nT+nCdf = n^T + n^C. Når der er klusteringproblemer kan dfdf beregnes via Equation E.21 (WWC, 2023, s. 171) eller hvis der kun er klustering en gruppe Equation 7 Hedges og Citkowicz (2015). Sampling variansen gDIDg_{} er givet ved VargDID=(1nT+1nC)2(1−ρprepost)+gDID22df\\begin{equation}   \\tag{2}    Var_{g_{}} = \\left(\\frac{1}{n^T} + \\frac{1}{n^C}\\right) 2(1-\\rho_{prepost})  + \\frac{g_{}^2}{2df} \\end{equation} Problemet er dog, man skal kende pre-posttest korrelationen, ρprepost\\rho_{prepost}, kunne beregne variansen korrekt. mange tilfælde vil vi være stand til kunne beregne denne. Se eksemplvis formlerne fra Cochranes handbook eller formel 31 Wilson (2016). Se også denne blog på VIVECampbell siden. Alternativt kan VargDIDVar_{g_{}} beregnes korrekt, hvis forfatterne har afrapporteret tt- eller FF-værdier fra repeated ANOVA, ANCOVA eller en regressions model, som har inkluderet baseline outcome som kontrol variabel. Hvis dette er tilfældet, så VargDID=gDID2t2+gDID22df\\begin{equation}   \\tag{3}    Var_{g_{}} = \\frac{g_{}^2}{t^2} + \\frac{g_{}^2}{2df} \\end{equation} Bemærk F=t2F = t^2. Se James Pustejovskys blog en yderligere uddybning. Michalak et al. (2015) har vi imidlertidig det problem, forfatterne ikke afrapporterer nogle af den kvantitative mål, som vi har brug , kunne beregne VargDIDVar_{g_{}} korrekt. sådan en situation foreslår Hedges et al. (2023, s. 14) følgende: impute value pre-test post-test correlation, practitioners use test–retest reliability coefficient outcome measure primary study. test-retest reliability coefficient measures stability scores across time computing correlation baseline ‘pre-test’ administration instrument ‘post-test’ administration instrument fixed period time. Michalak et al. (2015) kunne vi derfor beregnes formel (2) ved imputere det mest konservative test-retest reliablity Hamilton Rating Scale Depression fundet Trajković et al. (2011), dvs. 0.650.65. nogen tilfælde vil det ikke være muligt kunne finde en beregnet test-retest reliability. disse tilfælde, foreslår WWC (2021, s. E-6) imputere ρprepost=0.5\\rho_{prepost} = 0.5, således (1nT+1nC)2(1−ρprepost)+g22df=(1nT+1nC)+g22df\\begin{equation}   \\tag{4}   \\left(\\frac{1}{n^T} + \\frac{1}{n^C}\\right) 2(1-\\rho_{prepost})  + \\frac{g^2}{2df} = \\left(\\frac{1}{n^T} + \\frac{1}{n^C}\\right)  + \\frac{g^2}{2df} \\end{equation} Formlen på højre side af lighedstegnet formel 4, svarer til sampling variansen den simple posttest effektstørrelse. Det følger når ρprepost>0.5\\rho_{prepost} > 0.5 så vil højre side af lighedstegnet overestimere (dvs. variansen vil blive større end forventet) sampling variansen af gDIDg_{}, mens når ρprepost<0.5\\rho_{prepost} < 0.5 vil din underestimere (det vil modsat sige variansen vil blive mindre end forventet) sampling variansen af gDIDg_{}. Hvis man vælger denne løsning, kan man plot ændre til pp_cor <- 0.5 ovenstående koder.","code":"library(dplyr) library(tibble)  # Dataudtræk Michalak2015_dat <-    tibble(     outcome = \"HAM-D\",     N_t = 36,     N_c = 35,     N_total = N_t + N_c,      m_pre_t = 23.03,     sd_pre_t = 6.27,     m_pre_c = 23.87,     sd_pre_c = 6.33,     m_post_t = 17.86,     sd_post_t = 10.37,     m_post_c = 21.16,     sd_post_c = 8.16        )   pp_cor <- 0.65  # Udregning af DID effektstørrelse Michalak2015_est1 <-   Michalak2015_dat |>    mutate(     diff_t = m_post_t - m_pre_t,     diff_c = m_post_c - m_pre_c,     mean_diff = diff_t - diff_c,     sd_pool = sqrt( ((N_t-1)*sd_post_t^2 + (N_c-1)*sd_post_c^2)/(N_total-2)  ),        df = N_total,          J = 1 - 3/(4*df-1),          # Formel 1     g_DD = J * (mean_diff/sd_pool),          # Formel 2 - med imputeret pre-posttest korrelation baseret på test-retest reliability for HAM-D     vg_DD = (1/N_t + 1/N_c) * 2*(1-pp_cor) + g_DD^2/(2*df),     se_DD = sqrt(vg_DD)        )   # Resultater Michalak2015_est1 |>    select(J:se_DD) #> # A tibble: 1 × 4 #>        J    g_DD   vg_DD  se_DD #>    <dbl>   <dbl>   <dbl>  <dbl> #> 1 0.9894 -0.2604 0.03992 0.1998"},{"path":"https://mikkelvembye.github.io/VIVECampbell/articles/es-calc-uden-means-og-sds.html","id":"effektstørrelsesudregning-med-beta-coefficient-standardfejl-og-afrapportet-effekstørrelse","dir":"Articles","previous_headings":"Eksempel 1 - Michalak et al. (2015)","what":"Effektstørrelsesudregning med beta-coefficient, standardfejl, og afrapportet effekstørrelse","title":"Effektstørrelsesudregning uden means og SDs (med eksempler)","text":"Nu vender vi os imod eksemplet, hvor vi ønsker udtrække effektstørrelser og beregne variansen effektstørrelser, der ikke er afrapporteret via means og SDs. Michalak et al. (2015) afrapporteres beta-coefficienter, deres standardfejl, og effektstørrelser fra en fixed-effect multi-level model, se Tabel 5. dette tilfælde må vi stole på forfatternes effektstørrelsesudregning og trække deres effektstørrelser ud direkte. Der er ikke så meget mere vi kan gøre , når ikke forfatterne giver raw means og SDs. Man kunne evt. skrive til forfatterne og spørge efter disse, hvis man vil, men som udgangspunkt stoler vi på de afrapporterede effektstørrelser. Spørgsmålet er nu, hvordan beregner vi sampling variansen disse effektstørrelser? Problemet er, hvis vi benytter formlen på højre side af lighedstegnet formel (4), som primært baserer variansen på sample størrelser, så vil variansen med stor sandsyndlighed ikke blive beregnet korrekt. Men fordi forfatterne afrapporterer beta-coefficienter, som basically er en adjusteret means difference mellem treatment og kontrolgruppen, og standardfejl, så kan vi beregne t=βseβt = \\frac{\\beta}{se_{\\beta}} og benytte formel (3) til udregne den korrekte sampling varians af de afrapporterede effektstørrelser. Det kan gøres således  dette studie afrapporteres SF-36 skalaen på tværs af dens subskalaer, som ikke er relevante de moderator analyser som var planlagt dette givne review (se Dalgaard et al. 2022). Nedenfor viser jeg, hvordan man kan sammenlægge alle effektstørrelser på tværs af subskalaer få et overordnet mål SF-36 outcomet. kunne få helt præcise effekter skal man kende mellem-subskala korrelationerne ρSS\\rho_{SS}. Disse kender vi ikke, men vi antager , korrelationen er meget høj ρSS=0.9\\rho_{SS} = 0.9. En rå sammenlægning uden imputere ρSS\\rho_{SS} vil svare til antage ρSS=1\\rho_{SS} = 1. Om man antager ρSS=0.9\\rho_{SS} = 0.9 eller ρSS=1\\rho_{SS} = 1, gør med stor sandsynlighed ikke den store forskel, men vælger vi antage ρSS=0.9\\rho_{SS} = 0.9. Sammenlægningen kan gøres således Skriv endelig, hvis har flere problemer, som jeg skal vise løsninger på.","code":"Michalak2015_est2 <-    tibble(          outcome = rep(c(\"SF-36\", \"SASS\"), c(4,1)),     subscale = c(\"Vitality\", \"Social func\", \"Role\", \"Mental health\", \"overall\"),     treatment = \"MBCT\",     N_t = 36,     N_c = 35,      N_total = N_t + N_c,      df = N_total,     beta = c(1.12, 0.27, 0.52, 0.63, 2.43),     se_b = c(0.90, 0.43, 0.26, 0.95, 1.01),     t_val = beta/se_b,     d_paper = c(0.31, 0.12, 0.48, 0.14, 0.57),     J = 1 - 3/(4*df-1),     g_paper = J * d_paper,     #vg_post = (1/N_t + 1/N_c) + g_paper^2/(2*df),     vg_paper = g_paper^2/t_val^2 + g_paper^2/(2*df),     seg_paper = sqrt(vg_paper)        ); Michalak2015_est2 #> # A tibble: 5 × 15 #>   outcome subscale      treatment   N_t   N_c N_total    df  beta  se_b  t_val #>   <chr>   <chr>         <chr>     <dbl> <dbl>   <dbl> <dbl> <dbl> <dbl>  <dbl> #> 1 SF-36   Vitality      MBCT         36    35      71    71  1.12  0.9  1.244  #> 2 SF-36   Social func   MBCT         36    35      71    71  0.27  0.43 0.6279 #> 3 SF-36   Role          MBCT         36    35      71    71  0.52  0.26 2      #> 4 SF-36   Mental health MBCT         36    35      71    71  0.63  0.95 0.6632 #> 5 SASS    overall       MBCT         36    35      71    71  2.43  1.01 2.406  #>   d_paper      J g_paper vg_paper seg_paper #>     <dbl>  <dbl>   <dbl>    <dbl>     <dbl> #> 1    0.31 0.9894  0.3067  0.06141    0.2478 #> 2    0.12 0.9894  0.1187  0.03585    0.1893 #> 3    0.48 0.9894  0.4749  0.05797    0.2408 #> 4    0.14 0.9894  0.1385  0.04376    0.2092 #> 5    0.57 0.9894  0.5640  0.05718    0.2391 library(metafor)  rho <- 0.9  #_agg for aggregated Michalak2015_metafor <-    Michalak2015_est2 |>    metafor::escalc(measure = \"SMD\", yi = g_paper, vi = vg_paper, data = _)  Michalak2015_agg <-    aggregate.escalc(Michalak2015_metafor, cluster=outcome, rho=rho) |>    as_tibble() |>    mutate(     g_paper = yi,      vg_paper = vi,      seg_paper = sqrt(vi)   ) |>    # Her fjerner jeg de variabler vi ikke længere kan bruge, da en sammenlægning    # af disse ikke giver mening- Og så fjerne jeg yi og vi, som har fået andet navn   select(-c(subscale, beta:J, yi:vi))  Michalak2015_agg #> # A tibble: 2 × 9 #>   outcome treatment   N_t   N_c N_total    df  g_paper vg_paper seg_paper #>   <chr>   <chr>     <dbl> <dbl>   <dbl> <dbl>    <dbl>    <dbl>     <dbl> #> 1 SF-36   MBCT         36    35      71    71 -0.09513  0.03068    0.1751 #> 2 SASS    MBCT         36    35      71    71  0.5640   0.05718    0.2391"},{"path":"https://mikkelvembye.github.io/VIVECampbell/articles/es-calc-uden-means-og-sds.html","id":"litteratur","dir":"Articles","previous_headings":"Eksempel 1 - Michalak et al. (2015)","what":"Litteratur","title":"Effektstørrelsesudregning uden means og SDs (med eksempler)","text":"Hedges, L. V., & Citkowicz, M. (2015). Estimating effect size clustering one treatment group. Behavior Research Methods, 47(4), 1295–1308. https://doi.org/10.3758/s13428-014-0538-z Hedges, L. V, Tipton, E., Zejnullahi, R., & Diaz, K. G. (2023). Effect sizes ANCOVA difference--differences designs. British Journal Mathematical Statistical Psychology. https://doi.org/10.1111/bmsp.12296 Michalak, J., Schultze, M., Heidenreich, T., & Schramm, E. (2015). randomized controlled trial efficacy mindfulness-based cognitive therapy group version cognitive behavioral analysis system psychotherapy chronically depressed patients. Journal Consulting Clinical Psychology, 83(5), 951. https://doi.org/10.1037/ccp0000042 Trajković, G., Starčević, V., Latas, M., Leštarević, M., Ille, T., Bukumirić, Z., & Marinković, J. (2011). Reliability Hamilton Rating Scale Depression: meta-analysis period 49years. Psychiatry Research, 189(1), 1–9. https://doi.org/https://doi.org/10.1016/j.psychres.2010.12.007 WWC. (2021). Supplement document Appendix E Works Clearinghouse procedures handbook, version 4.1. Institute Education Sciences. https://ies.ed.gov/ncee/wwc/Docs/referenceresources/WWC-41-Supplement-508_09212020.pdf Wilson, D. B. (2016). Formulas used “Practical Meta-Analysis Effect Size Calculator. https://mason.gmu.edu/~dwilsonb/downloads/esformulas.pdf","code":""},{"path":"https://mikkelvembye.github.io/VIVECampbell/articles/openai.html","id":"organisations-skifte-på-openai-konto","dir":"Articles","previous_headings":"","what":"Organisations skifte på OpenAI konto","title":"VIVECampbell OpenAI konto","text":"Når jeg har inviteret jer til min OpenAI-konto/-organisation (som hedder “VIVECampbell”) skal gå til https://platform.openai.com/account/api-keys. Herunder skal skifte jeres organisation til “VIVECampbell” (billede 1) og trykke Confirm popup-vinduet (billede 2). Derefter skulle gerne kunne se en grøn linje (billede 3), hvori der står Default organisation updated successfully. Når denne er sat til default, trækker på min konto (dvs. mit VIVE-kort), når anvender jeres egen API-nøgle. Jeg sætter alle brugere som “Owner”, så alle kan tilgå vores kvitteringer. Rør dog endelig ikke ved Payment methods. På min OpenAI konto har vi 1000$ om måneden. Vi kan sagtens søge om ændre dette, hvis vi får brug mere, men så tag lige fat mig god tid.   Notér: kan altid skifte tilbage til jeres private konto ved trykke på VIVECampbell-teksten oppe højre hjørne.Billede 1: Organisations skift Billede 2: Confirm organisations skift Billede 3: Vellykket skifte","code":""},{"path":"https://mikkelvembye.github.io/VIVECampbell/articles/todos.html","id":"fremtidige-ideer","dir":"Articles","previous_headings":"","what":"Fremtidige ideer","title":"Fremtidige ideer og todos","text":"Del erfaringer angående EGM, evt. lav kort introduktion til håndtering af data? “Velkommen til VIVE - godt vide som ny Campbell-gruppen”? Kurs-referencelist (Jens og Mikkel) Vi kan dele alle dataset, som vi har brugt til meta-analyse? Til kollegaer Intern blog angående hvordan Campbell-review opstartes (del evt. eksempel på PICO) Kom gang med systematiske reviews. kunne vi komme med 3-4 vigtig artikler, som kan være gode begyndere, evt. prisma og pico artikler m.m.","code":""},{"path":"https://mikkelvembye.github.io/VIVECampbell/articles/todos.html","id":"todos","dir":"Articles","previous_headings":"","what":"Todos","title":"Fremtidige ideer og todos","text":"Cluster bias korrektion med binære outcomes Cluster bias korrektion med clustering både treatment og kontrol Indlæg tabelfunktioner fra fadeout (med apa format) (overvej S3 metode) Indlæg forrest plot funktioner fra fadeout Indlæg empiriske Blog angående hvordan man henter sit GitHub projekt ind RStudio Lav introduktion til siden (Get Started ) Meta-analyse med afhængige effektstørrelser - præsentation CHE, SCE og CMVE modellerne","code":""},{"path":"https://mikkelvembye.github.io/VIVECampbell/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Mikkel H. Vembye. Author, maintainer.","code":""},{"path":"https://mikkelvembye.github.io/VIVECampbell/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Vembye M (2025). VIVECampbell: Functions Campbell reviews VIVE. R package version 0.0.1, https://mikkelvembye.github.io/VIVECampbell/.","code":"@Manual{,   title = {VIVECampbell: Functions for Campbell reviews in VIVE},   author = {Mikkel H. Vembye},   year = {2025},   note = {R package version 0.0.1},   url = {https://mikkelvembye.github.io/VIVECampbell/}, }"},{"path":"https://mikkelvembye.github.io/VIVECampbell/index.html","id":"vivecampbell-functions-for-campbell-reviews-in-vive","dir":"","previous_headings":"","what":"Functions for Campbell reviews in VIVE","title":"Functions for Campbell reviews in VIVE","text":"package provides functions used Campbell reviews meta-analyses conducted VIVE - Danish Center Social Science Research. See also VIVE Campbell homepage.","code":""},{"path":"https://mikkelvembye.github.io/VIVECampbell/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Functions for Campbell reviews in VIVE","text":"can install development version VIVECampbell like :","code":"# install.packages(\"devtools\") devtools::install_github(\"MikkelVembye/VIVECampbell\") # Load necessary packages library(VIVECampbell) library(dplyr)"},{"path":"https://mikkelvembye.github.io/VIVECampbell/index.html","id":"example---degrees-of-freedom-calculation-for-cluster-designed-studies","dir":"","previous_headings":"","what":"Example - Degrees of freedom calculation for cluster-designed studies","title":"Functions for Campbell reviews in VIVE","text":"Calcualting degrees freedom studies clustering one treatment group (Hedges & Citkowicz, 2015)","code":"## Degrees of freedom calculation for cluster bias correction when there is clustering in one treatment group only  h_eq7_hedges2015 <-    df_h_1armcluster(N_total = 100, ICC = 0.1, N_grp = 60, avg_grp_size = 5)  h_eq7_hedges2015 #> [1] 95.4"},{"path":"https://mikkelvembye.github.io/VIVECampbell/index.html","id":"example---data-included-in-package","dir":"","previous_headings":"","what":"Example - Data included in package","title":"Functions for Campbell reviews in VIVE","text":"Data ‘Targeted school-based interventions improving reading mathematics students risk academic difficulties Grades K-6: systematic review’ (Dietrichson et al., 2021)","code":"# Data from a Campbell Systematic Review conducted by Dietrichson et al. (2021) glimpse(Dietrichson2021_data[1:20]) #> Rows: 1,334 #> Columns: 20 #> $ Authors                    <chr> \"Al-Hazza (2002)\", \"Al-Hazza (2002)\", \"Al-H… #> $ Study_ID                   <chr> \"19770510\", \"19770510\", \"19770510\", \"366227… #> $ Title                      <chr> \"An examination of the effects of the Ameri… #> $ Year                       <dbl> 2002, 2002, 2002, 2005, 2005, 2005, 2005, 2… #> $ Outlet                     <chr> \"Dissertation\", \"Dissertation\", \"Dissertati… #> $ Country                    <chr> \"USA\", \"USA\", \"USA\", \"USA\", \"USA\", \"USA\", \"… #> $ Language                   <chr> \"English\", \"English\", \"English\", \"English\",… #> $ Publishing_status          <dbl> 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1… #> $ RCT_QES                    <chr> \"QES\", \"QES\", \"QES\", \"RCT\", \"RCT\", \"RCT\", \"… #> $ Level_treatment_assignment <chr> \"School\", \"School\", \"School\", \"Individual\",… #> $ Test_subject               <chr> \"Reading\", \"Reading\", \"Reading\", \"Reading\",… #> $ Estimation_method          <chr> \"adjusted means\", \"adjusted means\", \"adjust… #> $ Effectsize_g               <dbl> 0.5534541, 0.3389140, 0.6929860, 0.5452505,… #> $ SE_g                       <dbl> 0.3477837, 0.2969933, 0.3147417, 0.2910332,… #> $ Effectsize_g_adj1          <dbl> 0.5415655, 0.3315552, 0.6779922, 0.5452505,… #> $ SE_g_adj1                  <dbl> 0.4587296, 0.4127792, 0.4255886, 0.2910332,… #> $ Effectsize_g_adj3          <dbl> 0.5127546, 0.3137140, 0.6416456, 0.5452505,… #> $ SE_g_adj3                  <dbl> 0.6485337, 0.6022398, 0.6122611, 0.2910332,… #> $ N_classrooms               <dbl> NA, NA, NA, 12, 12, 12, 12, 12, 12, 12, 12,… #> $ N_schools                  <dbl> 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4…  # Find documentation behind the data set by removing the below # #?Dietrichson2021_data"},{"path":"https://mikkelvembye.github.io/VIVECampbell/index.html","id":"references","dir":"","previous_headings":"","what":"References","title":"Functions for Campbell reviews in VIVE","text":"Dietrichson, J., Filges, T., Seerup, J. K., Klokker, R. H., Viinholt, B. C. ., Bøg, M., & Eiberg, M. (2021). Targeted school-based interventions improving reading mathematics students risk academic difficulties Grades K-6: systematic review. Campbell Systematic Reviews, 17(2), e1152. https://doi.org/10.1002/cl2.1152 Hedges, L. V., & Citkowicz, M (2015). Estimating effect size clustering one treatment groups. Behavior Research Methods, 47(4), 1295-1308. https://doi.org/10.3758/s13428-014-0538-z","code":""},{"path":"https://mikkelvembye.github.io/VIVECampbell/reference/Dietrichson2021_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Targeted school-based interventions data (K-6) — Dietrichson2021_data","title":"Targeted school-based interventions data (K-6) — Dietrichson2021_data","text":"Data meta-analysis effects targeted school-based interventions reading mathematics students risk academic difficulties Grades K-6 (Dietrichson et al., 2021)","code":""},{"path":"https://mikkelvembye.github.io/VIVECampbell/reference/Dietrichson2021_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Targeted school-based interventions data (K-6) — Dietrichson2021_data","text":"","code":"Dietrichson2021_data"},{"path":"https://mikkelvembye.github.io/VIVECampbell/reference/Dietrichson2021_data.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Targeted school-based interventions data (K-6) — Dietrichson2021_data","text":"tibble 1334 rows/studies 71 variables/columns","code":""},{"path":"https://mikkelvembye.github.io/VIVECampbell/reference/Dietrichson2021_data.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Targeted school-based interventions data (K-6) — Dietrichson2021_data","text":"Dietrichson, J., Filges, T., Seerup, J. K., Klokker, R. H., Viinholt, B. C. ., Bøg, M., & Eiberg, M. (2021). Targeted school-based interventions improving reading mathematics students risk academic difficulties Grades K-6: systematic review. Campbell Systematic Reviews, 17(2), e1152. doi:10.1002/cl2.1152","code":""},{"path":"https://mikkelvembye.github.io/VIVECampbell/reference/OR_calc.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate and cluster bias adjust odds ratios (OR) — OR_calc","title":"Calculate and cluster bias adjust odds ratios (OR) — OR_calc","text":"function calculated odds ratios based various type input/information, described Table 11.10 Borenstein Hedges (2019, p. 226).","code":""},{"path":"https://mikkelvembye.github.io/VIVECampbell/reference/OR_calc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate and cluster bias adjust odds ratios (OR) — OR_calc","text":"","code":"OR_calc(   A = NULL,   B = NULL,   C = NULL,   D = NULL,   p1 = NULL,   p2 = NULL,   n1 = NULL,   n2 = NULL,   OR = NULL,   LL_OR = NULL,   UL_OR = NULL,   SE_OR = NULL,   V_OR = NULL,   Z = 1.96,   ICC = NULL,   avg_cl_size = NULL,   n_cluster_arms = 2,   add_name_to_vars = NULL,   vars = dplyr::everything() )"},{"path":"https://mikkelvembye.github.io/VIVECampbell/reference/OR_calc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate and cluster bias adjust odds ratios (OR) — OR_calc","text":"Upper left cell 2 X 2 frequency table. B Upper right cell 2 X 2 frequency table. C Lower left cell 2 X 2 frequency table. D Lower right cell 2 X 2 frequency table. p1 Risk/probability event group 1 (usually treatment group). p2 Risk/probability event group 2 (usually control group). n1 Sample size group 1 (usually treatment group). n2 Sample size group 2 (usually control group). Odds ratio estimate. LL_OR Lower  bound 95% confidence interval odds ratio. UL_OR Upper  bound 95% confidence interval odds ratio. SE_OR Standard error odds ratio. V_OR Sampling variance odds ratio. Z Z-values normal distribution. ICC Intra-class correlation. avg_cl_size Average cluster size. n_cluster_arms (Optional) Number arm clustering. add_name_to_vars Optional character string added variables names generated tibble. vars Variables reported. Default NULL. See Value section details.","code":""},{"path":"https://mikkelvembye.github.io/VIVECampbell/reference/OR_calc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate and cluster bias adjust odds ratios (OR) — OR_calc","text":"tibble information , OR_LN, vln_OR.","code":""},{"path":"https://mikkelvembye.github.io/VIVECampbell/reference/OR_calc.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate and cluster bias adjust odds ratios (OR) — OR_calc","text":"2x2 table","code":""},{"path":"https://mikkelvembye.github.io/VIVECampbell/reference/OR_calc.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Calculate and cluster bias adjust odds ratios (OR) — OR_calc","text":"Read Borenstein Hedges (2019) details.","code":""},{"path":"https://mikkelvembye.github.io/VIVECampbell/reference/OR_calc.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Calculate and cluster bias adjust odds ratios (OR) — OR_calc","text":"Borenstein Hedges (2019). Effect sizes meta-analysis. H. Cooper, L. V. Hedges, & J. C. Valentine (Eds.), handbook research synthesis meta-analysis (3rd ed., pp. 207–242). Russell Sage Foundation West Sussex. Hedges, L. V., & Citkowicz, M (2015). Estimating effect size clustering one treatment groups. Behavior Research Methods, 47(4), 1295-1308. doi:10.3758/s13428-014-0538-z Higgins, J. P. T., Eldridge, S., & Li, T. (2019). J. P. T. Higgins, J. Thomas, J. Chandler, M. S. Cumpston, T. Li, M. Page, & V. Welch (Eds.), Cochrane handbook systematic reviews interventions (2nd ed., pp. 569–593). Wiley Online Library. doi:10.1002/9781119536604.ch23","code":""},{"path":"https://mikkelvembye.github.io/VIVECampbell/reference/OR_calc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate and cluster bias adjust odds ratios (OR) — OR_calc","text":"","code":"# Using raw events OR_calc(A = 20, B = 80, C = 10, D = 90) #> # A tibble: 1 × 3 #>      OR ln_OR vln_OR #>   <dbl> <dbl>  <dbl> #> 1  2.25 0.811  0.174  # Using proportions OR_calc(p1 = .2, p2 = .1, n1 = 100, n2 = 100) #> # A tibble: 1 × 3 #>      OR ln_OR vln_OR #>   <dbl> <dbl>  <dbl> #> 1  2.25 0.811  0.174  # Using raw OR and CIs OR_calc(OR = 2.25, LL_OR = 1.5, UL_OR = 3) #> # A tibble: 1 × 3 #>      OR ln_OR vln_OR #>   <dbl> <dbl>  <dbl> #> 1  2.25 0.811 0.0313  # Adding suffix to variables and selecting specific variables OR_calc(A = 20, B = 80, C = 10, D = 90, add_name_to_vars = \"_test\", vars = OR_test) #> # A tibble: 1 × 1 #>   OR_test #>     <dbl> #> 1    2.25  # Cluster bias adjustment when there is clustering in both groups OR_calc(p1 = .53, p2 = .11, n1 = 20, n2 = 26, ICC = 0.1, avg_cl_size = 8, n_cluster_arms = 2) #> # A tibble: 1 × 5 #>      OR ln_OR vln_OR    DE vln_OR_C #>   <dbl> <dbl>  <dbl> <dbl>    <dbl> #> 1  9.12  2.21  0.594   1.7     1.01  # Cluster bias adjustment when there is clustering in one group only OR_calc(p1 = .53, p2 = .11, n1 = 20, n2 = 26, ICC = 0.1, avg_cl_size = 8, n_cluster_arms = 1) #> # A tibble: 1 × 5 #>      OR ln_OR vln_OR    DE vln_OR_C #>   <dbl> <dbl>  <dbl> <dbl>    <dbl> #> 1  9.12  2.21  0.594  1.35    0.803"},{"path":"https://mikkelvembye.github.io/VIVECampbell/reference/df_h.html","id":null,"dir":"Reference","previous_headings":"","what":"Degrees of freedom calculation for cluster bias correction for standardized mean differences — df_h","title":"Degrees of freedom calculation for cluster bias correction for standardized mean differences — df_h","text":"function calculates degrees freedom studies clustering, using Equation (E.21) WWC (2022, p. 171). Can also found h WWC (2021). df_type = \"Pustejovsky\", function calculates degrees freedom, using upsilon formula Pustejovsky (2016, find Cluster randomized trials section). See details .","code":""},{"path":"https://mikkelvembye.github.io/VIVECampbell/reference/df_h.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Degrees of freedom calculation for cluster bias correction for standardized mean differences — df_h","text":"","code":"df_h(N_total, ICC, avg_grp_size = NULL, n_clusters = NULL, df_type = \"WWC\")"},{"path":"https://mikkelvembye.github.io/VIVECampbell/reference/df_h.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Degrees of freedom calculation for cluster bias correction for standardized mean differences — df_h","text":"N_total Numerical value indicating total sample size study. ICC Numerical value indicating intra-class correlation (ICC) value. avg_grp_size Numerical value indicating average cluster size/ average number individuals per cluster. n_clusters Numerical value indicating number clusters. df_type Character indicating degrees freedom calculated. Default \"WWC\", uses WWCs Equation E.21 (2022, p. 171). Alternative \"Pustejovsky\", uses upsilon formula Pustejovsky (2016).","code":""},{"path":"https://mikkelvembye.github.io/VIVECampbell/reference/df_h.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Degrees of freedom calculation for cluster bias correction for standardized mean differences — df_h","text":"Returns numerical value indicating cluster adjusted degrees freedom.","code":""},{"path":"https://mikkelvembye.github.io/VIVECampbell/reference/df_h.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Degrees of freedom calculation for cluster bias correction for standardized mean differences — df_h","text":"clustering present \\(N-2\\) degrees freedom (\\(df\\)) rather liberal choice, partly overestimating small sample corrector \\(J\\) partly underestimating true variance (Hedges') \\(g_T\\). impact calculated \\(df\\) consequential small (sample) studies. overcome issues, \\(df\\) can instead calculated least different way. Works Clearinghouse suggests using following formula $$ h = \\dfrac{[(N-2)-2(n-1)\\rho]^2} {(N-2)(1-\\rho)^2 + n(N-2n)\\rho^2 + 2(N-2n)\\rho(1-\\rho)}$$ \\(N\\) total sample size, \\(n\\) average cluster size \\(\\rho\\) (imputed) intraclass correlation. Alternatively, Pustejovsky (2016) suggests using following formula calculate degrees freedom cluster randomized trials $$ \\upsilon = \\dfrac{n^2M(M-2)} {M[(n-1)\\rho^2 + 1]^2 + (M-2)(n-1)(1-\\rho^2)^2}$$ \\(M\\) number cluster can also calculated \\(N/n\\).","code":""},{"path":"https://mikkelvembye.github.io/VIVECampbell/reference/df_h.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Degrees of freedom calculation for cluster bias correction for standardized mean differences — df_h","text":"Read Taylor et al. (2020) understand use \\(g_T\\) notation. Find suggestions ICC values impute unknown (Hedges & Hedberg, 2007, 2013).","code":""},{"path":"https://mikkelvembye.github.io/VIVECampbell/reference/df_h.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Degrees of freedom calculation for cluster bias correction for standardized mean differences — df_h","text":"Hedges, L. V., & Hedberg, E. C. (2007). Intraclass correlation values planning group-randomized trials education. Educational Evaluation Policy Analysis, 29(1), 60–87. doi:10.3102/0162373707299706 Hedges, L. V., & Hedberg, E. C. (2013). Intraclass correlations covariate outcome correlations planning two- three-Level cluster-randomized experiments education. Evaluation Review, 37(6), 445–489. doi:10.1177/0193841X14529126 Pustejovsky (2016). Alternative formulas standardized mean difference. https://www.jepusto.com/alternative-formulas---smd/ Taylor, J.., Pigott, T.D., & Williams, R. (2020) Promoting knowledge accumulation intervention effects: Exploring strategies standardizing statistical approaches effect size reporting. Educational Researcher, 51(1), 72-80. doi:10.3102/0013189X211051319 Works Clearinghouse (2021). Supplement document Appendix E Works Clearinghouse procedures handbook, version 4.1 Institute Education Science. https://ies.ed.gov/ncee/wwc/Docs/referenceresources/WWC-41-Supplement-508_09212020.pdf Works Clearinghouse (2022). Works Clearinghouse Procedures Standards Handbook, Version 5.0. Institute Education Science. https://ies.ed.gov/ncee/wwc/Docs/referenceresources/Final_WWC-HandbookVer5_0-0-508.pdf","code":""},{"path":"https://mikkelvembye.github.io/VIVECampbell/reference/df_h.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Degrees of freedom calculation for cluster bias correction for standardized mean differences — df_h","text":"","code":"df_h(N_total = 100, ICC = 0.1, avg_grp_size = 5) #> [1] 94.4  df_h(N_total = 100, ICC = 0.1, avg_grp_size = 5, df_type = \"Pustejovsky\") #> [1] 92.29"},{"path":"https://mikkelvembye.github.io/VIVECampbell/reference/df_h_1armcluster.html","id":null,"dir":"Reference","previous_headings":"","what":"Degrees of freedom calculation for cluster bias correction when there is clustering in one treatment group only — df_h_1armcluster","title":"Degrees of freedom calculation for cluster bias correction when there is clustering in one treatment group only — df_h_1armcluster","text":"function calculates degrees freedom studies clustering one treatment group , using Equation (7) Hedges & Citkowicz (2015).","code":""},{"path":"https://mikkelvembye.github.io/VIVECampbell/reference/df_h_1armcluster.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Degrees of freedom calculation for cluster bias correction when there is clustering in one treatment group only — df_h_1armcluster","text":"","code":"df_h_1armcluster(N_total, ICC, N_grp, avg_grp_size = NULL, n_clusters = NULL)"},{"path":"https://mikkelvembye.github.io/VIVECampbell/reference/df_h_1armcluster.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Degrees of freedom calculation for cluster bias correction when there is clustering in one treatment group only — df_h_1armcluster","text":"N_total Numerical value indicating total sample size study. ICC Numerical value indicating intra-class correlation (ICC) value. N_grp Numerical value indicating sample size arm/group containing clustering. avg_grp_size Numerical value indicating average cluster size. n_clusters Numerical value indicating number clusters treatment group.","code":""},{"path":"https://mikkelvembye.github.io/VIVECampbell/reference/df_h_1armcluster.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Degrees of freedom calculation for cluster bias correction when there is clustering in one treatment group only — df_h_1armcluster","text":"Returns numerical value indicating cluster adjusted degrees freedom.","code":""},{"path":"https://mikkelvembye.github.io/VIVECampbell/reference/df_h_1armcluster.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Degrees of freedom calculation for cluster bias correction when there is clustering in one treatment group only — df_h_1armcluster","text":"clustering present \\(N-2\\) degrees freedom (\\(df\\)) rather liberal choice, partly overestimating small sample corrector \\(J\\) partly underestimating true variance (Hedges') \\(g_T\\). impact calculated \\(df\\) consequential small (sample) studies. overcome issues, Hedges & Citkowicz (2015) suggest obtaining degrees freedom $$ h = \\dfrac{[(N-2)(1-\\rho) + (N^T-n)\\rho]^2} {(N-2)(1-\\rho)^2 + (N^T-n)n\\rho^2 + 2(N^T-n)(1-\\rho)\\rho}$$ \\(N\\) total sample size, \\(N^T\\) sample size treatment group, containg clustering, \\(n\\) average cluster size \\(\\rho\\) (imputed) intraclass correlation.","code":""},{"path":"https://mikkelvembye.github.io/VIVECampbell/reference/df_h_1armcluster.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Degrees of freedom calculation for cluster bias correction when there is clustering in one treatment group only — df_h_1armcluster","text":"Read Taylor et al. (2020) understand use \\(g_T\\) notation. Find suggestions ICC values impute unknown (Hedges & Hedberg, 2007, 2013).","code":""},{"path":"https://mikkelvembye.github.io/VIVECampbell/reference/df_h_1armcluster.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Degrees of freedom calculation for cluster bias correction when there is clustering in one treatment group only — df_h_1armcluster","text":"Hedges, L. V., & Citkowicz, M (2015). Estimating effect size clustering one treatment groups. Behavior Research Methods, 47(4), 1295-1308. doi:10.3758/s13428-014-0538-z Hedges, L. V., & Hedberg, E. C. (2007). Intraclass correlation values planning group-randomized trials education. Educational Evaluation Policy Analysis, 29(1), 60–87. doi:10.3102/0162373707299706 Hedges, L. V., & Hedberg, E. C. (2013). Intraclass correlations covariate outcome correlations planning two- three-Level cluster-randomized experiments education. Evaluation Review, 37(6), 445–489. doi:10.1177/0193841X14529126 Taylor, J.., Pigott, T.D., & Williams, R. (2020) Promoting knowledge accumulation intervention effects: Exploring strategies standardizing statistical approaches effect size reporting. Educational Researcher, 51(1), 72-80. doi:10.3102/0013189X211051319","code":""},{"path":"https://mikkelvembye.github.io/VIVECampbell/reference/df_h_1armcluster.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Degrees of freedom calculation for cluster bias correction when there is clustering in one treatment group only — df_h_1armcluster","text":"","code":"df <- df_h_1armcluster(N_total = 100, ICC = 0.1, N_grp = 60, avg_grp_size = 5) df #> [1] 95.4   # Testing function N <- 100 rho <- 0.1 NT <- 60 n <- 5  df_raw <- ((N-2)*(1-rho) + (NT-n)*rho)^2 /           ( (N-2)*(1-rho)^2 + (NT-n)*n*rho^2 + 2*(NT-n)*(1-rho)*rho )  round(df_raw, 2) #> [1] 95.4"},{"path":"https://mikkelvembye.github.io/VIVECampbell/reference/eta_1armcluster.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculating the design effect to cluster bias adjusted sampling variances when there is clustering in one treatment group only — eta_1armcluster","title":"Calculating the design effect to cluster bias adjusted sampling variances when there is clustering in one treatment group only — eta_1armcluster","text":"function calculates design effect used cluster bias adjust sampling variance estimates take account clustering one treatment group. design effect given second term Equation (6) Hedges & Citkowitz (2015, p. 6). design effect denoted \\(\\eta\\) WWC (2021). notion used gave name function.","code":""},{"path":"https://mikkelvembye.github.io/VIVECampbell/reference/eta_1armcluster.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculating the design effect to cluster bias adjusted sampling variances when there is clustering in one treatment group only — eta_1armcluster","text":"","code":"eta_1armcluster(N_total, Nc, avg_grp_size, ICC, sqrt = FALSE)"},{"path":"https://mikkelvembye.github.io/VIVECampbell/reference/eta_1armcluster.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculating the design effect to cluster bias adjusted sampling variances when there is clustering in one treatment group only — eta_1armcluster","text":"N_total Numerical value indicating total sample size study. Nc Numerical value indicating sample size arm/group contain clustering. avg_grp_size Numerical value indicating average cluster size. ICC Numerical value indicating intra-class correlation (ICC) value. sqrt Logical indicating square root \\(\\eta\\) calculated. Default FALSE.","code":""},{"path":"https://mikkelvembye.github.io/VIVECampbell/reference/eta_1armcluster.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculating the design effect to cluster bias adjusted sampling variances when there is clustering in one treatment group only — eta_1armcluster","text":"Returns numerical value design effect \\(\\eta\\) clustering one treatment group .","code":""},{"path":"https://mikkelvembye.github.io/VIVECampbell/reference/eta_1armcluster.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculating the design effect to cluster bias adjusted sampling variances when there is clustering in one treatment group only — eta_1armcluster","text":"calculating effect sizes cluster-designed studies properly account clustering one treatment group, recommended (Hedges, 2007, 2011; Hedges & Citkowitz, 2015; WWC, 2021) multiply design effect, \\(\\eta\\) first term variance \\(g_T\\) captures contribution variance mean effect difference. design effect clustering one treatment group given $$\\eta  = 1 + \\left( \\dfrac{nN^C}{N}-1 \\right)\\rho $$ \\(N\\) total samples size, \\(N^C\\) sample size group without clustering, \\(n\\) average cluster size, \\(\\rho\\) (often imputed) intraclass correlation. Multiplying design effect posttest measures illustrate procedure, let naive estimator Hedges' \\(g\\) $$g_{naive} = J\\times \\left(\\dfrac{\\bar{Y}^T_{\\bullet\\bullet} - \\bar{Y}^C_{\\bullet}}{S_T} \\right)$$ \\(J = 1 - 3/(4df-1)\\), \\(\\bar{Y}^T_{\\bullet\\bullet}\\) average treatment effect treatment group containing clustering, \\(\\bar{Y}^C_{\\bullet}\\) average treatment effect group without clustering, \\(S_T\\) standard deviation ignoring clustering. account fact \\(S_T\\) systematically underestimates true standard deviation, \\(\\sigma_T\\), making \\(g\\) larger true values \\(g\\), .e., \\(\\delta\\), cluster-adjusted effect size can obtained $$g_T = g_{naive}\\sqrt{1 - \\dfrac{(N^C+n-2)\\rho}{N-2}}$$ study properly adjust clustering, sampling variance \\(g_T\\) (based posttest measures ) given $$v_{g_T} = \\left(\\dfrac{1}{N^T} + \\dfrac{1}{N^C}\\right) \\eta + \\dfrac{g^2_T}{2h} $$ \\(N^T\\) sample size treatment group containing clustering \\(h\\) given $$ h = \\dfrac{[(N-2)(1-\\rho) + (N^T-n)\\rho]^2} {(N-2)(1-\\rho)^2 + (N^T-n)n\\rho^2 + 2(N^T-n)(1-\\rho)\\rho}$$ \\(N\\) total sample size. See also df_h_1armcluster. reason multiply \\(J^2\\) \\(v_{g_T}\\), otherwise suggested Borenstein et al. (2009, p. 27) Hedges & Citkowitz (2015, p. 1299), Hedges et al. (2023, p. 12) showed simulation multiplying \\(J^2\\) \\(v_{g_T}\\) underestimates true variance. Multiplying design effect adjusted measures also use design effect \\(\\eta\\) cluster-bias adjustment variance estimates pre-test /covariate adjusted measures. See Table 1 . Table 1Sampling variance estimates \\(g_T\\) across various models handling cluster, estimation techniques, reported quantities. Note: \\(R^2\\) \"multiple correlation covariates outcome\" (WWC, 2021), \\(\\gamma = 1 - (N^C+n-2)\\rho/(N-2)\\), see eta_1armcluster, \\(r\\) pre-posttest correlation, \\(q\\) number covariates. Std. = standardized. \"often desired practice adjust multiple baseline characteristics. problem \\(q\\) covariates straightforward extension single covariate case (...): correlation coefficient estimate \\(r\\) now obtained taking square root coefficient multiple determination, \\(R^2\\)\" (Hedges et al. 2023, p. 17) \\(df = h-q\\). Multiplying design effect effect size difference--differences Furthermore, \\(\\eta\\) can used correct effect size difference--differences given Table 2 Table 2Sampling variance estimates effect size difference--differences","code":""},{"path":"https://mikkelvembye.github.io/VIVECampbell/reference/eta_1armcluster.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Calculating the design effect to cluster bias adjusted sampling variances when there is clustering in one treatment group only — eta_1armcluster","text":"Read Taylor et al. (2020) understand use \\(g_T\\) notation. Find suggestions ICC values impute unknown (Hedges & Hedberg, 2007, 2013).","code":""},{"path":"https://mikkelvembye.github.io/VIVECampbell/reference/eta_1armcluster.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Calculating the design effect to cluster bias adjusted sampling variances when there is clustering in one treatment group only — eta_1armcluster","text":"Borenstein, M., Hedges, L. V., Higgins, J. P. T., & Rothstein, H. R. (2009). Introduction meta-analysis (1st ed.). John Wiley & Sons. Hedges, L. V. (2007). Effect sizes cluster-randomized designs. Journal Educational Behavioral Statistics, 32(4), 341–370. doi:10.3102/1076998606298043 Hedges, L. V. (2011). Effect sizes three-level cluster-randomized experiments. Journal Educational Behavioral Statistics, 36(3), 346–380. doi:10.3102/1076998610376617 Hedges, L. V., & Citkowicz, M (2015). Estimating effect size clustering one treatment groups. Behavior Research Methods, 47(4), 1295-1308. doi:10.3758/s13428-014-0538-z Hedges, L. V., & Hedberg, E. C. (2007). Intraclass correlation values planning group-randomized trials education. Educational Evaluation Policy Analysis, 29(1), 60–87. doi:10.3102/0162373707299706 Hedges, L. V., & Hedberg, E. C. (2013). Intraclass correlations covariate outcome correlations planning two- three-Level cluster-randomized experiments education. Evaluation Review, 37(6), 445–489. doi:10.1177/0193841X14529126 Hedges, L. V, Tipton, E., Zejnullahi, R., & Diaz, K. G. (2023). Effect sizes ANCOVA difference--differences designs. British Journal Mathematical Statistical Psychology. doi:10.1111/bmsp.12296 Taylor, J.., Pigott, T.D., & Williams, R. (2020) Promoting knowledge accumulation intervention effects: Exploring strategies standardizing statistical approaches effect size reporting. Educational Researcher, 51(1), 72-80. doi:10.3102/0013189X211051319 Works Clearinghouse (2021). Supplement document Appendix E Works Clearinghouse procedures handbook, version 4.1 Institute Education Science. https://ies.ed.gov/ncee/wwc/Docs/referenceresources/WWC-41-Supplement-508_09212020.pdf","code":""},{"path":[]},{"path":"https://mikkelvembye.github.io/VIVECampbell/reference/eta_1armcluster.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculating the design effect to cluster bias adjusted sampling variances when there is clustering in one treatment group only — eta_1armcluster","text":"","code":"N <- 100 Nc <- 40 n <- 5 rho <- 0.1  eta_1armcluster(N_total = N, Nc = Nc, avg_grp_size = n, ICC = rho) #> [1] 1.1  # Testing function round(1 + (n*Nc/N - 1)*rho, 3) #> [1] 1.1"},{"path":"https://mikkelvembye.github.io/VIVECampbell/reference/fadeout.html","id":null,"dir":"Reference","previous_headings":"","what":"Fadeout data — fadeout","title":"Fadeout data — fadeout","text":"Data four systematic reviews school interventions implemented kindergarten Grade 12 (Dietrichson et al., 2017, 2021; Dietrichson, Filges, et al., 2020; Filges, Sonne-Schmidt, & Nielsen, 2018). sample included data consist subset 29 studies reviews included post test least one follow-test. Tests standardized tests reading mathematics. interventions targeted (selected indicated) students risk academic difficulties.","code":""},{"path":"https://mikkelvembye.github.io/VIVECampbell/reference/fadeout.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fadeout data — fadeout","text":"","code":"fadeout"},{"path":"https://mikkelvembye.github.io/VIVECampbell/reference/fadeout.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Fadeout data — fadeout","text":"tibble 548 rows/studies 136 variables/columns","code":""},{"path":"https://mikkelvembye.github.io/VIVECampbell/reference/fadeout.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fadeout data — fadeout","text":"Dietrichson, J., Bøg, M., Filges, T., & Klint Jørgensen, .-M. (2017). Academic interventions elementary middle school students low socioeconomic status: systematic review meta-analysis. Review Educational Research, 87 (2), 243–282. doi:10.3102/0034654316687036 Dietrichson, J., Filges, T., Klokker, R. H., Viinholt, B. C., Bøg, M., & Jensen, U. H. (2020). Targeted school-based interventions improving reading mathematics students , risk , academic difficulties grades 7–12: systematic review. Campbell Systematic Reviews, 16(2). doi:10.1002/cl2.1081 Dietrichson, J., Filges, T., Seerup, J. K., Klokker, R. H., Viinholt, B. C. ., Bøg, M., & Eiberg, M. (2021). Targeted school-based interventions improving reading mathematics students risk academic difficulties grades K-6: systematic review. Campbell Systematic Reviews, 17(2), e1152. doi:10.1002/cl2.1152 Filges, T., Sonne-Schmidt, C. S., & Nielsen, B. C. V. (2018). Small class sizes improving student achievement primary secondary schools: systematic review. Campbell Systematic Reviews, 14(1), 1-107. doi:10.4073/csr.2018.10","code":""},{"path":[]},{"path":"https://mikkelvembye.github.io/VIVECampbell/reference/gamma_1armcluster.html","id":null,"dir":"Reference","previous_headings":"","what":"Small number of clusters correction when there is clustering in one treatment group only — gamma_1armcluster","title":"Small number of clusters correction when there is clustering in one treatment group only — gamma_1armcluster","text":"function calculates small cluster-design adjustment factor can used adjusted effect sizes (independently clustering handled) sampling variances cluster-design studies adequately handles clustering. factor can found second term Equation (5) Hedges & Citkowicz (2015, p. 1298). factor denoted \\(\\gamma\\) WWC (2021). notion used gave name function.","code":""},{"path":"https://mikkelvembye.github.io/VIVECampbell/reference/gamma_1armcluster.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Small number of clusters correction when there is clustering in one treatment group only — gamma_1armcluster","text":"","code":"gamma_1armcluster(N_total, Nc, avg_grp_size, ICC, sqrt = TRUE)"},{"path":"https://mikkelvembye.github.io/VIVECampbell/reference/gamma_1armcluster.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Small number of clusters correction when there is clustering in one treatment group only — gamma_1armcluster","text":"N_total Numerical value indicating total sample size study. Nc Numerical value indicating sample size arm/group contain clustering. avg_grp_size Numerical value indicating average cluster size. ICC Numerical value indicating intra-class correlation (ICC) value. sqrt Logical indicating square root \\(\\gamma\\) calculated. Default TRUE.","code":""},{"path":"https://mikkelvembye.github.io/VIVECampbell/reference/gamma_1armcluster.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Small number of clusters correction when there is clustering in one treatment group only — gamma_1armcluster","text":"Returns numerical value cluster-design adjustment factor, \\(\\gamma\\).","code":""},{"path":"https://mikkelvembye.github.io/VIVECampbell/reference/gamma_1armcluster.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Small number of clusters correction when there is clustering in one treatment group only — gamma_1armcluster","text":"calculating effect sizes cluster-designed studies, recommended (Hedges, 2007, 2011; Hedges & Citkowitz, 2015; WWC, 2021) add adjustment factor, \\(\\gamma\\) \\(d\\) whether cluster adequately handled studies. Even clustering adequately handled, WWC also recommend use \\(\\gamma\\) small number clusters correction variance component. adjustment factor \\(\\gamma\\) clustering one treatment group given $$\\gamma  = 1 - \\dfrac{(N^C+n-2)\\rho}{N-2}$$ \\(N\\) total samples size, \\(N^C\\) sample size group without clustering, \\(n\\) average cluster size, \\(\\rho\\) (often imputed) intraclass correlation. Multiplying \\(\\gamma\\) posttest measures illustrate procedure, let naive estimator Hedges' \\(g\\) $$g_{naive} = J\\times \\left(\\dfrac{\\bar{Y}^T_{\\bullet\\bullet} - \\bar{Y}^C_{\\bullet}}{S_T} \\right)$$ \\(J = 1 - 3/(4df-1)\\), \\(\\bar{Y}^T_{\\bullet\\bullet}\\) average treatment effect treatment group containing clustering, \\(\\bar{Y}^C_{\\bullet}\\) average treatment effect group without clustering, \\(S_T\\) standard deviation ignoring clustering. account fact \\(S_T\\) systematically underestimates true standard deviation, \\(\\sigma_T\\), making \\(g\\) larger true values \\(g\\), .e., \\(\\delta\\), cluster-adjusted effect size can obtained $$g_T = g_{naive}\\sqrt{\\gamma}$$ study properly adjusted clustering, sampling variance \\(g_T\\) (based posttest measures ) given $$v_{g_T} = \\left(\\dfrac{1}{N^T} + \\dfrac{1}{N^C}\\right) \\gamma + \\dfrac{g^2_T}{2h} $$ \\(N^T\\) sample size treatment group containing clustering \\(h\\) given $$ h = \\dfrac{[(N-2)(1-\\rho) + (N^T-n)\\rho]^2} {(N-2)(1-\\rho)^2 + (N^T-n)n\\rho^2 + 2(N^T-n)(1-\\rho)\\rho}$$ \\(N\\) total sample size. See also df_h_1armcluster. reason multiply \\(J^2\\) \\(v_{g_T}\\), otherwise suggested Borenstein et al. (2009, p. 27) Hedges & Citkowitz (2015, p. 1299), Hedges et al. (2023, p. 12) showed simulation multiplying \\(J^2\\) \\(v_{g_T}\\) underestimates true variance. Multiplying \\(\\gamma\\) adjusted measures also use small number cluster adjustment factor \\(\\gamma\\) cluster adjustment variance estimates pre-test /covariate adjusted measures. See Table 1 . Table 1Sampling variance estimates \\(g_T\\) across various models handling cluster, estimation techniques, reported quantities. Note: \\(R^2\\) \"multiple correlation covariates outcome\" (WWC, 2021), \\(\\eta = 1 + [(nN^C/N)-1]\\rho\\), see eta_1armcluster, \\(r\\) pre-posttest correlation, \\(q\\) number covariates. Std. = standardized. \"often desired practice adjust multiple baseline characteristics. problem \\(q\\) covariates straightforward extension single covariate case (...): correlation coefficient estimate \\(r\\) now obtained taking square root coefficient multiple determination, \\(R^2\\)\" (Hedges et al. 2023, p. 17) \\(df = h-q\\). Multiplying \\(\\gamma\\) effect size difference--differences Furthermore, \\(\\gamma\\) can used correct effect size difference--differences given Table 2 Table 2Sampling variance estimates effect size difference--differences","code":""},{"path":"https://mikkelvembye.github.io/VIVECampbell/reference/gamma_1armcluster.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Small number of clusters correction when there is clustering in one treatment group only — gamma_1armcluster","text":"Read Taylor et al. (2020) understand use \\(g_T\\) notation. Find suggestions ICC values impute unknown (Hedges & Hedberg, 2007, 2013).","code":""},{"path":"https://mikkelvembye.github.io/VIVECampbell/reference/gamma_1armcluster.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Small number of clusters correction when there is clustering in one treatment group only — gamma_1armcluster","text":"Borenstein, M., Hedges, L. V., Higgins, J. P. T., & Rothstein, H. R. (2009). Introduction meta-analysis (1st ed.). John Wiley & Sons. Hedges, L. V. (2007). Effect sizes cluster-randomized designs. Journal Educational Behavioral Statistics, 32(4), 341–370. doi:10.3102/1076998606298043 Hedges, L. V. (2011). Effect sizes three-level cluster-randomized experiments. Journal Educational Behavioral Statistics, 36(3), 346–380. doi:10.3102/1076998610376617 Hedges, L. V., & Citkowicz, M (2015). Estimating effect size clustering one treatment groups. Behavior Research Methods, 47(4), 1295-1308. doi:10.3758/s13428-014-0538-z Hedges, L. V., & Hedberg, E. C. (2007). Intraclass correlation values planning group-randomized trials education. Educational Evaluation Policy Analysis, 29(1), 60–87. doi:10.3102/0162373707299706 Hedges, L. V., & Hedberg, E. C. (2013). Intraclass correlations covariate outcome correlations planning two- three-Level cluster-randomized experiments education. Evaluation Review, 37(6), 445–489. doi:10.1177/0193841X14529126 Hedges, L. V, Tipton, E., Zejnullahi, R., & Diaz, K. G. (2023). Effect sizes ANCOVA difference--differences designs. British Journal Mathematical Statistical Psychology. doi:10.1111/bmsp.12296 Taylor, J.., Pigott, T.D., & Williams, R. (2020) Promoting knowledge accumulation intervention effects: Exploring strategies standardizing statistical approaches effect size reporting. Educational Researcher, 51(1), 72-80. doi:10.3102/0013189X211051319 Works Clearinghouse (2021). Supplement document Appendix E Works Clearinghouse procedures handbook, version 4.1 Institute Education Science. https://ies.ed.gov/ncee/wwc/Docs/referenceresources/WWC-41-Supplement-508_09212020.pdf","code":""},{"path":[]},{"path":"https://mikkelvembye.github.io/VIVECampbell/reference/gamma_1armcluster.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Small number of clusters correction when there is clustering in one treatment group only — gamma_1armcluster","text":"","code":"N <- 100 Nc <- 40 n <- 5 rho <- 0.1  gamma_1armcluster(N_total = N, Nc = Nc, avg_grp_size = n, ICC = rho) #> [1] 0.978  # Testing function sqrt(1 - (((Nc + n-2)*rho)/(N-2))) |> round(3) #> [1] 0.978"},{"path":"https://mikkelvembye.github.io/VIVECampbell/reference/map_rho_impact.html","id":null,"dir":"Reference","previous_headings":"","what":"Conduct sensitivity analyses across various values of the assumed sample correlation on the overall average effect in the CHE-RVE model — map_rho_impact","title":"Conduct sensitivity analyses across various values of the assumed sample correlation on the overall average effect in the CHE-RVE model — map_rho_impact","text":"Conduct sensitivity analyses across various values assumed sample correlation overall average effect CHE-RVE model","code":""},{"path":"https://mikkelvembye.github.io/VIVECampbell/reference/map_rho_impact.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Conduct sensitivity analyses across various values of the assumed sample correlation on the overall average effect in the CHE-RVE model — map_rho_impact","text":"","code":"map_rho_impact(   data,   yi,   vi,   studyid,   r = seq(0, 0.9, 0.1),   random = \"~ 1 | studyid / esid\",   smooth_vi = TRUE )"},{"path":"https://mikkelvembye.github.io/VIVECampbell/reference/map_rho_impact.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Conduct sensitivity analyses across various values of the assumed sample correlation on the overall average effect in the CHE-RVE model — map_rho_impact","text":"data Data frame including relevant data function. yi Vector length k observed effect sizes/outcomes. vi Sampling variance estimates observed effect sizes. studyid Study ID specifying cluster structure included studies. r numerical value vector specifying assumed sampling correlation within-study effect size estimates. Default seq(0, .9, .1). random Formula specify random-effects structure model. Default \"~ 1 | studyid / esid\", amounts fitting correlated-hierarchical effects (CHE) model. smooth_vi Logical specifying whether take average vi within study. Default TRUE.","code":""},{"path":"https://mikkelvembye.github.io/VIVECampbell/reference/map_rho_impact.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Conduct sensitivity analyses across various values of the assumed sample correlation on the overall average effect in the CHE-RVE model — map_rho_impact","text":"tibble class map_rho information estimated beta value, confidence prediction intervals, well variance components across specified values assumed sampling correlation.","code":""},{"path":"https://mikkelvembye.github.io/VIVECampbell/reference/map_rho_impact.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Conduct sensitivity analyses across various values of the assumed sample correlation on the overall average effect in the CHE-RVE model — map_rho_impact","text":"","code":"Diet_dat <- Dietrichson2021_data |> dplyr::mutate(vg = SE_g^2)  map_rho_impact(  data = head(Diet_dat, 100),  yi = Effectsize_g,  vi = vg,  studyid = Study_ID ) #> # A tibble: 10 × 11 #>     beta   se_b   ci_l  ci_u   pi_l  pi_u     omega   tau total_sd   rho avg_var #>    <dbl>  <dbl>  <dbl> <dbl>  <dbl> <dbl>     <dbl> <dbl>    <dbl> <dbl> <lgl>   #>  1 0.237 0.0741 0.0816 0.393 -0.415 0.889   7.58e-6 0.301    0.301   0   TRUE    #>  2 0.234 0.0736 0.0798 0.389 -0.411 0.879   7.16e-2 0.289    0.298   0.1 TRUE    #>  3 0.232 0.0731 0.0784 0.385 -0.409 0.873   1.07e-1 0.276    0.296   0.2 TRUE    #>  4 0.229 0.0726 0.0768 0.382 -0.408 0.866   1.31e-1 0.263    0.294   0.3 TRUE    #>  5 0.227 0.0721 0.0752 0.378 -0.406 0.860   1.51e-1 0.250    0.292   0.4 TRUE    #>  6 0.224 0.0716 0.0736 0.375 -0.406 0.854   1.69e-1 0.236    0.291   0.5 TRUE    #>  7 0.222 0.0712 0.0721 0.372 -0.405 0.849   1.86e-1 0.222    0.289   0.6 TRUE    #>  8 0.220 0.0707 0.0705 0.369 -0.406 0.845   2.01e-1 0.207    0.288   0.7 TRUE    #>  9 0.217 0.0703 0.0690 0.366 -0.407 0.842   2.16e-1 0.190    0.288   0.8 TRUE    #> 10 0.215 0.0699 0.0676 0.363 -0.410 0.840   2.30e-1 0.173    0.287   0.9 TRUE"},{"path":"https://mikkelvembye.github.io/VIVECampbell/reference/plot_rho_impact.html","id":null,"dir":"Reference","previous_headings":"","what":"Plotting the impact of the assumed sampling correlation on the overall average effect size estimate — plot_rho_impact","title":"Plotting the impact of the assumed sampling correlation on the overall average effect size estimate — plot_rho_impact","text":"Creates plot showing impact assumed sampling correlation (\\(\\rho\\)) overall average effect size variance estimation.","code":""},{"path":"https://mikkelvembye.github.io/VIVECampbell/reference/plot_rho_impact.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plotting the impact of the assumed sampling correlation on the overall average effect size estimate — plot_rho_impact","text":"","code":"plot_rho_impact(   data,   rho_used,   prediction_interval = FALSE,   ylab_beta = NULL,   var_breaks = NULL )"},{"path":"https://mikkelvembye.github.io/VIVECampbell/reference/plot_rho_impact.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plotting the impact of the assumed sampling correlation on the overall average effect size estimate — plot_rho_impact","text":"data Data/object plot made. rho_used Numerical value indicating (assumed) sampling correlation used fit main CHE-RVE model. prediction_interval Logical indicting whether plot showing impact sampling correlation prediction interval estimation. ylab_beta Optional character y-axis label overall mean effect plot var_breaks Optional vector setting y-axis breaks variance plot.","code":""},{"path":"https://mikkelvembye.github.io/VIVECampbell/reference/plot_rho_impact.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plotting the impact of the assumed sampling correlation on the overall average effect size estimate — plot_rho_impact","text":"ggplot object","code":""},{"path":"https://mikkelvembye.github.io/VIVECampbell/reference/plot_rho_impact.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plotting the impact of the assumed sampling correlation on the overall average effect size estimate — plot_rho_impact","text":"Inspiration plot found Pustejovsky Tipton (2021).","code":""},{"path":"https://mikkelvembye.github.io/VIVECampbell/reference/plot_rho_impact.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Plotting the impact of the assumed sampling correlation on the overall average effect size estimate — plot_rho_impact","text":"Pustejovsky, J. E., & Tipton, E. (2021). Meta-analysis robust variance estimation: Expanding range working models. Prevention Science, 23(1), 425–438. doi:10.1007/s11121-021-01246-3","code":""},{"path":[]},{"path":"https://mikkelvembye.github.io/VIVECampbell/reference/plot_rho_impact.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plotting the impact of the assumed sampling correlation on the overall average effect size estimate — plot_rho_impact","text":"","code":"Diet_dat <- Dietrichson2021_data |> dplyr::mutate(vg = SE_g^2)  map_rho_impact(   data = head(Diet_dat, 100),   yi = Effectsize_g,   vi = vg,   studyid = Study_ID ) |> plot_rho_impact(rho_used = 0.7, var_breaks = seq(0, 0.35, 0.05))"},{"path":"https://mikkelvembye.github.io/VIVECampbell/reference/plot_rho_impact.map_rho.html","id":null,"dir":"Reference","previous_headings":"","what":"Plotting the impact of the assumed sampling correlation on the overall average effect size estimate — plot_rho_impact.map_rho","title":"Plotting the impact of the assumed sampling correlation on the overall average effect size estimate — plot_rho_impact.map_rho","text":"Creates plot showing impact assumed sampling correlation (\\(\\rho\\)) overall average effect size variance estimation.","code":""},{"path":"https://mikkelvembye.github.io/VIVECampbell/reference/plot_rho_impact.map_rho.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plotting the impact of the assumed sampling correlation on the overall average effect size estimate — plot_rho_impact.map_rho","text":"","code":"# S3 method for class 'map_rho' plot_rho_impact(   data,   rho_used,   prediction_interval = FALSE,   ylab_beta = NULL,   var_breaks = NULL )"},{"path":"https://mikkelvembye.github.io/VIVECampbell/reference/plot_rho_impact.map_rho.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plotting the impact of the assumed sampling correlation on the overall average effect size estimate — plot_rho_impact.map_rho","text":"data Data/object plot made. Much class map_rho. rho_used Numerical value indicating (assumed) sampling correlation used fit main CHE-RVE model. prediction_interval Logical indicting whether plot showing impact sampling correlation prediction interval estimation. ylab_beta Optional character y-axis label overall mean effect plot. var_breaks Optional vector setting y-axis breaks variance plot.","code":""},{"path":"https://mikkelvembye.github.io/VIVECampbell/reference/plot_rho_impact.map_rho.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plotting the impact of the assumed sampling correlation on the overall average effect size estimate — plot_rho_impact.map_rho","text":"ggplot object","code":""},{"path":"https://mikkelvembye.github.io/VIVECampbell/reference/plot_rho_impact.map_rho.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plotting the impact of the assumed sampling correlation on the overall average effect size estimate — plot_rho_impact.map_rho","text":"Inspiration plot found Pustejovsky Tipton (2021).","code":""},{"path":"https://mikkelvembye.github.io/VIVECampbell/reference/plot_rho_impact.map_rho.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Plotting the impact of the assumed sampling correlation on the overall average effect size estimate — plot_rho_impact.map_rho","text":"Pustejovsky, J. E., & Tipton, E. (2021). Meta-analysis robust variance estimation: Expanding range working models. Prevention Science, 23(1), 425–438. doi:10.1007/s11121-021-01246-3","code":""},{"path":[]},{"path":"https://mikkelvembye.github.io/VIVECampbell/reference/plot_rho_impact.map_rho.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plotting the impact of the assumed sampling correlation on the overall average effect size estimate — plot_rho_impact.map_rho","text":"","code":"Diet_dat <- Dietrichson2021_data |> dplyr::mutate(vg = SE_g^2)  map_rho_impact(   data = head(Diet_dat, 100),   yi = Effectsize_g,   vi = vg,   studyid = Study_ID ) |> plot_rho_impact(rho_used = 0.7, var_breaks = seq(0, 0.35, 0.05))"},{"path":"https://mikkelvembye.github.io/VIVECampbell/reference/vgt_smd_1armcluster.html","id":null,"dir":"Reference","previous_headings":"","what":"Variance calculation when there is clustering in one treatment group only — vgt_smd_1armcluster","title":"Variance calculation when there is clustering in one treatment group only — vgt_smd_1armcluster","text":"function calculates sampling variance estimates effect sizes obtained cluster-designed studies. include measures sampling variance, modified variance estimate publication bias testing, variance-stabilized transformed effect size variance presented Pustejovsky & Rodgers (2019).","code":""},{"path":"https://mikkelvembye.github.io/VIVECampbell/reference/vgt_smd_1armcluster.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Variance calculation when there is clustering in one treatment group only — vgt_smd_1armcluster","text":"","code":"vgt_smd_1armcluster(   N_cl_grp,   N_ind_grp,   avg_grp_size,   ICC,   g,   model = c(\"posttest\", \"ANCOVA\", \"emmeans\", \"DiD\", \"reg_coef\", \"std_reg_coef\"),   cluster_adj = FALSE,   prepost_cor = NULL,   F_val = NULL,   t_val = NULL,   SE = NULL,   SD = NULL,   SE_std = NULL,   R2 = NULL,   q = 1,   add_name_to_vars = NULL,   vars = dplyr::everything() )"},{"path":"https://mikkelvembye.github.io/VIVECampbell/reference/vgt_smd_1armcluster.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Variance calculation when there is clustering in one treatment group only — vgt_smd_1armcluster","text":"N_cl_grp Numerical value indicating sample size arm/group containing clustering. N_ind_grp Numerical value indicating sample size arm/group contain clustering. avg_grp_size Numerical value indicating average cluster size. ICC Numerical value indicating (imputed) intra-class correlation. g Numerical values indicating estimated effect size (Hedges' g). model Character indicating model effect size estimate obtained. See details. cluster_adj Logical indicating clustering adequately handled model/study. Default FALSE. prepost_cor Numerical value indicating pre-posttest correlation. F_val Numerical value indicating reported F statistics value. Note \\(F = t^2\\). t_val Numerical value indicating reported t statistics value. SE Numerical value indicating (reported) non-standardized standard error. SD Numerical value indicating pooled standard deviation. SE_std Numerical value indicating (reported) standardized standard error (SE). R2 Numerical value indicating (reported) \\(R^2\\) value analysis model. q Numerical value indicating number covariates. add_name_to_vars Optional character string added variables names generated tibble. vars Variables reported. Default NULL. See Value section details.","code":""},{"path":"https://mikkelvembye.github.io/VIVECampbell/reference/vgt_smd_1armcluster.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Variance calculation when there is clustering in one treatment group only — vgt_smd_1armcluster","text":"add_name_to_vars = NULL, function returns tibble following variables: gt cluster small sample adjusted effect size estimate. vgt cluster adjusted sampling variance estimate \\(gt\\). Wgt cluster adjusted samplingvariance estimate \\(gt\\), without second term variance formula, given Eq. (2) Pustejovsky & Rodgers (2019). hg variance-stabilizing transformed effect size. See Eq. (3) Pustejovsky & Rodgers (2019) vhg approximate sampling variance hg h degrees freedom given Eq (7) Hedges & Citkowicz (2015, p. 1298). See df_h_1armcluster. df degrees freedom. none one covariate \\(df = h\\). otherwise two covariates \\(df = h - q\\). n_covariates number covariates model, defined \\(q\\) Hedges et al. (2023). var_term1 Unadjusted measure first term variance formula. adj_fct Indicating whether \\(\\eta\\) \\(\\gamma\\) used adjust variance. whether studies handle clustering inadequately . adj_value Estimated value adjustment factor.","code":""},{"path":"https://mikkelvembye.github.io/VIVECampbell/reference/vgt_smd_1armcluster.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Variance calculation when there is clustering in one treatment group only — vgt_smd_1armcluster","text":"Table 1 illustrates cluster adjustment variance estimates pre-test /covariate-adjusted measures can calculated vgt_smd_1armcluster() Table 1Sampling variance estimates \\(g_T\\) across various models handling cluster, estimation techniques, reported quantities. Note: \\(R^2\\) \"multiple correlation covariates outcome\" (WWC, 2021), \\(\\eta = 1 - (N^C+n-2)\\rho/(N-2)\\), see eta_1armcluster, \\(\\gamma = 1 - (N^C+n-2)\\rho/(N-2)\\), see eta_1armcluster, \\(r\\) pre-posttest correlation, \\(q\\) number covariates. Std. = standardized. \"often desired practice adjust multiple baseline characteristics. problem \\(q\\) covariates straightforward extension single covariate case (...): correlation coefficient estimate \\(r\\) now obtained taking square root coefficient multiple determination, \\(R^2\\)\" (Hedges et al. 2023, p. 17) \\(df = h-q\\). Calculating modified measures variance  publication bias testing Table 2Sampling variance estimates \\(g_T\\) across various models handling cluster, estimation techniques, reported quantities. Note: \\(R^2\\) \"multiple correlation covariates outcome\" (WWC, 2021), \\(\\eta = 1 - (N^C+n-2)\\rho/(N-2)\\), see eta_1armcluster, \\(\\gamma = 1 - (N^C+n-2)\\rho/(N-2)\\), see eta_1armcluster, \\(r\\) pre-posttest correlation. Std. = standardized. \"often desired practice adjust multiple baseline characteristics. problem \\(q\\) covariates straightforward extension single covariate case (...): correlation coefficient estimate \\(r\\) now obtained taking square root coefficient multiple determination, \\(R^2\\)\" (Hedges et al. 2023, p. 17) \\(df = h-q\\).","code":""},{"path":"https://mikkelvembye.github.io/VIVECampbell/reference/vgt_smd_1armcluster.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Variance calculation when there is clustering in one treatment group only — vgt_smd_1armcluster","text":"Insert","code":""},{"path":"https://mikkelvembye.github.io/VIVECampbell/reference/vgt_smd_1armcluster.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Variance calculation when there is clustering in one treatment group only — vgt_smd_1armcluster","text":"Hedges, L. V., & Citkowicz, M (2015). Estimating effect size clustering one treatment groups. Behavior Research Methods, 47(4), 1295-1308. doi:10.3758/s13428-014-0538-z Pustejovsky, J. E., & Rodgers, M. . (2019). Testing funnel plot asymmetry standardized mean differences. Research Synthesis Methods, 10(1), 57–71. doi:10.1002/jrsm.1332 Works Clearinghouse (2021). Supplement document Appendix E Works Clearinghouse procedures handbook, version 4.1 Institute Education Science. https://ies.ed.gov/ncee/wwc/Docs/referenceresources/WWC-41-Supplement-508_09212020.pdf","code":""},{"path":[]},{"path":"https://mikkelvembye.github.io/VIVECampbell/reference/vgt_smd_1armcluster.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Variance calculation when there is clustering in one treatment group only — vgt_smd_1armcluster","text":"","code":"vgt_smd_1armcluster( N_cl_grp = 60, N_ind_grp = 40, avg_grp_size = 10, ICC = 0.1, g = 0.2, model = \"ANCOVA\", cluster_adj = FALSE, R2 = 0.5, q = 3 ) #> # A tibble: 1 × 11 #>      gt    vgt    Wgt    hg    vhg     h    df n_covariates var_term1 adj_fct #>   <dbl>  <dbl>  <dbl> <dbl>  <dbl> <dbl> <dbl>        <dbl>     <dbl> <chr>   #> 1   0.2 0.0273 0.0271 0.128 0.0111  93.0  90.0            3    0.0208 eta     #> # ℹ 1 more variable: adj_value <dbl>  # Example showing how to add a suffix to the variable names vgt_smd_1armcluster( N_cl_grp = 60, N_ind_grp = 40, avg_grp_size = 10, ICC = 0.3, g = 0.2, model = \"ANCOVA\", cluster_adj = FALSE, R2 = 0.5, q = 3, add_name_to_vars = \"_icc03\" ) #> # A tibble: 1 × 11 #>   gt_icc03 vgt_icc03 Wgt_icc03 hg_icc03 vhg_icc03 h_icc03 df_icc03 #>      <dbl>     <dbl>     <dbl>    <dbl>     <dbl>   <dbl>    <dbl> #> 1      0.2    0.0399    0.0396    0.131    0.0172    61.3     58.3 #> # ℹ 4 more variables: n_covariates_icc03 <dbl>, var_term1_icc03 <dbl>, #> #   adj_fct_icc03 <chr>, adj_value_icc03 <dbl>  # Example showing how to select specific variables vgt_smd_1armcluster( N_cl_grp = 60, N_ind_grp = 40, avg_grp_size = 10, ICC = 0.3, g = 0.2, model = \"ANCOVA\", cluster_adj = FALSE, R2 = 0.5, q = 3, add_name_to_vars = \"_icc03\", vars = vgt_icc03 ) #> # A tibble: 1 × 1 #>   vgt_icc03 #>       <dbl> #> 1    0.0399"}]
